<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="在路上，慢慢走！">
<meta property="og:type" content="website">
<meta property="og:title" content="小沙文的博客">
<meta property="og:url" content="http://pengshuang.space/page/3/index.html">
<meta property="og:site_name" content="小沙文的博客">
<meta property="og:description" content="在路上，慢慢走！">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="小沙文的博客">
<meta name="twitter:description" content="在路上，慢慢走！">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://pengshuang.space/page/3/"/>

  <title> 小沙文的博客 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">小沙文的博客</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/11/09/分布式系统学习-ZooKeeper与Paxos/" itemprop="url">
                  分布式系统学习: ZooKeeper与Paxos
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-11-09T21:06:27+08:00" content="2016-11-09">
              2016-11-09
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/分布式系统/" itemprop="url" rel="index">
                    <span itemprop="name">分布式系统</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/11/09/分布式系统学习-ZooKeeper与Paxos/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/11/09/分布式系统学习-ZooKeeper与Paxos/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/11/09/分布式系统学习-ZooKeeper与Paxos/" class="leancloud_visitors" data-flag-title="分布式系统学习: ZooKeeper与Paxos">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="ZooKeeper-的设计目标"><a href="#ZooKeeper-的设计目标" class="headerlink" title="ZooKeeper 的设计目标"></a>ZooKeeper 的设计目标</h3><p>ZooKeeper致力于提供一个高性能、高可用，且具有严格的顺序访问控制能力（主要是写操作的严格顺序性）的分布式协调服务。高性能使得 ZooKeeper 能够应用于那些对系统吞吐有明确要求的大型分布式系统中，高可用使得分布式的单点问题得到了很好的解决，而严格的顺序访问控制使得客户端能够基于 ZooKeeper 实现一些复杂的同步原语。下面介绍一下 ZooKeeper 的四个设计目标。</p>
<h4 id="目标一：简单的数据模型"><a href="#目标一：简单的数据模型" class="headerlink" title="目标一：简单的数据模型"></a>目标一：简单的数据模型</h4><p>ZooKeeper 使得分布式程序能够通过一个共享的、树型结构的名字空间来进行相互协调。这里的树型结构的名字空间，是指 ZooKeeper 服务器内的一个数据模型，其由一系列被称为 ZNode 的数据节点组成，总的来说，其数据模型类似于一个文件系统，而 ZNode 之间的层级关系，就像文件系统的目录结构一样。不过，ZooKeeper 将全量数据存储在内存中，以此来实现提高服务器吞吐、减少延迟的目的。</p>
<h4 id="目标二：可以构建集群"><a href="#目标二：可以构建集群" class="headerlink" title="目标二：可以构建集群"></a>目标二：可以构建集群</h4><p>一个 ZooKeeper 集群通常由一组机器组成，一般 3 ~ 5 台机器就可以组成一个可用的 ZooKeeper 集群了。</p>
<p>组成 ZooKeeper 集群的每台机器都会在内存中维护当前的服务器状态，并且每台机器之间都互相保持通信。只要集群中有超过半数的机器能够正常工作，那么整个集群就能够正常对外服务。</p>
<p>ZooKeeper 的客户端程序会选择和集群中任意一台机器共同创建一个 TCP 连接，而一旦客户端和某台 ZooKeeper 服务器之间的连接断开之后，客户端会自动连接到集群中的其他机器。</p>
<h4 id="目标三：顺序访问"><a href="#目标三：顺序访问" class="headerlink" title="目标三：顺序访问"></a>目标三：顺序访问</h4><p>对于来自客户端的每个更新请求，ZooKeeper 都会分配一个全局唯一的递增编号，这个编号反映了所有事务操作的先后顺序，应用程序可以使用 ZooKeeper 的这个特性来实现更高层次的同步原语。</p>
<h4 id="目标四：高性能"><a href="#目标四：高性能" class="headerlink" title="目标四：高性能"></a>目标四：高性能</h4><p>由于 ZooKeeper 将全量数据存储在内存中，并直接服务于客户端的所有非事务请求，因此它尤其适用于以读操作为主的应用场景。</p>
<h3 id="ZooKeeper-基本概念"><a href="#ZooKeeper-基本概念" class="headerlink" title="ZooKeeper 基本概念"></a>ZooKeeper 基本概念</h3><h4 id="集群角色"><a href="#集群角色" class="headerlink" title="集群角色"></a>集群角色</h4><p>通常在分布式系统中，构成一个集群的每一台机器都有自己的角色，最典型的集群模式是 Master/Slave 模式。在这种模式下，我们把能够处理所有写操作的机器称为 Master 机器，把所有通过异步复制方式获取最新数据，并提供读服务的机器称为 Slave 机器。</p>
<p>而在 ZooKeeper 中，没有 Master/Slave，取而代之的是Leader、Follower 和 Observer 三种角色。ZooKeeper 集群中的所有机器通过一个 Leader 选举过程来选定一台称为“Leader”的机器。Leader 服务器为客户端提供读和写服务。而 Follower 和 Observer 都能够提供读服务，它们唯一的区别在于，Observer 机器不参与 Leader 的选举，也不参与写操作的“过半写成功”策略，因此 Observer 可以在不影响写性能的情况下提升集群的读性能。</p>
<h4 id="会话"><a href="#会话" class="headerlink" title="会话"></a>会话</h4><p>Session 是指客户端会话，在 ZooKeeper 中，一个客户端连接是指客户端和服务器之间的一个 TCP 长连接。ZooKeeper 对外的端口是 2181，客户端启动的时候，首先会与服务器建立一个 TCP 连接，从第一次连接建立开始，客户端的会话周期也开始了，通过这个连接，客户端可以通过心跳检测与服务器保持有效的会话，也能够向 ZooKeeper 服务器发送请求并接受响应，同时还能够通过该连接接收来自服务器的 Watch 事件通知。Session 的 sessionTimeout 值用来设置一个客户端会话的超时时间。当由于服务器压力太大、网络故障或是客户端主动断开连接等各种原因导致客户端连接断开时，只要在 sessionTimeout </p>
<h4 id="数据节点-Znode"><a href="#数据节点-Znode" class="headerlink" title="数据节点(Znode)"></a>数据节点(Znode)</h4><p>在 ZooKeeper 中， 节点分为两类，第一类同样是指构成集群的集群，称为机器节点；第二类则是指数据模型中的数据单元，我们称为数据节点—Znode。ZooKeeper 将所有数据存储在内存中，数据模型是一棵树，由斜杠进行分割的路径就是一个 ZNode，例如 /foo/path1。每个 Znode 上都会保存自己的数据内容，同时还会保存一系列属性信息。</p>
<p>在 ZooKeeper 中，Znode 节点可以分为持久节点和临时节点两类。持久节点一旦被创建了，除非主动移除，否则一直保存在 ZooKeeper 上；临时节点的生命周期和客户端会话绑定，一旦客户端会话失效，那么这个客户端创建的所有临时节点都会被移除。</p>
<h4 id="Watcher"><a href="#Watcher" class="headerlink" title="Watcher"></a>Watcher</h4><p>Watcher(事件监听器)，是 ZooKeeper 中的一个重要特性。ZooKeeper 允许用户在指定节点上注册一些 Watcher，并且在一些特定事件触发的时候，ZooKeeper 服务端会将事件通知到感兴趣的客户端上去，该机制是 ZooKeeper 实现分布式协调服务的重要特性。</p>
<h4 id="ACL"><a href="#ACL" class="headerlink" title="ACL"></a>ACL</h4><p>ZooKeeper 采用 ACL 策略来进行权限控制，类似于 UNIX 文件系统的权限控制。ZooKeeper 定义了如下 5 种权限。</p>
<ul>
<li>CREATE</li>
<li>READ</li>
<li>WRITE</li>
<li>DELETE</li>
<li>ADMIN</li>
</ul>
<h3 id="ZooKeeper-的-ZAB-协议"><a href="#ZooKeeper-的-ZAB-协议" class="headerlink" title="ZooKeeper 的 ZAB 协议"></a>ZooKeeper 的 ZAB 协议</h3><p>事实上，ZooKeeper 并没有完全采用 Paxos 算法，而是使用了一种称为 ZooKeeper Atomic Broadcast（ZAB）的协议作为其数据一致性的核心算法。</p>
<p>ZAB 协议是一种支持崩溃恢复的原子广播协议。在 ZooKeeper 中，主要通过 ZAB 协议来实现分布式数据一致性，基于该协议，ZooKeeper 实现了一种主备模式的系统架构来保持集群中各副本之间数据的一致性。ZAB 协议的这个主备模型架构保证了同一时刻集群中只能够有一个主进程来广播服务器的状态变更，因此可以很好的处理大量客户端的并发请求。另一方面，考虑到在分布式环境中，顺序执行的一些状态变更前后会存在一定的依赖关系，因此 ZAB 协议必须保证一个全局的变更序列被顺序应用。最后考虑到主进程可能会存在崩溃的可能，所以，ZAB 协议还需要做到在当前主进程出现上述异常情况的时候，依旧能够正常工作。</p>
<p>ZAB 的核心是定义了对于那些会改变 ZooKeeper 服务器数据状态的事务请求的处理方式：</p>
<pre><code>所以的事务请求必须由一个全局的唯一的服务器来协调处理，它被称为 Leader，其他的被
称为 Follower。Leader 负责将一个客户端事务请求转换成一个事务 Proposal (提
议)，并将该 Proposal 分发给集群中所有的 Follower。之后 Leader 服务器需要等
待所有 Follower 服务器反馈，一旦得到超过半数的 Follower 进行正确的反馈之后，
那么 Leader 再次向所有的 Follower 发送 Commit 消息，要求其将前一个 
Proposal 进行提交。
</code></pre><p>ZAB 协议包括两种基本的模式，分别是崩溃恢复和消息广播。当整个服务框架在启动的过程中，或是当 Leader 服务器出现网络中断、崩溃退出与重启等异常情况时，ZAB 协议就会进入恢复模式并选举产生新的 Leader 服务器。当选举产生了新的 Leader 服务器，同时集群中已经有过半的机器与该 Leader 服务器完成了状态同步之后，ZAB 协议就会退出恢复模式。其中，所谓的状态同步是指数据同步，用来保证集群中存在过半的机器能够和 Leader 服务器的数据状态保持一致。</p>
<p>当集群中已经有过半的 Follower 服务器完成了和 Leader 服务器的状态同步，那么整个服务框架就可以进入消息广播模式了。当一台同样遵守 ZAB 协议的服务器启动后加入到集群中时，如果此时集群中已经存在一个 Leader 服务器在负责进行消息广播，那么新加入的服务器就会自觉地进入数据恢复模式：找到 Leader 所在的服务器，并与其进行数据同步，然后一起参与到消息广播流程中去。ZooKeeper 的设计只允许唯一的一个 Leader 服务器来进行事务请求的处理。Leader 服务器在接收到客户端的事务请求后，会生成对应的事务提案并发起一轮广播协议；而如果集群中的其他机器接收到客户端的事务请求，那么这些非 Leader 服务器会首先将这个事务请求转发给 Leader 服务器。</p>
<p>当 Leader 服务器出现崩溃退出或机器重启，亦或集群中已经不存在过半的服务器与该 Leader 服务器保持正常通信时，那么在重新开始新一轮的原子广播事务操作之前，所有进程首先会使用崩溃恢复协议来使彼此达到一个一致的状态，于是整个 ZAB 流程就会从消息广播模式进入到崩溃恢复模式。</p>
<p>一个机器要称为新的 Leader，必须获得过半进程的支持，同时由于每个进程都有可能会崩溃，因此，在 ZAB 协议运行过程中，前后会出现多个 Leader，并且每个进程也有可能或多次成为 Leader，并且每个进程也有可能会多次成为 Leader。进入崩溃恢复模式后，只要集群中存在过半的服务器能够彼此进行正常通信，那么就可以产生一个新的 Leader 并再次进入消息广播模式。</p>
<p>接下来重点介绍 ZAB 协议中的消息广播和崩溃恢复过程。</p>
<h3 id="消息广播"><a href="#消息广播" class="headerlink" title="消息广播"></a>消息广播</h3><p>ZAB 协议的消息广播过程使用的是一个原子广播协议，类似一个二阶段提交过程。针对客户端的事务请求，Leader 服务器会为其生成对应的事务 Proposal，并将其发送给集群中其余所有的机器，然后再分别收集各自的选票，最后进行事务提交。不过在 ZAB 协议的二阶段提交过程中，所有的 Follower 服务器要么正常反馈 Leader 提出的事务 Proposal，要么就抛弃 Leader 服务器。同时，ZAB 协议将二阶段提交中的中断逻辑移除意味着可以在过半 Follower 服务器已经反馈 Ack 之后就开始提交事务 Proposal 了，而不需要等待集群中所有的 Follower 服务器都反馈响应。整个消息广播协议使基于具有 FIFO 特性的 TCP 协议来进行网络通信的，因此能够很容易地保证消息广播过程中的消息接收与发送的顺序。</p>
<p>在整个消息广播过程中，Leader 服务器会为每个事务请求生成对应的 Proposal 来进行广播，并且在广播事务 Proposal 之前，Leader 服务器会首先为这个事务 Proposal 分配一个全局单调递增的唯一 ID，我们称之为事务 ID(即 ZXID)。由于 ZAB 协议需要保证每一个消息严格的因果关系，因此必须将每一个事务 Proposal 按照其 ZXID 的先后顺序来进行排序与处理。</p>
<p>具体的，在消息广播过程中，Leader 服务器会为每一个 Follower 服务器都各自分配一个单独的队列，然后将需要广播的事务 Proposal 依次放入这些队列中去，并且根据 FIFO 策略进行消息发送。每一个 Follower 服务器在接收到这个事务 Proposal 之后，都会首先将其以事务日志的形式写入到本地磁盘中去，并且在成功写入后反馈给 Leader 服务器一个 Ack 响应。当 Leader 服务器接收到超过半数 Follower 的 Ack 响应后，就会广播一个 Commit 消息给所有的 Follower 服务器以通知其进行事务提交，同时 Leader 自身也会完成对事务的提交，而每一个 Follower 服务器在接收到 Commit 消息后，也会完成对事务的提交。</p>
<h3 id="崩溃恢复"><a href="#崩溃恢复" class="headerlink" title="崩溃恢复"></a>崩溃恢复</h3><p>ZAB 协议的这个基于原子广播协议的消息传播过程，在正常情况下运行非常良好，但是一旦 Leader 服务器出现崩溃，或者说由于网络原因导致 Leader 服务器失去了与过半 Follower 的联系，那么就会进入崩溃恢复模式。在 ZAB 协议中，为了保证程序的正常运行，整个恢复过程结束后需要选举出一个新的 Leader 服务器。因此，ZAB 协议需要一个高效且可靠的 Leader 选举算法，从而确保能够快速地选举新的 Leader。同时，Leader 选举算法不仅需要让 Leader 自己知道其自身已经被选举为 Leader，同时还需要让集群中的所有其他机器也能够快速地感知到选举产生的新的 Leader 服务器。</p>
<h3 id="数据同步"><a href="#数据同步" class="headerlink" title="数据同步"></a>数据同步</h3><p>完成 Leader 选举之后，在正式开始工作（即接收客户端的事务请求，然后提出新的提案）之前，Leader 服务器会首先确认事务日志中的所有 Proposal 是否已经被集群中过半的机器提交了，即是否完成数据同步。ZAB 协议的数据同步过程如下：</p>
<p>所有正常运行的服务器，要么成为 Leader，要么成为 Follower 并和 Leader 保持同步。Leader 服务器需要确保所有的 Follower 服务器能够接收到每一条事务 Proposal，并且能够正确地将所有已经提交了的事务 Proposal 应用到内存数据库中去。具体的，Leader 服务器会为每一个 Follower 服务器都准备一个队列，并将那些没有被各 Follower 服务器同步的事务以 Proposal 消息的形式逐个发送给 Follower 服务器，并在每一个 Proposal 消息后面紧接着再发送一个 Commit 消息，以表示该事务已经被提交。等到 Follower 服务器将所有其尚未同步的事务 Proposal 都从 Leader 服务器上同步过来并成功应用到本地数据库中，Leader 服务器就会将该 Follower 服务器加入到真正的可用 Follower 列表中，并开始之后的其他流程。</p>
<h3 id="ZAB-与-Paxos-算法的联系与区别"><a href="#ZAB-与-Paxos-算法的联系与区别" class="headerlink" title="ZAB 与 Paxos 算法的联系与区别"></a>ZAB 与 Paxos 算法的联系与区别</h3><p>ZAB 协议并不是 Paxos 算法的一个典型实现，但两者之间也存在很多联系：</p>
<ul>
<li>两者都存在一个类似于 Leader 进程的角色，由其负责协调多个 Follower 进程的运行。</li>
<li>Leader 进程都会等待超过半数的 Follower 做出正确的反馈后，才会将一个提案进行提交。</li>
<li>在 ZAB 协议中，每个 Proposal 中都包含了一个 epoch 值，用来代表当前的 Leader 周期，在 Paxos 算法中，同样存在这样的一个标识，知识名字变成了 Ballot。</li>
</ul>
<p>ZAB 协议和 Paxos 算法的本质区别在于，两者的设计目标不太一样。ZAB 协议主要用于构建一个高可用的分布式数据主备系统，而 Paxos 算法则是用于构建一个分布式的一致性状态机系统。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/11/08/HBase学习-专用过滤器/" itemprop="url">
                  HBase学习: 专用过滤器
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-11-08T17:25:26+08:00" content="2016-11-08">
              2016-11-08
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/HBase/" itemprop="url" rel="index">
                    <span itemprop="name">HBase</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/11/08/HBase学习-专用过滤器/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/11/08/HBase学习-专用过滤器/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/11/08/HBase学习-专用过滤器/" class="leancloud_visitors" data-flag-title="HBase学习: 专用过滤器">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>HBase 提供的第二类过滤器直接继承自 FilterBase，同时用于更特定的场景。其中一些过滤器只能做行筛选，因此只适用于扫描操作。</p>
<h3 id="单列值过滤器"><a href="#单列值过滤器" class="headerlink" title="单列值过滤器"></a>单列值过滤器</h3><p>当用户用一列的值来决定是否一行数据被过滤时，可以考虑使用单列值过滤器。首先设定待检查的列，然后设置待检查的列的对应值。具体构造函数如下：</p>
<pre><code>SingleColumnValueFilter(byte[] family, byte[] qualifier,
    CompareOp compareOp, byte[] value)
SingleColumnValueFilter(byte[] family, byte[] qualifier,
    CompareOp compareOp, ByteArrayComparable comparator)
</code></pre><p>第一个构造函数比较简单，因为它只在内部创建了一个 BinaryComparator 实例。第二个构造函数中所需的参数与用户一直在使用的基于 CompareFilter 的类相同，尽管 SingleColumnValueFilter 并不是直接继承自 CompareFilter， 但还是使用了相同的参数类型。</p>
<p>同时，过滤器还提供了一些辅助方法帮助用户微调过滤行为:</p>
<pre><code>boolean getFilterIfMissing()
void setFilterIfMissing(boolean filterIfMissing)
boolean getLatestVersionOnly()
void setLatestVersionOnly(boolean latestVersionOnly)
</code></pre><p>前者决定了当参考列不存在时如何处理这一行。默认的这一行是被包含在结果中的。用户可以用 <strong>setFilterIfMissing(true)</strong> 来过滤这些行。即，这样设置之后所有不包含参考列的行都可以被过滤掉。</p>
<p>下面一个例子展示了如何使用过滤器返回包含特定列中特定值的行。</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable hTable = new HTable(conf, &quot;temp2&quot;);

SingleColumnValueFilter filter = new SingleColumnValueFilter(
        Bytes.toBytes(&quot;colfam1&quot;),
        Bytes.toBytes(&quot;col-5&quot;),
        CompareFilter.CompareOp.NOT_EQUAL,
        new SubstringComparator(&quot;val-5&quot;));
filter.setFilterIfMissing(true);

Scan scan = new Scan();
scan.setFilter(filter);
ResultScanner scanner = hTable.getScanner(scan);
for(Result result: scanner){
    System.out.println(result);
}
scanner.close();

Get get = new Get(Bytes.toBytes(&quot;row-6&quot;));
get.setFilter(filter);
Result result = hTable.get(get);
System.out.println(result);
</code></pre><h3 id="单列排除过滤器"><a href="#单列排除过滤器" class="headerlink" title="单列排除过滤器"></a>单列排除过滤器</h3><p>单列排除过滤器继承自 SingleColumnValueFilter, 它的参考列不被包括在结果之中。</p>
<h3 id="前缀过滤器"><a href="#前缀过滤器" class="headerlink" title="前缀过滤器"></a>前缀过滤器</h3><p>在构造当前过滤器的时候传入一个前缀，所有与前缀匹配的行都会被返回给客户端。构造函数如下：</p>
<pre><code>Public PrefixFilter(byte[] prefix)
</code></pre><p>下面的例子展示了如何使用前缀过滤器。</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable hTable = new HTable(conf, &quot;temp2&quot;);

Filter filter = new PrefixFilter(Bytes.toBytes(&quot;row-1&quot;));
Scan scan = new Scan();
scan.setFilter(filter);
ResultScanner scanner = hTable.getScanner(scan);
for(Result result : scanner){
    System.out.println(result);
}
scanner.close();

Get get = new Get(Bytes.toBytes(&quot;row-5&quot;));
get.setFilter(filter);
Result result = hTable.get(get);
System.out.println(result);
</code></pre><h3 id="包含结束的过滤器"><a href="#包含结束的过滤器" class="headerlink" title="包含结束的过滤器"></a>包含结束的过滤器</h3><p>扫描操作中的开始行被包含到结果中，但终止行被排除在外。在使用这个过滤器的时候，用户也可以将结束行包含在结果中。例如下面这个例子：</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable hTable = new HTable(conf, &quot;temp2&quot;);
Filter filter = new InclusiveStopFilter(Bytes.toBytes(&quot;row-5&quot;));

Scan scan = new Scan();
scan.setStartRow(Bytes.toBytes(&quot;row-3&quot;));
scan.setFilter(filter);
ResultScanner scanner = hTable.getScanner(scan);
for(Result result:scanner){
    System.out.println(result);
}
scanner.close();
</code></pre><h3 id="时间戳过滤器"><a href="#时间戳过滤器" class="headerlink" title="时间戳过滤器"></a>时间戳过滤器</h3><p>当用户需要在扫描结果中对版本进行细粒度的控制时，这个过滤器可以满足需求。用户需要传入一个装载了时间戳的 List 实例。</p>
<pre><code>TimestampFilter(List&lt;Long&gt; timestamps)
</code></pre><p>下面这个例子展示了一个典型的时间戳过滤器，其中第一个扫描中使用了包括 3 个时间戳的过滤器，在第二个扫描中增加了一个时间范围限制。</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable hTable = new HTable(conf, &quot;temp2&quot;);

List&lt;Long&gt; ts = new ArrayList&lt;Long&gt;();
// 向列表中添加时间戳
ts.add(new Long(5));
ts.add(new Long(10));
ts.add(new Long(15));
Filter filter = new TimestampsFilter(ts);

Scan scan1 = new Scan();
// 向scan实例中添加过滤器
scan1.setFilter(filter);
ResultScanner scanner1 = hTable.getScanner(scan1);
for(Result result:scanner1){
    System.out.println(result);
}
scanner1.close();

Scan scan2 = new Scan();
scan2.setFilter(filter);
// 添加时间范围限制
scan2.setTimeRange(8,12);
ResultScanner scanner2 = hTable.getScanner(scan2);
for(Result result:scanner2){
    System.out.println(result);
}
scanner2.close();
</code></pre>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/11/07/HBase学习-比较过滤器/" itemprop="url">
                  HBase学习: 比较过滤器
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-11-07T16:55:42+08:00" content="2016-11-07">
              2016-11-07
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/HBase/" itemprop="url" rel="index">
                    <span itemprop="name">HBase</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/11/07/HBase学习-比较过滤器/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/11/07/HBase学习-比较过滤器/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/11/07/HBase学习-比较过滤器/" class="leancloud_visitors" data-flag-title="HBase学习: 比较过滤器">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>HBase 提供的第一种过滤器实现就是<strong>比较过滤器</strong>。用户创建一个实例时需要一个比较运算符和一个比较器实例。每个比较过滤器的构造方法都有一个从 CompareFilter 继承来的签名方法。</p>
<pre><code>CompareFilter(CompareOp valueCompareOp,
    WritableByteArrayCompareable valueComparator)
</code></pre><p>用户需要提供比较运算符和比较类来让过滤器工作。</p>
<p>HBase 中过滤器本来的目的是为了筛掉无用的信息，被过滤掉的信息不会被传递到客户端，过滤器不能用来指定用户需要哪些信息，而是在读取数据的过程中不返回用户不想要的信息。</p>
<p>相反，所有基于 CompareFilter 的过滤处理过程与上述描述正好相反，它们返回匹配的值</p>
<h3 id="行过滤器"><a href="#行过滤器" class="headerlink" title="行过滤器"></a>行过滤器</h3><p>行过滤器基于行键来过滤数据。下面一个例子展示了使用不同的过滤器来获得需要的行。</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable hTable = new HTable(conf, &quot;temp2&quot;);

Scan scan = new Scan();
scan.addColumn(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;col-0&quot;));
// 指定比较运算符和比较器
Filter filter1 = new RowFilter(CompareFilter.CompareOp.LESS_OR_EQUAL,
        new BinaryComparator(Bytes.toBytes(&quot;row-22&quot;)));
scan.setFilter(filter1);
ResultScanner scanner1 = hTable.getScanner(scan);
for(Result res: scanner1){
    System.out.println(res);
}
scanner1.close();

// 用正则表达式来匹配行键
Filter filter2 = new RowFilter(CompareFilter.CompareOp.EQUAL,
        new RegexStringComparator(&quot;.*-.5&quot;));
scan.setFilter(filter2);
ResultScanner scanner2 = hTable.getScanner(scan);
for(Result res: scanner2){
    System.out.println(res);
}
scanner2.close();

// 子串匹配方法
Filter filter3 = new RowFilter(CompareFilter.CompareOp.EQUAL,
        new SubstringComparator(&quot;-5&quot;));
scan.setFilter(filter3);
ResultScanner scanner3 = hTable.getScanner(scan);
for(Result res: scanner3){
    System.out.println(res);
}
scanner3.close();
</code></pre><h3 id="列族过滤器"><a href="#列族过滤器" class="headerlink" title="列族过滤器"></a>列族过滤器</h3><p>和行过滤器类似，它通过比较列族而不是行键来返回结果。通过使用不同组合的运算符和比较器，用户可以在列族一级筛选所需的数据。下面一个例子展示了如何使用它。</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable hTable = new HTable(conf, &quot;temp2&quot;);
// 创建一个过滤器, 指定比较运算符和比较器, 使用过滤器来返回特定的列族
Filter filter1 = new FamilyFilter(CompareFilter.CompareOp.LESS,
        new BinaryComparator(Bytes.toBytes(&quot;colfam3&quot;)));
Scan scan = new Scan();
scan.setFilter(filter1);
// 使用扫描器扫描
ResultScanner scanner = hTable.getScanner(scan);
for(Result res: scanner){
    System.out.println(res);
}
scanner.close();

Get get1 = new Get(Bytes.toBytes(&quot;row-5&quot;));
// 使用和之前相同的过滤器获取同一行的数据
get1.setFilter(filter1);
Result result1 = hTable.get(get1);
System.out.println(&quot;Result of get(): &quot; + result1);

 // 在一个列族上创建一个过滤器，同时获取另一行的数据
Filter filter2 = new FamilyFilter(CompareFilter.CompareOp.EQUAL,
        new BinaryComparator(Bytes.toBytes(&quot;colfam3&quot;)));
Get get2 = new Get(Bytes.toBytes(&quot;row-5&quot;));
get2.addFamily(Bytes.toBytes(&quot;colfam1&quot;));
get2.setFilter(filter2);
// 使用新的过滤器获取同一行数据，此时返回的结果为 None 
Result result2 = hTable.get(get2);
System.out.print(&quot;Result of get(): &quot; + result2);
</code></pre><h4 id="列名过滤器"><a href="#列名过滤器" class="headerlink" title="列名过滤器"></a>列名过滤器</h4><p>通过列名筛选特定的列。</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable hTable = new HTable(conf, &quot;temp2&quot;);

Filter filter = new QualifierFilter(CompareFilter.CompareOp.LESS_OR_EQUAL,
        new BinaryComparator(Bytes.toBytes(&quot;col-2&quot;)));
Scan scan = new Scan();
scan.setFilter(filter);
ResultScanner scanner = hTable.getScanner(scan);
for(Result result: scanner){
    System.out.println(result);
}
scanner.close();

Get get = new Get(Bytes.toBytes(&quot;row-5&quot;));
get.setFilter(filter);
Result result2 = hTable.get(get);
System.out.print(result2);
</code></pre><h4 id="值过滤器"><a href="#值过滤器" class="headerlink" title="值过滤器"></a>值过滤器</h4><p>值过滤器可以筛选某个特定值的单元格。</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable hTable = new HTable(conf, &quot;temp2&quot;);

Filter filter = new ValueFilter(CompareFilter.CompareOp.EQUAL,
        new SubstringComparator(&quot;.4&quot;));
Scan scan = new Scan();
scan.setFilter(filter);
ResultScanner scanner = hTable.getScanner(scan);
for(Result result : scanner){
    System.out.println(result);
}
scanner.close();
</code></pre><h3 id="参考列过滤器"><a href="#参考列过滤器" class="headerlink" title="参考列过滤器"></a>参考列过滤器</h3><p>参考列过滤器允许用户指定一个参考列或者引用列，并使用参考列控制其他列的过滤。参考列过滤器使用参考列的时间戳，并在过滤时包括所有与引用时间戳相同的列。</p>
<p>下面是它们的构造方法：</p>
<pre><code>DependentColumnFilter(byte[] family, byte[] qualifier)
DependentColumnFilter(byte[] family, byte[] qualifier,
    boolean dropDependentColumn)
DependentColumnFilter(byte[] family, byte[] qualifier,
    boolean dropDependentColumn, CompareOp valueCompareOp,
    ByteArrayComparable valueComparator)
</code></pre><p>由于参考过滤器也是继承自 CompareFilter，所以它也可以帮助用户筛选列，不过这个过滤器是基于这些列值进行筛选的。用户可以把他理解为一个 ValueFilter 和 一个时间戳过滤器的组合。用户可以传入比较运算符和基准值来启用 ValueFilter 的功能。</p>
<p>下面这个例子展示了参考过滤器的用法：</p>
<pre><code>public class Filter5 {
    private static void filter(boolean drop,
                               CompareFilter.CompareOp operator,
                               ByteArrayComparable comparator)
    throws IOException {
        Filter filter;
        if(comparator != null){
            filter = new DependentColumnFilter(Bytes.toBytes(&quot;colfam1&quot;),
                    Bytes.toBytes(&quot;col-5&quot;), drop, operator, comparator);
        } else {
            filter = new DependentColumnFilter(Bytes.toBytes(&quot;colfam1&quot;),
                    Bytes.toBytes(&quot;col-5&quot;), drop);
        }

    Configuration conf = HBaseConfiguration.create();
    HTable hTable = new HTable(conf, &quot;temp2&quot;);
    Scan scan = new Scan();
    scan.setFilter(filter);
    ResultScanner scanner = hTable.getScanner(scan);
    for(Result result : scanner){
        System.out.println(result);
    }
    scanner.close();

    Get get = new Get(Bytes.toBytes(&quot;row-5&quot;));
    get.setFilter(filter);
    Result result = hTable.get(get);
    System.out.println(result);

}
public static void main(String[] args) throws IOException
{
    filter(true, CompareFilter.CompareOp.NO_OP, null);
    filter(false, CompareFilter.CompareOp.NO_OP, null);
    filter(true, CompareFilter.CompareOp.EQUAL,
            new BinaryPrefixComparator(Bytes.toBytes(&quot;val-5&quot;)));
    filter(false, CompareFilter.CompareOp.EQUAL,
            new BinaryPrefixComparator(Bytes.toBytes(&quot;val-5&quot;)));
    filter(true, CompareFilter.CompareOp.EQUAL,
            new RegexStringComparator(&quot;.*\\.5&quot;));
    filter(false, CompareFilter.CompareOp.EQUAL,
            new RegexStringComparator(&quot;.*\\.5&quot;));
    }
}
</code></pre>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/29/HBase-学习-扫描/" itemprop="url">
                  HBase 学习: 扫描
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-29T10:30:50+08:00" content="2016-10-29">
              2016-10-29
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/10/29/HBase-学习-扫描/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/10/29/HBase-学习-扫描/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/10/29/HBase-学习-扫描/" class="leancloud_visitors" data-flag-title="HBase 学习: 扫描">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><p>扫描技术 (scan) 类似于数据库系统中的游标，并利用到了 HBase 提供的底层顺序存储的数据结构。</p>
<p>Scan 类拥有以下构造器：</p>
<pre><code>Scan()
Scan(byte[] startRow, Filter filter)
Scan(byte[] startRow)
Scan(byte[] startRow, byte[] stopRow)
</code></pre><p>我们可以选择性地提供 startRow 参数，来定义扫描读取 HBase 表的起始行键，即行键不是必须指定的。同时可选 stopRow 来限定读取到何时停止。</p>
<p>创建 Scan 实例之后，用户可能还要给它增加更多限制条件。可以使用多种方法限制所要读取的数据：</p>
<pre><code>Scan addFamily(byte[] family)
Scan addColumn(byte[] family, byte[] qualifier)
</code></pre><p>一旦设置好了 Scan 实例，就可以调用 Htable 的 getScanner() 方法，获得用于检索数据的 ResultScanner 实例。</p>
<p>扫描操作不会通过一次 RPC 请求返回所有匹配的行，而是以行为单位进行返回，很明显，行的数目很大，可能有上千条甚至更多，同时在一次请求中发送大量数据，会占用大量的系统资源并消耗很长时间。</p>
<p>ResultScanner 把扫描操作转换为类似的 get 操作，它将每一行数据封装成一个 Result 实例，并将所有的 Result 实例放入一个迭代器中，ResultScanner 的一些方法如下：</p>
<pre><code>Result next() throws IOException
Result next(int nbRows) throws IOException
void close()
</code></pre><p>有 2 种类型的 next() 调用供用户选择。调用 close() 方法会释放所有由扫描控制的资源。</p>
<p>next() 调用返回一个单独的 Result 实例，这个实例代表了下一个可用的行。此外，用户可以使用 next(int nbRows) 一次获取多行数据，它返回一个数组，数组中包含的 Result 实例最多可达 nbRows 个，每个实例代表唯一的一行。下面展示了一个关于扫描的简单例子。</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable table = new HTable(conf, &quot;test&quot;);

Scan scan1 = new Scan();
ResultScanner scanner1 = table.getScanner(scan1);
for (Result res: scanner1) {
    System.out.println(res);
}
scanner1.close();

Scan scan2 = new Scan();
scan2.addFamily(Bytes.toBytes(&quot;colfam1&quot;));
ResultScanner scanner2 = table.getScanner(scan2);
for (Result res: scanner2) {
    System.out.println(res);
}
scanner2.close();

Scan scan3 = new Scan();
// 使用 builder 模式将详细限制条件添加到 Scan 中
scan3.addColumn(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;col-5&quot;))
        .addColumn(Bytes.toBytes(&quot;colfam2&quot;), Bytes.toBytes(&quot;col-33&quot;))
        .setStartRow(Bytes.toBytes(&quot;row-10&quot;)).setStopRow(Bytes.toBytes(&quot;row-20&quot;));
ResultScanner scanner3 = table.getScanner(scan3);
for(Result res: scanner3) {
    System.out.println(res);
}
scanner3.close();
</code></pre><p><strong>注意</strong>：要确保尽早释放扫描器实例，一个打开的扫描器会占用不少服务端资源，累积多了会占用大量的堆空间。当使用完 ResultScanner 之后应调用它的 close() 方法，同时应当把 close() 方法放到 try/finally 块中，以保证其在迭代获取数据过程中出现异常和错误时，仍然能执行 close()。</p>
<h3 id="缓存与批量处理"><a href="#缓存与批量处理" class="headerlink" title="缓存与批量处理"></a>缓存与批量处理</h3><p>当我想要一次 RPC 请求可以获取多行数据时，可以使用<strong>扫描器缓存</strong>，默认情况下，这个缓存是关闭的。</p>
<p>可以在连个层面上打开它：在表的层面，这个表所有扫描实例的缓存都会生效：也可以在扫描层面，这样便只会影响当前的扫描实例。用户可以使用以下的 HTable 方法设置表级的扫描器缓存：</p>
<pre><code>void setScannerCaching(int scannerCaching)
int getScannerCaching()
</code></pre><p>用户可以修改整个 HBase 集群的默认值1，只要把下面的配置项添加到 hbase-site.xml 中即可。</p>
<pre><code>&lt;property&gt;
    &lt;name&gt;hbase.client.scanner.caching&lt;/name&gt;
    &lt;value&gt;10&lt;/value&gt;
&lt;/property&gt;
</code></pre><p>可以使用下列 Scan 类的方法设置扫描级别的缓存：</p>
<pre><code>void setCaching(int caching)
int getCaching()
</code></pre><p><strong>注意</strong>：扫描层面的配置高于表层面的配置，这两种方法能控制每次RPC调用取回的行数。</p>
<p>我们之前介绍的了如何使用客户端的扫描器缓存来从远程 region 服务器向客户端整批传输数据，不过还有一件事需要注意：数据量非常大的行，这些行有可能超过客户端进程的内存容量。HBase 和它的客户端 API 对这个问题有一个解决方法：批量。用户可以使用以下方法控制批量获取操作：</p>
<pre><code>void setBatch(int batch)
int getBatch()
</code></pre><p>缓存是面向行一级的操作，而批量则是面向列一级的操作。批量可以让用户选择每一次 ResultScanner 实例的 next() 操作要取回多少列。例如，在扫描中设置 setBatch(5)，则一次 next() 返回的 Result 实例会包括 5 列。</p>
<p>通过组合使用扫描器缓存和批量大小，可以让用户方便地控制一个范围内的行键时所需要的 RPC 调用次数。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/28/HBase-学习-Delete-和-行锁/" itemprop="url">
                  HBase 学习: Delete、批量处理操作
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-28T15:50:58+08:00" content="2016-10-28">
              2016-10-28
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/HBase/" itemprop="url" rel="index">
                    <span itemprop="name">HBase</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/10/28/HBase-学习-Delete-和-行锁/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/10/28/HBase-学习-Delete-和-行锁/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/10/28/HBase-学习-Delete-和-行锁/" class="leancloud_visitors" data-flag-title="HBase 学习: Delete、批量处理操作">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="单行删除"><a href="#单行删除" class="headerlink" title="单行删除"></a>单行删除</h3><p>delete() 方法 </p>
<pre><code>void delete(Delete delete) throws IOException
</code></pre><p>和 get 及 post 方法一样，用户必须先创建一个 Delete 实例，然后再添加想要删除的数据的详细信息。</p>
<p>下面是一个使用 delete() 函数的例子</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable table = new HTable(conf, &quot;test1&quot;);
Delete delete = new Delete(Bytes.toBytes(&quot;row1&quot;));
// 设置时间戳
delete.setTimestamp(1);
// 删除一列中的特定版本
delete.deleteColumn(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), 1);
// 删除一列中的全部版本
delete.deleteColumns(Bytes.toBytes(&quot;colfam2&quot;), Bytes.toBytes(&quot;qual1&quot;));
// 删除一列中的给定版本和所有更旧的版本
delete.deleteColumns(Bytes.toBytes(&quot;colfam2&quot;), Bytes.toBytes(&quot;qual3&quot;),15);
// 删除整个列族,包括所有的列和版本
delete.deleteFamily(Bytes.toBytes(&quot;colfam3&quot;));
// 删除给定列族中的所有列的给定版本和所有更旧的版本
delete.deleteFamily(Bytes.toBytes(&quot;colfam3&quot;), 3);
table.delete(delete);
table.close(); 
</code></pre><h3 id="多行删除"><a href="#多行删除" class="headerlink" title="多行删除"></a>多行删除</h3><p>多行删除和之前博文介绍的多行 Put 很类似，</p>
<pre><code>void delete(List&lt;Delete&gt; deletes) throw IOException
</code></pre><p>这里不再赘述。</p>
<h3 id="批量处理操作"><a href="#批量处理操作" class="headerlink" title="批量处理操作"></a>批量处理操作</h3><p>HBase 中有一些 API 可以批量处理跨多行的不同操作。</p>
<pre><code>void batch(List&lt;Row&gt; actions, Object[] results) throws 
    IOException, InterruptedException
Object[] batch(List&lt;Row&gt; actions) throws
    IOException, InterruptedException
</code></pre><p>上面的 API 提供了批量处理操作。用户可能注意到这里引入了一个新的名为 Row 的类，它是 Put、Get 和 Delete 的祖先，或者是父类。</p>
<p>使用同样的父类允许在列表中实现多态，即放入以上 3 种不同的子类。这种调用跟之前介绍的基于列表的调用方法一样简单易用。下面展示了一个简单的例子。</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable table = new HTable(conf, &quot;test&quot;);

byte[] ROW1 = Bytes.toBytes(&quot;row1&quot;);
byte[] ROW2 = Bytes.toBytes(&quot;row2&quot;);

byte[] COLFAM1 = Bytes.toBytes(&quot;colfam1&quot;);

byte[] QUAL1 = Bytes.toBytes(&quot;qual1&quot;);

List&lt;Row&gt; batch = new ArrayList&lt;Row&gt;();

Put put = new Put(ROW1);
put.add(COLFAM1, QUAL2,Bytes.toBytes(&quot;val5&quot;));
batch.add(put);

Get get1 = new Get(ROW2);
get1.addColumn(COLFAM1,QUAL2);
batch.add(get1);

Delete delete = new Delete(ROW1);
delete.deleteColumns(COLFAM1,QUAL2);
batch.add(delete);

table.batch(batch, results);
</code></pre><p><strong>注意</strong>：不可以将针对同一行的 Put 和 Delete 操作放在同一个批量处理请求中。</p>
<h3 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h3><p>像 put()、delete()、checkAndPut() 这样的修改操作是独立执行的，这意味着在一个串行方式的执行中，对于每一行必须保证行级别的操作是原子性的。region 服务器提供了一个行锁 (row lock) 的特性，这个特性保证了只有一个客户端能获取一行数据相应的锁，同时对该行进行修改。</p>
<p>处理服务器端隐式加锁之外，客户端也可以显示地对当行数据的多次操作进行加锁，通过以下调用实现：</p>
<pre><code>RowLock lockRow(byte[] row) throws IOException
void unlockRow(RowLock r1) throws IOException
</code></pre><p>第一个调用 lockRow() 需要一个行健作为参数，返回一个 RowLock 的实例，这个实例可以供后续的 Put 或者 Delete 的构造函数使用。一旦不再需要锁时，必须通过 unLockRow() 调用来释放它。</p>
<p>默认的锁超时时间是一分钟，但是可以在 <strong>hbase-site.xml</strong> 文件中添加一下配置项。</p>
<pre><code>&lt;property&gt;
    &lt;name&gt;hbase.regionserver.lease.period&lt;/name&gt;
    &lt;value&gt;1200000&lt;/value&gt;
&lt;property&gt;
</code></pre><p><strong>注意</strong>：Get 方法是不需要锁的。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/27/HBase-学习-Put-和-Get“/" itemprop="url">
                  HBase 学习: Put 和 Get
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-27T19:53:24+08:00" content="2016-10-27">
              2016-10-27
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/HBase/" itemprop="url" rel="index">
                    <span itemprop="name">HBase</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/10/27/HBase-学习-Put-和-Get“/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/10/27/HBase-学习-Put-和-Get“/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/10/27/HBase-学习-Put-和-Get“/" class="leancloud_visitors" data-flag-title="HBase 学习: Put 和 Get">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="单行-Put"><a href="#单行-Put" class="headerlink" title="单行 Put"></a>单行 Put</h3><pre><code>void put(Put put) throws IOException
</code></pre><p>这个方法以单个 Put 或存储在列表中的一组 Put 对象作为输入参数。</p>
<p>创建 Put 实例时用户需要提供一个行健 row，在 HBase 中每行数据都有唯一的行健作为标识，跟 HBase 的大多数数据类型一样，它是一个 Java 的 byte[] 数组。用户可以按自己的需求来指定每行的行健。</p>
<p>下面是一个简单的 HBase 插入数据的实例应用。</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable table = new HTable(conf, &quot;test1&quot;);
//指定一行来创建一个 Put
Put put = new Put(Bytes.toBytes(&quot;row1&quot;));
//向 Put 中添加一个名为 &quot;colfam1:qual1&quot; 的列
put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), 
Bytes.toBytes(&quot;val1&quot;));
//将这一行存储到 HBase 表中
table.put(put);
// 关闭表
table.close();
</code></pre><h3 id="客户端的写缓存区"><a href="#客户端的写缓存区" class="headerlink" title="客户端的写缓存区"></a>客户端的写缓存区</h3><p>每一个put操作实际上都是一个 RPC 操作，它将客户端数据传送到服务器然后返回。这只适合小数据量的操作，如果有个应用程序需要每秒存储上千行数据到 HBase 表中，就不太合适，</p>
<p>HBase 的 api 配备了一个客户端的写缓冲区，缓冲区负责收集 put 操作，然后调用 RPC 操作一次性将 put 送往服务器。全局交换机控制着该缓冲区是否在使用。默认情况下，客户端缓冲区是禁用的。可以通过将 自动刷写（autoflush）设置为 false 来激活缓冲区。</p>
<p>下面举一个客户端写缓冲区的例子，这样比较好理解一些：</p>
<p>Configuration conf = HBaseConfiguration.create();</p>
<pre><code>HTable table = new HTable(conf, &quot;test1&quot;);
//检查自动刷写标识位的设置
System.out.println(&quot;Auto flush: &quot; + table.isAutoFlush());
//将一些行和列数据存入 HBase
table.setAutoFlushTo(false);

Put put1 = new Put(Bytes.toBytes(&quot;row1&quot;));
put1.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), Bytes.toBytes(&quot;val1&quot;));
table.put(put1);

Put put2 = new Put(Bytes.toBytes(&quot;row2&quot;));
put2.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), Bytes.toBytes(&quot;val2&quot;));
table.put(put2);

Get get = new Get(Bytes.toBytes(&quot;row1&quot;));
//试图加载先前存储的行,结果会打印出 &quot; Restful: keyvalues=NONE &quot;
Result res1 = table.get(get);
System.out.println(&quot;Result: &quot; + res1);
// 强制刷写缓冲区,会导致产生一个 RPC 请求
table.flushCommits();
// 现在,这一行被持久化了,可以被读取了
Result res2 = table.get(get);
System.out.println(&quot;Result: &quot; + res2);
</code></pre><h3 id="Put-列表"><a href="#Put-列表" class="headerlink" title="Put 列表"></a>Put 列表</h3><p>客户端的 api 可以插入单个 Put 实例，同时也有批量处理操作的高级特性。请看下面的例子：</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable table = new HTable(conf, &quot;test1&quot;);

List&lt;Put&gt; puts = new ArrayList&lt;Put&gt;();

Put put1 = new Put(Bytes.toBytes(&quot;row1&quot;));
put1.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), Bytes.toBytes(&quot;val1&quot;));
puts.add(put1);

Put put2 = new Put(Bytes.toBytes(&quot;row2&quot;));
put2.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual2&quot;), Bytes.toBytes(&quot;val2&quot;));
puts.add(put2);

table.put(puts);
</code></pre><p> 上面这个例子使用列表向 HBase 中添加数据。当使用基于列表的 put 调用时，用户需要特别注意：用户无法控制服务器执行 put 的顺序，这意味着服务器被调用的顺序也不受用户控制。如果要保证写入的顺序，需要小心地使用这个操作，最坏的情况，要减少每一批量的操作数，并显示地刷写客户端写缓冲区，强制把操作发送到远程服务器。</p>
<h3 id="原子性操作-compare-and-set"><a href="#原子性操作-compare-and-set" class="headerlink" title="原子性操作 compare-and-set"></a>原子性操作 compare-and-set</h3><p>有一种特别的 put 调用，其能保证自身操作的原子性：检查写。有了这种带有检查功能的方法，就能保证服务器端 put 操作的原子性。如果检查成功通过，就执行 put 操作，否则就彻底放弃修改操作。这种方法可用来检查现有相关值，并决定是否修改数据的操作。</p>
<pre><code>boolean checkAndPut(Byte[] row, byte[] family, byte[] qualifier, 
    byte[] value, Put put) throws IOException
</code></pre><p>这种有原子性保证的操作经常被用于账户结余、状态转换或数据处理等场景。这些应用场景的共同点是，在读取数据的同时需要处理数据。一旦你想把一个处理好的结果写回 HBase，并保证没有其他客户端已经做了同样的事情，你就可以使用这个有原子性保证的操作，先比较原值，再做修改。</p>
<p>有一种特别的检查通过 <strong>checkAndPut()</strong> 调用来完成，即只有在另外一个值不存在的情况下，才执行这个修改。要执行这种操作只需要将参数 value 设置为 <strong>null</strong> 即可，只要指定列不存在，就可以成功执行修改操作。</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable table = new HTable(conf, &quot;test1&quot;);

Put put1 = new Put(Bytes.toBytes(&quot;row1&quot;));
put1.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), Bytes.toBytes(&quot;val1&quot;));
//检查指定列是否存在,按检查的结果决定是否执行 put 操作
boolean res1 = table.checkAndPut(Bytes.toBytes(&quot;row1&quot;),
        Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;),null,put1);
//输出结果应为: &quot;Put applied: true&quot;
System.out.println(&quot;Put applied: &quot; + res1);
//再次向同一单元格写入数据
boolean res2 = table.checkAndPut(Bytes.toBytes(&quot;row1&quot;),
        Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;),null,put1);
//因为那个列的值已经存在,此时的输出结果应为 &quot;Put applied:false&quot;
System.out.println(&quot;Put applied: &quot; + res2);

Put put2 = new Put(Bytes.toBytes(&quot;row1&quot;));
//创建一个新的 Put 实例,这次使用一个不同的列限定符
put2.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual2&quot;), Bytes.toBytes(&quot;val2&quot;));
//当上一次的put值存在时,写入新的值
boolean res3 = table.checkAndPut(Bytes.toBytes(&quot;row1&quot;),
        Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;),Bytes.toBytes(&quot;val1&quot;),put2);
//因为已经存在,所以输出的结果应当为 &quot;Put applied: true&quot;
System.out.println(&quot;Put applied: &quot; + res3);
</code></pre><h3 id="单行-Get"><a href="#单行-Get" class="headerlink" title="单行 Get"></a>单行 Get</h3><p>get 方法分为两类：一类是一次获取一行数据；另一类是一次获取多行数据。</p>
<p>与 Put 操作一样。用户有许多方法可用，可用通过多种标准筛选目标数据，也可以指定精确的坐标获取某个单元格的数据:</p>
<pre><code>Get addFamily(byte[] family)
Get addColumn(bytep[] family, byte[] qualifier)
Get setTimeRange(long minStamp,long maxStamp) throws IOException
Get setTimeStamp(long timeStamp)
Get getMaxVersions() 
Get setMaxVersions(int maxVersions) throws IOException
</code></pre><p>下面一个例子展示了从 HBase 中获取数据的整个过程</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable table = new HTable(conf, &quot;test1&quot;);
// 使用一个指定的行健构建一个 Get 实例
Get get = new Get(Bytes.toBytes(&quot;row1&quot;));
// 向 Get 实例中添加一个列
get.addColumn(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;));
// 从 HBase 中获取指定列的行数据
Result result = table.get(get);
// 从返回的结果中获取对应列的数据
byte[] val = result.getValue(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;));
// 将数据转换为字符串打印输出
System.out.println(&quot;Value: &quot; + Bytes.toString(val));
</code></pre><p>get 方法调用后返回一个 Result 类的实例。这里着重介绍一下 Restful 类一些面向列的存取函数：</p>
<pre><code>List&lt;KeyValue&gt; getColumn(byte[] family, byte[] qualifier);
KeyValue getColumnLatest(byte[] family, byte[] qualifier);
boolean containsColumn(byte[] family, byte[] qualifier);
</code></pre><p>这个方法返回一个特定列的多个值，返回值中的版本数取决于用户调用 get()方法之前，创建 Get 实例时设置的最大版本数，默认是1.换句话说，getColumn() 返回的列表中包括 0 或 1 个条目，这一条目是该列最新版本的值，如果用户指定了一个比默认值 1 大的版本数，返回的列表中就可能会有多个条目。getColumnLatest() 方法返回对应列的最新版本值。containsColumn() 是一个检查返回值中是否有对应的列的方法。</p>
<h3 id="Get-列表"><a href="#Get-列表" class="headerlink" title="Get 列表"></a>Get 列表</h3><p>和 put() 方法对应，用户可以用一次请求获取多行数据。</p>
<pre><code>Result[] get(List&lt;Get&gt; gets) throws IOException
</code></pre><p>和之前一样，用户需要创建一个列表，并把之前准备好的 Get 实例添加到其中。然后将这个列表传给 get()，会返回一个与列表大小相等的 Result 数组。</p>
<h3 id="获取数据的相关方法"><a href="#获取数据的相关方法" class="headerlink" title="获取数据的相关方法"></a>获取数据的相关方法</h3><p>还有一些方法可以用来获取或检查存储的数据，第一个是：</p>
<pre><code>boolean exists(Get get) throws IOException
</code></pre><p>可以和使用 HTable 的 get() 方法一样，先创建一个 Get 类的实例。exists()方法通过 RPC 验证请求的数据是否存在，但不会从远程服务器返回请求的数据，只返回一个布尔指。</p>
<p>用户在检索数据时可能需要查找一个特定的行，或者某个请求行之前的一行。通过使用 <strong>getRowOrBefore(byte[] row, byte[] family)</strong> 方法来实现。可以是从 getRowOrBefore() 返回的 Result 实例中得到要查找的行键。这个行键要么与用户设定的行一致，要么刚好是设定行键之前的一行。如果没有匹配的结果，则返回 null。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/27/Google-Chubby-学习-Paxos-协议实现/" itemprop="url">
                  Google Chubby 学习: Paxos 协议实现
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-27T14:12:31+08:00" content="2016-10-27">
              2016-10-27
            </time>
          </span>

          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/10/27/Google-Chubby-学习-Paxos-协议实现/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/10/27/Google-Chubby-学习-Paxos-协议实现/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/10/27/Google-Chubby-学习-Paxos-协议实现/" class="leancloud_visitors" data-flag-title="Google Chubby 学习: Paxos 协议实现">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Chubby-中-Paxos-协议实现"><a href="#Chubby-中-Paxos-协议实现" class="headerlink" title="Chubby 中 Paxos 协议实现"></a>Chubby 中 Paxos 协议实现</h3><p>Chubby 服务端的基本架构大致分为三层：</p>
<ul>
<li>最底层是容错日志系统，通过 Paxos 算法能够保证集群所有机器上的日志完全一致，同时具备较好的容错性。</li>
<li>日志层上是的 Key - Value 类型的容错数据库，其通过下层的日志来保证一致性和容错性。</li>
<li>存储层之上就是 Chubby 对外提供的分布式锁和小文件存储服务。</li>
</ul>
<p>Paxos 算法的作用在于保证集群内各个副本节点的日志能够保证一致。Chubby 事务日志中的每一个 Value 对应 Paxos 算法中的一个 Instance，由于 Chubby 需要对外提供不间断的服务，因此事务日志会无限增长，于是整个 Chubby 运行过程中，会存在多个 Paxos Instance。同时，Chubby 会为每一个 Paxos Instance 都按序分配一个全局唯一的 Instance 编号，并将其顺序写入到事务日志中去。</p>
<p>在多 Paxos Instance 的模式下，为了提升算法执行的性能，就必须选举一个副本节点作为 Paxos 算法的主节点，以避免因为每一个 Paxos Instance 都提出提案而陷入多个 Paxos Round 并存的情况。同时，Paxos 会保证在 Master 重启或出现故障而进行切换的时候，允许出现短暂的多个 Master 共存却不影响副本之间的一致性。</p>
<p>在 Paxos 中，每一个 Paxos Instance 都需要进行一轮或多轮 “ Prepare -&gt; Promise -&gt; Propose -&gt; Accept “ 这样完整的二阶段请求过程来完成对一个提案值的选定，而多个 Instance 之间是完全独立的，每个 Instance 可以自己决定每一个 Round 的序号，仅仅只需要保证在 Instance 内部不会出现序号重复即可。为了在保证正确性的前提下尽可能地提高算法运行性能，可以让多个 Instance 共用一套序号分配机制，并将 “Prepare -&gt; Promise” 合并为一个阶段，具体做法如下。</p>
<ul>
<li>当某个副本节点通过选举成为 Master 后，就会使用新分配的编号 N 来广播一个 Prepare 消息，该 Prepare 消息会被所有未达成一致的 Instance 和目前还未开始的 Instance 共用。</li>
<li>当 Acceptor 接收到 Prepare 消息后，必须对多个 Instance 同时做出回应，这通常可以通过将反馈信息封装在一个数据包中来实现。假设最多允许 K 个 Instance 同时进行提案值的选定，那么：<ul>
<li>当前至多存在 K 个 未达成一致的 Instance，将这些未决的 Instance 各自最后接受的提案值封装进一个数据包，并作为 Promise 消息返回。</li>
<li>同时，判断 N 是否大于当前 Acceptor 的 highestPromiseNum 值，如果大于该值的话，那么就标记这些未决 Instance 和所有未来的 Instance 的 highestPromisedNum 指为 N — 这样，这些未决 Instance 和所有未来 Instance 都不能再接受任何编号小于 N 的提案。</li>
</ul>
</li>
<li>然后 Master 就可以对所有未决 Instance 和所有未来 Instance 分别执行 “Propose -&gt; Accept” 阶段的处理。如果当前 Master 能够一直稳定运行的话，那么在接下来的算法运行过程中，就不再需要进行 “Prepare -&gt; Promise” 的处理了。但是，一旦 Master 发现 Acceptor 返回了一个 Reject 消息，说明集群中存在另一个 Master，并且试图使用更大的提案编号发送了 Prepare 消息。碰到这种情况，当前 Master 就需要重新分配新的提案编号并再次进行 “Prepare -&gt; Promise” 阶段的逻辑处理。</li>
</ul>
<p>利用上述改进的 Paxos 算法，在 Master 稳定运行的情况下，只需要使用同一个编号来依次执行每一个 Instance 的 “Promise -&gt; Accept” 阶段逻辑处理。在每个 Instance 的运行过程中，一旦接收到多数派的 Accept 反馈后，就可以将对应的提案值写入本地事务日志并广播 COMMIT 消息给集群中的其他副本节点，其他副本节点在接收到这个 COMMIT 消息之后也会将提案值写入到事务日志中去。如果某个副本节点因为宕机或者网络原因没有接收到 COMMIT 消息，可以主动向集群中的其他副本节点进行查询。因此，我们可以看到，在 Chubby 的 Paxos 算法实现中，只要维持集群中存在多数派的机器能够正常运行，即使其他机器在任意时刻发生宕机，也能保证已经提交的提案的安全性。</p>
<h3 id="Hypertable"><a href="#Hypertable" class="headerlink" title="Hypertable"></a>Hypertable</h3><p>Hypertable 以 Google 的 Bigtable 相关论文为基础指导，采用与 HBase 非常相似的分布式模型，其目的是构建一个针对分布式海量数据的高并发数据库。</p>
<p>Hypertable 的核心组件包括 Hyperspace、RangeServer、Master 和 DFS Broker 四部分。其中 Hyperspace 是 Hypertable 中最重要的组件之一，其提供了对分布式锁服务的支持以及对元数据的管理，是保证 Hypertable 数据一致性的核心。Hyperspace 类似于 Chubby，它存储一些元数据信息，同时提供分布式锁服务，另外还负责提供高效、可靠的主机选举服务。</p>
<p>RangeServer 是实际对外提供服务的组件单元，负责数据的读取和写入。在 Hypertable的设计中，对每一张表都按照主键进行切分，形成多个 Range，每个 Range 由一个 RangeServer 负责管理。在 Hypertable 中，通常会部署多个 RangeServer，每个 RangeServer 都负责管理部分数据，由 Master 来负责进行 RangeServer 的集群管理。</p>
<p>Master 是元数据管理中心，管理包括创建表、删除表或是其他表空间变更在内的所有元数据操作，同时负责检测 RangeServer 的工作状态，一旦某一个 RangeServer 宕机或是重启，能够自动进行 Range 的重新分配，从而实现对 RangeServer 集群的管理和负责均衡。</p>
<p>DFS Broker 则是底层分布式文件系统的抽象层，用于衔接上层 Hypertable 和底层文件存储。所有对文件系统的读写操作，都是通过 DFS Broker 来完成的。目前已经可以接入 Hypertable 中的分布式文件系统包括 HDFS、MapR，Ceph 和 KFS。针对任何其他的新文件系统，只需实现一个对应的 DFS Broker，就可以将其快速接入到整个 Hypertable 系统中。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/26/Google-Chubby-学习-基本概念/" itemprop="url">
                  Google Chubby 学习: 基本概念
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-26T15:14:36+08:00" content="2016-10-26">
              2016-10-26
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/分布式系统/" itemprop="url" rel="index">
                    <span itemprop="name">分布式系统</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/10/26/Google-Chubby-学习-基本概念/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/10/26/Google-Chubby-学习-基本概念/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/10/26/Google-Chubby-学习-基本概念/" class="leancloud_visitors" data-flag-title="Google Chubby 学习: 基本概念">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Google Chubby 是一个很有名的分布式锁服务，GFS 和 Big Table 等大型系统都用它解决分布式协作、元数据存储和 Master 选举等一系列与分布式锁服务相关的问题。Chubby 的底层一致性实现就是以 Paxos 算法为基础。</p>
<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>Chubby 是一个面向松耦合分布式系统的锁服务，通常用于为一个由大量小型计算机构成的松耦合分布式系统提供可用的分布式锁服务。一个分布式锁服务的目的是允许它的客户端进程同步彼此的操作，并对当前所处环境的基本状态信息达成一致。针对这个目的，Chubby 提供了粗粒度的分布式锁服务，开发人员不需要使用复杂的同学协议，而是直接调用 Chubby 的锁服务接口即可实现分布式系统中多个进程粗粒度的同步控制，从而保证分布式数据的一致性。</p>
<p>Chubby 的客户端接口设计类似于 Unix 文件系统结构，应用程序通过 Chubby 的客户端接口，不仅能够对 Chubby 服务器上的整个文件进行读写操作，还能够添加对文件节点的锁控制，并且能够订阅 Chubby 服务端发出的一系列文件变动的事件通知。</p>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>Chubby 最典型的应用是 机器中服务器的 Master 选举。例如 GFS 中使用 Chubby 锁服务来实现对 GFS Master 服务器的选举。而在 Bigtable 中，Chubby 同样被用于 Master 选举，并且借助 Chubby，Master 能够非常方便地感知到其所控制的那些服务器。同时，通过 Chubby，Bigtable 的客户端还能够方便地定位到当前 Bigtable 集群的 Master 服务器。此外，在 GFS 和 Bigtable 中，都使用 Chubby 来进行系统运行时元数据的存储。</p>
<h3 id="Chubby-技术架构"><a href="#Chubby-技术架构" class="headerlink" title="Chubby 技术架构"></a>Chubby 技术架构</h3><h4 id="系统结构"><a href="#系统结构" class="headerlink" title="系统结构"></a>系统结构</h4><p>Chubby 的整个系统结构主要由服务端和客户端两部分组成，客户端通过 RPC 调用与服务端进行通信。</p>
<p>一个典型的 Chubby 集群，或称为 Chubby cell，通常由 5 台服务器组成。这些副本服务器采用 Paxos 协议，通过投票的方式来选举产生一个获得过半投票的服务器作为 Master。一旦某台服务器成为了 Master， Chubby 就会保证在一段时间内不会再有其他服务器成为 Master —- 这段时期成为 Master 租期。在运行过程中，Master 服务器会通过不断续租的方式来延长 Master 租期，而如果 Master 服务器出现故障，那么余下的服务器就会进行新一轮的 Master 选举，最终产生新的 Master 服务器，开始新的租期。</p>
<p>集群中的每个服务器都维护这一份服务端数据库的副本，但在实际运行过程中，只有 Master 可以对数据库进行写操作，而其他服务器都是使用 Paxos 协议从 Master 服务器上同步数据库数据的更新。</p>
<p>Chubby 客户端通过向记录有 Chubby 服务端机器列表的 DNS 来请求获取所有的 Chubby 服务器列表，然后逐个发起请求获取所有的 Chubby 服务器列表，然后逐个发起请求询问该服务器是否是 Master。在这个询问过程中，那些非 Master 的服务器，则会将当前 Master 所在的服务器标识反馈给客户端，这样客户端就能够非常快地定位到 Master 服务器了。</p>
<p>一旦客户端定位到 Master 服务器之后，只要该 Master 正常运行，那么客户端就会将所有的请求都发送到该 Master 服务器上。针对写请求，Chubby Master 会采用一致性协议将其广播给集群中所有的副本服务器，并且在过半的服务器接受了该写请求之后，再响应给客户端正确的应答。而对于读请求，则不需要在集群内部进行广播处理，直接由 Master 服务器单独处理即可。</p>
<p>在 Chubby 运行过程中，服务器难免会发生故障，如果当前的 Master 服务器崩溃了，那么集群中的其他服务器会在 Master 租期到期后，重新开始新一轮 Master 选举。而如果是任意一台非 Master 服务器崩溃，那么整个集群是不会停止工作的，这个崩溃的服务器会在恢复之后自动加入 Chubby 集群中。</p>
<p>如果集群中的一个服务器发送崩溃并在几小时后仍然无法恢复正常，那么就需要加入新的机器，并同时更新 DNS 列表。</p>
<h3 id="目录与文件"><a href="#目录与文件" class="headerlink" title="目录与文件"></a>目录与文件</h3><p>Chubby 的数据结构可以看作是一个由文件和目录组成的树，其中每一个节点都可以表示为一个使用斜杠分割的字符串，典型的节点路径如下：</p>
<pre><code>/ls/foo/wombat/pouch
</code></pre><p>其中 ls 是所有 Chubby 节点所共有的前缀，代表着锁服务；foo 则指定了 Chubby 机器的名字；剩余部分 /wombat/pouch 则是一个真正包含业务含义的节点名字，由 Chubby 服务器内部解析并定位到数据节点。</p>
<h3 id="锁与锁序列器"><a href="#锁与锁序列器" class="headerlink" title="锁与锁序列器"></a>锁与锁序列器</h3><p>在分布式系统中，锁是一个非常复杂的问题，由于网络通信的不确定性，导致在分布式系统中锁机制变得非常复杂，消息的延迟或是乱序都有可能会引起锁的失效。一个典型的分布式锁错乱案例是，一个客户端 C1 获取到了互斥锁 L，并且在锁 L 的保护下发出请求 R，但请求 R 迟迟没有到达服务端（可能出现网络延时或反复重发等），这时应用程序会认为该客户端进程已经失败，于是便会为另一个客户端 C2 分配锁 L，然后再重新发起之前的请求 R，并成功地应用到了服务器上。此时，如果客户端 C1 发起的请求 R 经过一波三折也到达了服务端，此时，它可能会在不受任何锁控制的情况下被服务端处理，从而覆盖客户端 C2 的操作，于是导致系统数据出现不一致。解决此类问题的方案主要包括虚拟时间和虚拟同步。</p>
<p>在 Chubby 中，任意一个数据节点都可以充当一个读写锁来使用：一种是单个客户端以排他（写）模式持有这个锁，另一种则是任意数目的客户端以共享（读）模式持有这个锁同时，在 Chubby 的锁机制中需要注意，Chubby 舍弃了严格的强制锁，客户端可以在没有获取任何锁的情况下访问 Chubby 的文件，即，持有锁 F 既不是访问文件 F 的必要条件，也不会阻止其他客户端访问文件 F。</p>
<p>在 Chubby 中，主要采用锁延迟和锁序列两种策略来解决上面我们提到的由于消息延迟和重排序引起的分布式锁问题。其中锁延迟是一种比较简单的策略，使用 Chubby 的应用几乎不需要进行任何的代码修改。具体的，如果一个客户端以正常的方式主动释放了一个锁，那么 Chubby 服务端将会允许其他客户端能够立即获取到该锁。而如果一个锁是因为客户端的异常情况（如客户端无响应）而被释放的话，那么 Chubby 服务器会为该锁保留一定的时间，称之为“锁延迟”，在这段时间内，其他客户端无法获取这个锁。锁延迟措施能够很好地防止一些客户端由于网络闪断等原因而与服务器暂时断开的场景出现。另外一种方式称为锁序列器，当然该策略需要 Chubby 的上层应用配合在代码中加入相应的修改逻辑。任何时候，锁的持有者都可以向 Chubby 请求一个锁序列器，包括锁的名字、锁模式，以及锁序号。当客户端应用程序在进行一些需要锁机制保护的操作时，可以将该锁序列一并发送给服务端。Chubby 服务端接收到这样的请求后，会首先检测该序列器是否有效，以及检查客户端是否处于恰当的锁模式；如果没有通过检查，那么服务端就会拒绝该客户端请求。</p>
<h3 id="Chubby-中的事件通知机制"><a href="#Chubby-中的事件通知机制" class="headerlink" title="Chubby 中的事件通知机制"></a>Chubby 中的事件通知机制</h3><p>为了避免大量客户端轮询 Chubby 服务端状态所带来的压力，Chubby 提供了事件通知机制。Chubby 的客户端可以向服务端注册事件通知，当触发这些事件的时候，服务端就会向客户端发送对应的事件通知。在 Chubby 的事件通知机制中，消息通知都是通过异步的方式发送给客户端的，常用的 Chubby 事件如下：</p>
<h4 id="文件内容变更"><a href="#文件内容变更" class="headerlink" title="文件内容变更"></a>文件内容变更</h4><p>BigTable 集群使用 Chubby 锁来确定集群中的哪台 BigTable 机器是 Master；获得锁的 BigTable Master 会将自身信息写入 Chubby 上对应的文件中。 BigTable机器中的其他客户端可以通过监视这个 Chubby 文件的变化来确定新的 BigTable Master 机器。</p>
<h4 id="节点删除"><a href="#节点删除" class="headerlink" title="节点删除"></a>节点删除</h4><p>当 Chubby 上指定节点被删除的时候，会产生“节点删除”事件，通常是临时节点，可以利用该特性来间接判断该临时节点对应的客户端会话是否有效。</p>
<h4 id="子结点新增、删除"><a href="#子结点新增、删除" class="headerlink" title="子结点新增、删除"></a>子结点新增、删除</h4><p>当 Chubby 上指定节点的子节点新增或是减少时，会产生”子节点新增、删除“事件。</p>
<h4 id="Master-服务器转移"><a href="#Master-服务器转移" class="headerlink" title="Master 服务器转移"></a>Master 服务器转移</h4><p>当 Chubby 服务器发生 Master 转移时，会以事件的形式通知客户端。</p>
<h3 id="Chubby-中的缓存"><a href="#Chubby-中的缓存" class="headerlink" title="Chubby 中的缓存"></a>Chubby 中的缓存</h3><p>为了提高 Chubby 的性能，同时也是为了减少客户端和服务端之间频繁的读请求对服务端的压力，Chubby 除了提供事件通知机制之外，还在客户端中实现了缓存，会在客户端对文件内容和元数据信息进行缓存。使用缓存机制在提高系统整体性能的同时，也为系统带来了一定的复杂性，最大的问题是如何保证缓存的一致性。</p>
<p>Chubby 保证缓存一致性的主要方法是使用了缓存的生命周期这一概念。具体的，每个客户端的缓存都有一个租期，一旦该租期到期，客户端就需要向服务端续订租期以继续维持缓存的有效性。当文件数据或元数据信息被修改时，Chubby服务端首先会阻塞该修改操作，然后由 Master 向所有可能缓存了该数据的客户端发送缓存过期信号，以使其缓存失效，等到 Master 在接收到所有相关客户端针对该过期信号的应答后（1. 客户端明确要求更新缓存；2. 客户端允许缓存租期过期。），再继续进行之前的修改操作。</p>
<h3 id="会话和会话激活"><a href="#会话和会话激活" class="headerlink" title="会话和会话激活"></a>会话和会话激活</h3><p>Chubby 客户端和服务端之间通过创建一个 TCP 连接来进行所有的网络通信操作，我们将这一连接称为会话（Session）。会话有生命周期，并且存在一个超时时间，在超时时间内，Chubby客户端和服务端之间可以通过心跳检测来保持会话的活性。</p>
<h3 id="Chubby-Master-故障恢复"><a href="#Chubby-Master-故障恢复" class="headerlink" title="Chubby Master 故障恢复"></a>Chubby Master 故障恢复</h3><p>Chubby 的 Master 服务器上会运行着会话租期计时器，用来管理所有会话的生命周期。如果在运行过程中 Master 出现了故障，那么该计时器会停止，直到新的 Master 选举产生后，计时器才会继续计时，</p>
<p>新的 Master 会设法将上一个 Master 服务器的内存状态构造出来。具体的，由于本地数据库记录了每个客户端的会话信息，以及其持有的锁和临时文件等信息，因此 Chubby 会通过读取本地磁盘上的数据来恢复一部分状态。总的来讲，一个新的 Chubby Master 服务器选举产生以后会进行如下几个主要处理：</p>
<ol>
<li>新的 Master 选举产生之后，首先需要确定 Master 周期。Master 周期用来唯一标识一个 Chubby 集群的 Master 统治轮次，以便区分不同的 Master。一旦新的 Master 周期确定下来之后，Master 就会拒绝所有携带其他 Master 周期编号的客户端请求，同时告知其最新的 Master 周期编号。</li>
<li>选举产生的新 Master 能够立即对客户端的 Master 寻址请求进行响应，但是不会立即开始处理客户端会话相关的请求操作。</li>
<li>Master 根据本地数据库中存储的会话和锁信息，来构建服务器的内存状态。</li>
<li>到现在为止，Master 已经能够处理客户端的 KeepAlive 请求了，但依然无法处理其他会话相关的操作。</li>
<li>Master 会发生一个”Master 故障切换”事件给每一个会话，客户端接收到这个事件后，会清空它的本地缓存，并警告上层应用程序可能已经丢失了别的事件，之后再向 Master反馈应答。</li>
<li>此时，Master会一致等待客户端的应答，直到每一个会话都应答了这个切换事件。</li>
<li>在 Master 接收到了所有客户端的应答之后，就能够开始处理所有的请求操作。</li>
<li>如果客户端使用了一个在故障切换之前创建的句柄，Master 会重新为其创建这个句柄的内存对象，并执行调用。而如果该句柄在之前的 Master 周期中已经被关闭了，那么它就不能在这个 Master 周期内再次被重建了。这样就确保了即使由于网络原因使得 Master 接收到那些延迟或重发的网络数据包，也不会错误地重建一个已经关闭的句柄。</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/25/Linux常用命令-find-和-ping/" itemprop="url">
                  Linux常用命令: find 和 ping
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-25T19:52:43+08:00" content="2016-10-25">
              2016-10-25
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/10/25/Linux常用命令-find-和-ping/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/10/25/Linux常用命令-find-和-ping/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/10/25/Linux常用命令-find-和-ping/" class="leancloud_visitors" data-flag-title="Linux常用命令: find 和 ping">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="find-命令"><a href="#find-命令" class="headerlink" title="find 命令"></a>find 命令</h3><pre><code>$ find &lt;指定目录&gt; &lt;指定条件&gt; &lt;指定动作&gt;

- &lt;指定目录&gt;: 所要搜索的目录及其所有子目录
- &lt;指定条件&gt;: 所要搜索的文件的特征 (eg: -name -type)
- &lt;指定动作&gt;: 对搜索结果进行特定的处理 (eg: -ls, -print,)
</code></pre><h3 id="locate-命令"><a href="#locate-命令" class="headerlink" title="locate 命令"></a>locate 命令</h3><p>locate 其实相当于 “find -name”，但是要比后者快得多，原因在于它不搜索具体目录，而是搜索一个数据库（/var/lib/locatedb），这个数据库中含有本地所有文件信息。Linux系统自动创建这个数据库，并且每天自动更新一次，<strong>所以使用locate命令查不到最新变动过的文件。</strong></p>
<p>为了避免这种情况，可以在使用locate之前，先使用<strong>updatedb</strong>命令，手动更新数据库。</p>
<pre><code>$ locate /etc/sh
搜索etc目录下所有以sh开头的文件。

$ locate ~/m
搜索用户目录下，所有以 m 开头的文件。

$ locate -i ~/m
搜索用户目录下，所有以 m 开头的文件，同时忽略大小写。
</code></pre><h3 id="whereis-命令"><a href="#whereis-命令" class="headerlink" title="whereis 命令"></a>whereis 命令</h3><p>whereis 命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。</p>
<h3 id="ping-多个-ip"><a href="#ping-多个-ip" class="headerlink" title="ping 多个 ip"></a>ping 多个 ip</h3><p>假设有一个日志文件，里面是每行的记录如下：172.0.0.1 <strong><em>**</em></strong>，也就是每行都有一个ip，例如在一个分布式系统里面，有很多机器的ip，那么我们要知道哪些机器宕机了，那么只需要ping一下这个ip即可，但是我们不能一个一个的ping啊，Linux 有没有什么命令可以解决。</p>
<p>Linux 自带的 ping 命令本身不可以 ping 多个 ip，但可以用 shell 来实现同时 ping 多个 ip。</p>
<ol>
<li><p>建一个空的输出文件 </p>
<pre><code>touch /output.txt 
</code></pre></li>
<li><p>新建一个脚本。</p>
<pre><code>vim ping.sh
</code></pre></li>
<li><p>脚本内容</p>
<pre><code>#!/bin/bash
A = &apos;cat /ip.txt&apos;
for B in $A 
do
ping -c 3 $B &gt;&gt;/output
done
wq
</code></pre></li>
<li><p>执行脚本</p>
<pre><code>./ ping.sh
</code></pre></li>
<li><p>查看结果</p>
<pre><code>cat output.txt
</code></pre></li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/25/分布式系统学习-Paxos算法/" itemprop="url">
                  分布式系统学习: Paxos算法
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-25T13:54:04+08:00" content="2016-10-25">
              2016-10-25
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/分布式系统/" itemprop="url" rel="index">
                    <span itemprop="name">分布式系统</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/10/25/分布式系统学习-Paxos算法/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/10/25/分布式系统学习-Paxos算法/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/10/25/分布式系统学习-Paxos算法/" class="leancloud_visitors" data-flag-title="分布式系统学习: Paxos算法">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在常见的分布式系统中，总会发生诸如机器宕机或网络异常等情况。Paxos 算法需要解决的问题就是如何在一个可能发生上述异常的分布式系统中快速且正确地在集群内部对某个数据的值达成一致，并且保证不会破坏整个系统的一致性。</p>
<h3 id="Paxos-算法详解"><a href="#Paxos-算法详解" class="headerlink" title="Paxos 算法详解"></a>Paxos 算法详解</h3><h4 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h4><p>假设有一组可以提出提案的进程集合，那么对于一个一致性算法来说需要保证以下几点：</p>
<ul>
<li>在这些提出的提案中，只有一个会被选定</li>
<li>如果没有提案被提出，那么就不会有被选定的提案</li>
<li>当一个提案被选定后，进程应该可以获取被选定的提案信息</li>
</ul>
<p>对于一致性来说，安全性需求如下：</p>
<ul>
<li>只有被提出的提案才能被选定</li>
<li>只能有一个值被选定</li>
<li>如果某个进程认为某个提案被选定了，那么这个提案必须是真的被选定的那个</li>
</ul>
<p><strong>从整体上来说，Paxos 算法的目标就是要保证最终有一个提案会被选定，当提案被选定后，进程最终也能获取到被选定的提案。</strong></p>
<p>在该一致性算法中，有三种参与角色，我们用 Proposer、Acceptor 和 Learner 来表示。在具体的实现中，一个进程可能充当不止一种角色。假设不同参与者之间可以通过收发消息来进行通信，那么：</p>
<ul>
<li>每个参与者以任意的速度执行，可能会因为出错而停止，也可能会重启。同时，即使一个提案被选定后，所有的参与者也都有可能失败或重启，因此除非那些失败或重启的参与者可以记录某些信息，否则将无法确定最终的值。</li>
<li>消息在传输过程中可能会出现不可预知的延迟，也可能会重复或丢失，但是消息不会被损坏，即消息内容不会被篡改。</li>
</ul>
<h4 id="提案的选定"><a href="#提案的选定" class="headerlink" title="提案的选定"></a>提案的选定</h4><p>要选定一个唯一提案的最简单方式莫过于只允许一个 Acceptor 存在，这样的话，Proposer 只能发生提案给该 Acceptor，Acceptor 会选择它接收到的第一个提案作为被选定的提案。这种解决方式尽管实现简单，但也存在单点问题，因为一旦这个 Acceptor 出现问题，那么整个系统就无法工作。</p>
<p>在存在多个 Acceptor 的情况下，如何进行提案的选取：Proposer 向一个 Acceptor 集合发送提案，同样，集合中的每个 Acceptor 都可能会批准（Accept）该提案，当有足够多的 Acceptor 批准这个提案的时候，我们就可以认为该提案被选定。</p>
<p>但是，如何去定义“足够多”这个概念，我们假定足够多的 Acceptor 是整个 Acceptor 集合的一个子集，并且让这个集合大得可以包含 Acceptor 集合中的大多数成员，因为任意两个包含大多数 Acceptor 的子集至少有一个公共成员。另外，我们假定每一个 Acceptor 最多只能批准一个提案，那么就能保证只有一个提案被选定了。</p>
<h4 id="推导过程"><a href="#推导过程" class="headerlink" title="推导过程"></a>推导过程</h4><p>在没有失败和消息丢失的情况下，如果我们希望即使在只有一个提案被提出的情况下，仍然可以选出一个提案，这就暗示了如下的需求：</p>
<pre><code>P1：一个 Acceptor 必须批准它收到的第一个提案
</code></pre><p>但是上面这个存在一点问题：如果有多个提案被不同的 Proposer 同时提出，这可能会导致虽然每个 Acceptor 都批准了它收到的第一个提案，但是没有一个提案是由多数人都批准的。</p>
<p>因此，在 P1 的基础上，再加上一个提案被选定需要由半数以上的 Acceptor 批准的需求暗示着一个 Acceptor 必须能够批准不止一个提案。在这里我们使用一个全局的编号（这种全局唯一编号的生成并不是 Paxos算法 需要关注的地方）来唯一标识每一个被 Acceptor 批准的提案，当一个具有某 Value 值的提案被半数以上的 Acceptor 批准后，我们就认为该 Value 被选定了，此时我们也认为该提案被选定了。注意，这里的提案和 Value 不是同一个概念，提案变成了一个由编号和 Value 组成的组合体，因此我们以 “[编号，Value]”来表示一个提案。</p>
<p>根据上面讲到的内容，我们虽然允许多个提案被选定，但同时必须要保证所有被选定的提案都具有相同的 Value 值—这是一个关于提案 Value 的约定，结合提案的编号，该约定可以定义如下：</p>
<pre><code>P2：如果编号为 M0、Value 值为 V0 的提案（即[M0，V0]）被选定了，那么所有比
编号 M0 更高的，且被选定的提案，其 Value 值必须也是 V0。
</code></pre><p>因为提案的编号是全序的，条件 P2 就保证了只有一个 Value 值被选定这一关键安全性属性。同时，一个提案要被选定，其首先必须被至少一个 Acceptor 批准，因此我们可以通过满足如下条件来满足 P2：</p>
<pre><code>P2a：如果编号为M0、Value 值为 V0 的提案（即[M0，V0]）被选定了，那么所有比
编号 M0 更高的，且被 Acceptor 批准的提案，其 Value 值必须也是 V0。
</code></pre><p>但是由于通信是异步的，一个提案可能会在某个 Acceptor 还未收到任何提案时就被选定了，但是 P1 又要求我们必须批准第一个收到的提案，这与 P2a 矛盾，因此如果要同时满足 P1 和 P2a，需要对 P2a 进行如下强化：</p>
<pre><code>P2b：如果一个提案[M0，V0] 被选定之后，那么之后任何 Proposer 产生的编号更高
的提案，其 Value 值都为 V0。
</code></pre><p>因为一个提案必须在被 Proposer 提出后才能被 Acceptor 批准，因此 P2b 包含了 P2a，进而包含了 P2。所以只需要证明 P2b 成立即可：</p>
<pre><code>假设某个提案 [M0，V0] 已经被选定了，证明任何编号 Mn &gt; M0 的提案，其 Value 
值都是 V0。
</code></pre><h4 id="数学归纳法证明"><a href="#数学归纳法证明" class="headerlink" title="数学归纳法证明"></a>数学归纳法证明</h4><p>我们可以通过对 Mn 进行第二数学归纳法来进行证明，即：</p>
<pre><code>假设编号在 M0 到 Mn-1 之间的提案，其 Value 值都是 V0，证明编号为 Mn 的提案
的 Value 值也为 V0。
</code></pre><p>因为编号为 M0 的提案已经被选定了，这就意味着肯定存在一个由半数以上的 Acceptor 组成的集合 C，C 中的每个 Acceptor 都批准了该提案。再结合归纳假设，“编号为 M0 的提案被选定” 意味着：</p>
<pre><code>C 中的每个 Acceptor 都批准了一个编号在 M0 到 Mn-1范围内的提案，并且每个编
号在 M0 到 Mn-1 范围内的被 Acceptor 批准的提案，其 Value 值都是 V0。
</code></pre><p>因为任何包含半数以上的 Acceptor 的集合 S 都至少包含 C 中的一个成员，因此我们可以认为如果保持了下面 P2c 的不变性，那么编号为 Mn 的提案的 Value 也为 V0。</p>
<pre><code>P2c：对于任意的 Mn 和 Vn，如果提案 [Mn，Vn] 被提出，那么肯定存在一个由半数
以上的 Acceptor 组成的集合 S，满足以下两个条件中的任意一个：
    1. S 中不存在任何批准过编号小于 Mn 的提案的 Acceptor
    2. 选取 S 中所有 Acceptor 批准的编号小于 Mn 的提案，其中编号最大的那个
       提案其 Value 值是 Vn
</code></pre><p>至此，只需要通过保持 P2c，我们就能满足 P2b。</p>
<p>从 P1 到 P2c 是对一系列条件的逐步加强，实际上 P2c 规定了每个 Proposer 如何产生一个提案：对于产生的每个提案 [Mn，Vn]，需要满足以下条件：</p>
<pre><code>存在一个由超过半数的 Acceptor 组成的集合 S：
1. 要么 S 中没有 Acceptor 批准过编号小于 Mn 的任何提案
2. 要么 S 中的所有 Acceptor 批准的所有编号小于 Mn 的提案中，编号最大的那个
   提案的Value值为 Vn
</code></pre><p> 当每个 Proposer 都按照这个规则来产生提案时，就可以保证满足 P2b 了， P2c 可以用第二数学归纳法证明，此处省略。</p>
<h4 id="Proposer-生成提案"><a href="#Proposer-生成提案" class="headerlink" title="Proposer 生成提案"></a>Proposer 生成提案</h4><p>对于一个 Proposer 来说，获取那些已经被通过的提案远比预测未来可能会被通过的提案简单。因此，Proposer 在产生一个编号为 Mn 的提案时，必须要知道当前某一个将要或已经被半数以上 Acceptor 批准的编号小于 Mn 但为最大编号的提案。并且，Proposer 会要求所有的 Acceptor 都不要再批准任何编号小于 Mn 的提案—这便是下面的提案生产算法。</p>
<ol>
<li><p>Proposer 选择一个新的提案编号 Mn，然后向某个 Acceptor 集合的成员发送请求，要求该集合中的 Acceptor 作出如下回应。</p>
<ul>
<li>像 Proposer 承诺，保证不再批准任何编号小于 Mn 的提案。</li>
<li><p>如果 Acceptor 已经批准过任何提案，那么其就向 Proposer 反馈当前该 Acceptor 已经批准的编号小于 Mn 但为最大编号的那个提案的值。</p>
<p>我们将该请求称为编号为 Mn 的提案的 Prepare 请求。</p>
</li>
</ul>
</li>
<li><p>如果 Proposer 收到了来自半数以上的 Acceptor 的响应结果，那么它就可以产生编号为 Mn， Value 值为 Vn 的提案，这里的 Vn 是所有响应中编号最大的提案的 Value 值。还有一种情况，就是半数以上的 Acceptor 都没有批准过任何提案，即响应中不包含任何的提案，那么此时 Vn 值就可以由 Proposer 任意选择</p>
</li>
</ol>
<p>在确定提案之后，Proposer 就会将该提案再次发送给某个 Acceptor 集合，并期望获得它们的批准，这称为 Accept 请求。</p>
<h4 id="Paxos-提案选定的整个流程"><a href="#Paxos-提案选定的整个流程" class="headerlink" title="Paxos 提案选定的整个流程"></a>Paxos 提案选定的整个流程</h4><p><strong>阶段一</strong></p>
<ol>
<li><p>Proposer 选择一个提案编号 Mn，然后向 Acceptor 的某个超过半数的子集成员发送编号为 Mn 的 Prepare 请求。</p>
</li>
<li><p>如果一个 Acceptor 收到一个编号为 Mn 的 Prepare 请求， 且编号 Mn 大于该 Acceptor 已经响应的所有 Prepare 请求的编号，那么它就会将它已经批准过的最大编号的提案作为响应反馈给 Proposer，同时该 Acceptor 会承诺不会再批准任何编号小于 Mn 的提案。</p>
</li>
</ol>
<p><strong>阶段二</strong></p>
<ol>
<li><p>如果 Proposer 收到来自半数以上的 Acceptor 对于其发出的编号为 Mn 的 Prepare 请求的响应，那么它就会发送一个针对 [Mn, Vn] 提案的 Accept 请求给 Acceptor。</p>
</li>
<li><p>如果 Acceptor 收到这个针对 [Mn, Vn]提案的 Accept 请求，只要该 Acceptor 尚未对编号大于 Mn 的 Prepare 请求做出响应，它就可以通过这个提案。</p>
</li>
</ol>
<h4 id="提案的获取"><a href="#提案的获取" class="headerlink" title="提案的获取"></a>提案的获取</h4><p>Learner 获取提案，有以下几种方案。</p>
<p><strong>方案一</strong></p>
<p>Learner 获取一个已经被选定的提案的前提是，该提案已经被半数以上的 Acceptor 批准。因此，最简单的做法是一旦 Acceptor 批准了一个提案，就将该提案发送给所有的 Learner。</p>
<p>这种方式需要让每个 Acceptor 与所有的 Learner 逐个进行一次通信，通信的次数至少为二者个数的乘积。</p>
<p><strong>方案二</strong></p>
<p>另一种可行的方案是，我们可以让所有的 Acceptor 将它们对提案的批准情况，统一发给一个特定的 Learner (主 Learner)，我们假定 Learner 之间可以通过消息通信来互相感知提案的选定情况。这样来说，当主 Learner 被通知一个提案已经被选定时，它会负责通知其他的 Learner。</p>
<p>这种方案下，Acceptor 首先会将被批准的提案发送给 Learner，再由其同步给其他 Learner，因此方案二的通信次数较方案一而言，大大减少了，通常只是 Acceptor 和 Learner 的总和。但同时又引入了单点问题，即主 Learner 随时可能故障。</p>
<p><strong>方案三</strong></p>
<p>针对方案二的单点问题，可以将主 Learner 的范围扩大，即 Acceptor 可以将批准的提案发送给一个特定的 Learner 集合，该集合中的每个 Learner 都可以在一个提案被选定后通知所有其他的 Learner。</p>
<h4 id="通过选取主-Proposer-保证算法的活性"><a href="#通过选取主-Proposer-保证算法的活性" class="headerlink" title="通过选取主 Proposer 保证算法的活性"></a>通过选取主 Proposer 保证算法的活性</h4><p>假设存在这样一种极端情况，有两个 Proposer 依次提出了一系列编号递增的议案，但是最终都无法确定，从而陷入死循环。</p>
<p>为了保证 Paxos 算法流程的可持续性，以避免陷入上述提到的“死循环”，就必须选择一个主 Proposer，并规定只有主 Proposer 才能提出议案。这样一来，只要主 Proposer 和过半的 Acceptor 能够正常进行网络通信，那么但凡主 Proposer 提出一个编号更高的提案，该提案最终将会被批准。当然，如果当前有一个编号更高的提案被提出或正在接受批准，那么它会丢弃当前这个编号较小的提案，并最终能够选出一个编号足够大的提案。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>2PC、3PC 和 Paxos都是典型的分布式一致性协议，都从不同方面不同程度地解决了分布式一致性问题。其中二阶段提交协议解决了分布式事务的原子性问题，保证了分布式事务的多个参与者要么执行成功，要么执行失败。但是，二阶段存在一些诸如同步阻塞和无限期等待的问题。三阶段提交协议则是在二阶段的基础上，添加了 PreCommit 过程，从而避免了二阶段提交协议中的无限期等待问题。而 Paxos 算法中引入 “过半” 的理念，同时支持分布式节点角色之间的轮换。从而避免了分布式单点的出现。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="PengShuang" />
          <p class="site-author-name" itemprop="name">PengShuang</p>
          <p class="site-description motion-element" itemprop="description">在路上，慢慢走！</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">68</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">18</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">29</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/pengshuang" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/2176899852/profile?rightmod=1&wvr=6&mod=personnumber&is_all=1" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://lingyu.wang/" title="天镶的博客" target="_blank">天镶的博客</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://coolshell.cn/" title="酷壳" target="_blank">酷壳</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.dongwm.com" title="小明明的博客" target="_blank">小明明的博客</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PengShuang</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

<script>
(function(){
    var bp = document.createElement('script');
    bp.src = '//push.zhanzhang.baidu.com/push.js';
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"pengshuang"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  






  
  

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("DKbLgBme7UkAx9JX6sM3D4Hj-gzGzoHsz", "GXjJ9Ox3pUGI9PJhm6CNfJGN");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

</body>
</html>
