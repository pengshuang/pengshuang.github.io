<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="在路上，慢慢走！">
<meta property="og:type" content="website">
<meta property="og:title" content="小沙文的博客">
<meta property="og:url" content="http://pengshuang.space/page/4/index.html">
<meta property="og:site_name" content="小沙文的博客">
<meta property="og:description" content="在路上，慢慢走！">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="小沙文的博客">
<meta name="twitter:description" content="在路上，慢慢走！">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://pengshuang.space/page/4/"/>

  <title> 小沙文的博客 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">小沙文的博客</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/28/HBase-学习-Delete-和-行锁/" itemprop="url">
                  HBase 学习: Delete、批量处理操作
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-28T15:50:58+08:00" content="2016-10-28">
              2016-10-28
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/HBase/" itemprop="url" rel="index">
                    <span itemprop="name">HBase</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/10/28/HBase-学习-Delete-和-行锁/" class="leancloud_visitors" data-flag-title="HBase 学习: Delete、批量处理操作">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="单行删除"><a href="#单行删除" class="headerlink" title="单行删除"></a>单行删除</h3><p>delete() 方法 </p>
<pre><code>void delete(Delete delete) throws IOException
</code></pre><p>和 get 及 post 方法一样，用户必须先创建一个 Delete 实例，然后再添加想要删除的数据的详细信息。</p>
<p>下面是一个使用 delete() 函数的例子</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable table = new HTable(conf, &quot;test1&quot;);
Delete delete = new Delete(Bytes.toBytes(&quot;row1&quot;));
// 设置时间戳
delete.setTimestamp(1);
// 删除一列中的特定版本
delete.deleteColumn(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), 1);
// 删除一列中的全部版本
delete.deleteColumns(Bytes.toBytes(&quot;colfam2&quot;), Bytes.toBytes(&quot;qual1&quot;));
// 删除一列中的给定版本和所有更旧的版本
delete.deleteColumns(Bytes.toBytes(&quot;colfam2&quot;), Bytes.toBytes(&quot;qual3&quot;),15);
// 删除整个列族,包括所有的列和版本
delete.deleteFamily(Bytes.toBytes(&quot;colfam3&quot;));
// 删除给定列族中的所有列的给定版本和所有更旧的版本
delete.deleteFamily(Bytes.toBytes(&quot;colfam3&quot;), 3);
table.delete(delete);
table.close(); 
</code></pre><h3 id="多行删除"><a href="#多行删除" class="headerlink" title="多行删除"></a>多行删除</h3><p>多行删除和之前博文介绍的多行 Put 很类似，</p>
<pre><code>void delete(List&lt;Delete&gt; deletes) throw IOException
</code></pre><p>这里不再赘述。</p>
<h3 id="批量处理操作"><a href="#批量处理操作" class="headerlink" title="批量处理操作"></a>批量处理操作</h3><p>HBase 中有一些 API 可以批量处理跨多行的不同操作。</p>
<pre><code>void batch(List&lt;Row&gt; actions, Object[] results) throws 
    IOException, InterruptedException
Object[] batch(List&lt;Row&gt; actions) throws
    IOException, InterruptedException
</code></pre><p>上面的 API 提供了批量处理操作。用户可能注意到这里引入了一个新的名为 Row 的类，它是 Put、Get 和 Delete 的祖先，或者是父类。</p>
<p>使用同样的父类允许在列表中实现多态，即放入以上 3 种不同的子类。这种调用跟之前介绍的基于列表的调用方法一样简单易用。下面展示了一个简单的例子。</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable table = new HTable(conf, &quot;test&quot;);

byte[] ROW1 = Bytes.toBytes(&quot;row1&quot;);
byte[] ROW2 = Bytes.toBytes(&quot;row2&quot;);

byte[] COLFAM1 = Bytes.toBytes(&quot;colfam1&quot;);

byte[] QUAL1 = Bytes.toBytes(&quot;qual1&quot;);

List&lt;Row&gt; batch = new ArrayList&lt;Row&gt;();

Put put = new Put(ROW1);
put.add(COLFAM1, QUAL2,Bytes.toBytes(&quot;val5&quot;));
batch.add(put);

Get get1 = new Get(ROW2);
get1.addColumn(COLFAM1,QUAL2);
batch.add(get1);

Delete delete = new Delete(ROW1);
delete.deleteColumns(COLFAM1,QUAL2);
batch.add(delete);

table.batch(batch, results);
</code></pre><p><strong>注意</strong>：不可以将针对同一行的 Put 和 Delete 操作放在同一个批量处理请求中。</p>
<h3 id="行锁"><a href="#行锁" class="headerlink" title="行锁"></a>行锁</h3><p>像 put()、delete()、checkAndPut() 这样的修改操作是独立执行的，这意味着在一个串行方式的执行中，对于每一行必须保证行级别的操作是原子性的。region 服务器提供了一个行锁 (row lock) 的特性，这个特性保证了只有一个客户端能获取一行数据相应的锁，同时对该行进行修改。</p>
<p>处理服务器端隐式加锁之外，客户端也可以显示地对当行数据的多次操作进行加锁，通过以下调用实现：</p>
<pre><code>RowLock lockRow(byte[] row) throws IOException
void unlockRow(RowLock r1) throws IOException
</code></pre><p>第一个调用 lockRow() 需要一个行健作为参数，返回一个 RowLock 的实例，这个实例可以供后续的 Put 或者 Delete 的构造函数使用。一旦不再需要锁时，必须通过 unLockRow() 调用来释放它。</p>
<p>默认的锁超时时间是一分钟，但是可以在 <strong>hbase-site.xml</strong> 文件中添加一下配置项。</p>
<pre><code>&lt;property&gt;
    &lt;name&gt;hbase.regionserver.lease.period&lt;/name&gt;
    &lt;value&gt;1200000&lt;/value&gt;
&lt;property&gt;
</code></pre><p><strong>注意</strong>：Get 方法是不需要锁的。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/27/HBase-学习-Put-和-Get“/" itemprop="url">
                  HBase 学习: Put 和 Get
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-27T19:53:24+08:00" content="2016-10-27">
              2016-10-27
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/HBase/" itemprop="url" rel="index">
                    <span itemprop="name">HBase</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/10/27/HBase-学习-Put-和-Get“/" class="leancloud_visitors" data-flag-title="HBase 学习: Put 和 Get">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="单行-Put"><a href="#单行-Put" class="headerlink" title="单行 Put"></a>单行 Put</h3><pre><code>void put(Put put) throws IOException
</code></pre><p>这个方法以单个 Put 或存储在列表中的一组 Put 对象作为输入参数。</p>
<p>创建 Put 实例时用户需要提供一个行健 row，在 HBase 中每行数据都有唯一的行健作为标识，跟 HBase 的大多数数据类型一样，它是一个 Java 的 byte[] 数组。用户可以按自己的需求来指定每行的行健。</p>
<p>下面是一个简单的 HBase 插入数据的实例应用。</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable table = new HTable(conf, &quot;test1&quot;);
//指定一行来创建一个 Put
Put put = new Put(Bytes.toBytes(&quot;row1&quot;));
//向 Put 中添加一个名为 &quot;colfam1:qual1&quot; 的列
put.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), 
Bytes.toBytes(&quot;val1&quot;));
//将这一行存储到 HBase 表中
table.put(put);
// 关闭表
table.close();
</code></pre><h3 id="客户端的写缓存区"><a href="#客户端的写缓存区" class="headerlink" title="客户端的写缓存区"></a>客户端的写缓存区</h3><p>每一个put操作实际上都是一个 RPC 操作，它将客户端数据传送到服务器然后返回。这只适合小数据量的操作，如果有个应用程序需要每秒存储上千行数据到 HBase 表中，就不太合适，</p>
<p>HBase 的 api 配备了一个客户端的写缓冲区，缓冲区负责收集 put 操作，然后调用 RPC 操作一次性将 put 送往服务器。全局交换机控制着该缓冲区是否在使用。默认情况下，客户端缓冲区是禁用的。可以通过将 自动刷写（autoflush）设置为 false 来激活缓冲区。</p>
<p>下面举一个客户端写缓冲区的例子，这样比较好理解一些：</p>
<p>Configuration conf = HBaseConfiguration.create();</p>
<pre><code>HTable table = new HTable(conf, &quot;test1&quot;);
//检查自动刷写标识位的设置
System.out.println(&quot;Auto flush: &quot; + table.isAutoFlush());
//将一些行和列数据存入 HBase
table.setAutoFlushTo(false);

Put put1 = new Put(Bytes.toBytes(&quot;row1&quot;));
put1.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), Bytes.toBytes(&quot;val1&quot;));
table.put(put1);

Put put2 = new Put(Bytes.toBytes(&quot;row2&quot;));
put2.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), Bytes.toBytes(&quot;val2&quot;));
table.put(put2);

Get get = new Get(Bytes.toBytes(&quot;row1&quot;));
//试图加载先前存储的行,结果会打印出 &quot; Restful: keyvalues=NONE &quot;
Result res1 = table.get(get);
System.out.println(&quot;Result: &quot; + res1);
// 强制刷写缓冲区,会导致产生一个 RPC 请求
table.flushCommits();
// 现在,这一行被持久化了,可以被读取了
Result res2 = table.get(get);
System.out.println(&quot;Result: &quot; + res2);
</code></pre><h3 id="Put-列表"><a href="#Put-列表" class="headerlink" title="Put 列表"></a>Put 列表</h3><p>客户端的 api 可以插入单个 Put 实例，同时也有批量处理操作的高级特性。请看下面的例子：</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable table = new HTable(conf, &quot;test1&quot;);

List&lt;Put&gt; puts = new ArrayList&lt;Put&gt;();

Put put1 = new Put(Bytes.toBytes(&quot;row1&quot;));
put1.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), Bytes.toBytes(&quot;val1&quot;));
puts.add(put1);

Put put2 = new Put(Bytes.toBytes(&quot;row2&quot;));
put2.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual2&quot;), Bytes.toBytes(&quot;val2&quot;));
puts.add(put2);

table.put(puts);
</code></pre><p> 上面这个例子使用列表向 HBase 中添加数据。当使用基于列表的 put 调用时，用户需要特别注意：用户无法控制服务器执行 put 的顺序，这意味着服务器被调用的顺序也不受用户控制。如果要保证写入的顺序，需要小心地使用这个操作，最坏的情况，要减少每一批量的操作数，并显示地刷写客户端写缓冲区，强制把操作发送到远程服务器。</p>
<h3 id="原子性操作-compare-and-set"><a href="#原子性操作-compare-and-set" class="headerlink" title="原子性操作 compare-and-set"></a>原子性操作 compare-and-set</h3><p>有一种特别的 put 调用，其能保证自身操作的原子性：检查写。有了这种带有检查功能的方法，就能保证服务器端 put 操作的原子性。如果检查成功通过，就执行 put 操作，否则就彻底放弃修改操作。这种方法可用来检查现有相关值，并决定是否修改数据的操作。</p>
<pre><code>boolean checkAndPut(Byte[] row, byte[] family, byte[] qualifier, 
    byte[] value, Put put) throws IOException
</code></pre><p>这种有原子性保证的操作经常被用于账户结余、状态转换或数据处理等场景。这些应用场景的共同点是，在读取数据的同时需要处理数据。一旦你想把一个处理好的结果写回 HBase，并保证没有其他客户端已经做了同样的事情，你就可以使用这个有原子性保证的操作，先比较原值，再做修改。</p>
<p>有一种特别的检查通过 <strong>checkAndPut()</strong> 调用来完成，即只有在另外一个值不存在的情况下，才执行这个修改。要执行这种操作只需要将参数 value 设置为 <strong>null</strong> 即可，只要指定列不存在，就可以成功执行修改操作。</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable table = new HTable(conf, &quot;test1&quot;);

Put put1 = new Put(Bytes.toBytes(&quot;row1&quot;));
put1.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;), Bytes.toBytes(&quot;val1&quot;));
//检查指定列是否存在,按检查的结果决定是否执行 put 操作
boolean res1 = table.checkAndPut(Bytes.toBytes(&quot;row1&quot;),
        Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;),null,put1);
//输出结果应为: &quot;Put applied: true&quot;
System.out.println(&quot;Put applied: &quot; + res1);
//再次向同一单元格写入数据
boolean res2 = table.checkAndPut(Bytes.toBytes(&quot;row1&quot;),
        Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;),null,put1);
//因为那个列的值已经存在,此时的输出结果应为 &quot;Put applied:false&quot;
System.out.println(&quot;Put applied: &quot; + res2);

Put put2 = new Put(Bytes.toBytes(&quot;row1&quot;));
//创建一个新的 Put 实例,这次使用一个不同的列限定符
put2.add(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual2&quot;), Bytes.toBytes(&quot;val2&quot;));
//当上一次的put值存在时,写入新的值
boolean res3 = table.checkAndPut(Bytes.toBytes(&quot;row1&quot;),
        Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;),Bytes.toBytes(&quot;val1&quot;),put2);
//因为已经存在,所以输出的结果应当为 &quot;Put applied: true&quot;
System.out.println(&quot;Put applied: &quot; + res3);
</code></pre><h3 id="单行-Get"><a href="#单行-Get" class="headerlink" title="单行 Get"></a>单行 Get</h3><p>get 方法分为两类：一类是一次获取一行数据；另一类是一次获取多行数据。</p>
<p>与 Put 操作一样。用户有许多方法可用，可用通过多种标准筛选目标数据，也可以指定精确的坐标获取某个单元格的数据:</p>
<pre><code>Get addFamily(byte[] family)
Get addColumn(bytep[] family, byte[] qualifier)
Get setTimeRange(long minStamp,long maxStamp) throws IOException
Get setTimeStamp(long timeStamp)
Get getMaxVersions() 
Get setMaxVersions(int maxVersions) throws IOException
</code></pre><p>下面一个例子展示了从 HBase 中获取数据的整个过程</p>
<pre><code>Configuration conf = HBaseConfiguration.create();
HTable table = new HTable(conf, &quot;test1&quot;);
// 使用一个指定的行健构建一个 Get 实例
Get get = new Get(Bytes.toBytes(&quot;row1&quot;));
// 向 Get 实例中添加一个列
get.addColumn(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;));
// 从 HBase 中获取指定列的行数据
Result result = table.get(get);
// 从返回的结果中获取对应列的数据
byte[] val = result.getValue(Bytes.toBytes(&quot;colfam1&quot;), Bytes.toBytes(&quot;qual1&quot;));
// 将数据转换为字符串打印输出
System.out.println(&quot;Value: &quot; + Bytes.toString(val));
</code></pre><p>get 方法调用后返回一个 Result 类的实例。这里着重介绍一下 Restful 类一些面向列的存取函数：</p>
<pre><code>List&lt;KeyValue&gt; getColumn(byte[] family, byte[] qualifier);
KeyValue getColumnLatest(byte[] family, byte[] qualifier);
boolean containsColumn(byte[] family, byte[] qualifier);
</code></pre><p>这个方法返回一个特定列的多个值，返回值中的版本数取决于用户调用 get()方法之前，创建 Get 实例时设置的最大版本数，默认是1.换句话说，getColumn() 返回的列表中包括 0 或 1 个条目，这一条目是该列最新版本的值，如果用户指定了一个比默认值 1 大的版本数，返回的列表中就可能会有多个条目。getColumnLatest() 方法返回对应列的最新版本值。containsColumn() 是一个检查返回值中是否有对应的列的方法。</p>
<h3 id="Get-列表"><a href="#Get-列表" class="headerlink" title="Get 列表"></a>Get 列表</h3><p>和 put() 方法对应，用户可以用一次请求获取多行数据。</p>
<pre><code>Result[] get(List&lt;Get&gt; gets) throws IOException
</code></pre><p>和之前一样，用户需要创建一个列表，并把之前准备好的 Get 实例添加到其中。然后将这个列表传给 get()，会返回一个与列表大小相等的 Result 数组。</p>
<h3 id="获取数据的相关方法"><a href="#获取数据的相关方法" class="headerlink" title="获取数据的相关方法"></a>获取数据的相关方法</h3><p>还有一些方法可以用来获取或检查存储的数据，第一个是：</p>
<pre><code>boolean exists(Get get) throws IOException
</code></pre><p>可以和使用 HTable 的 get() 方法一样，先创建一个 Get 类的实例。exists()方法通过 RPC 验证请求的数据是否存在，但不会从远程服务器返回请求的数据，只返回一个布尔指。</p>
<p>用户在检索数据时可能需要查找一个特定的行，或者某个请求行之前的一行。通过使用 <strong>getRowOrBefore(byte[] row, byte[] family)</strong> 方法来实现。可以是从 getRowOrBefore() 返回的 Result 实例中得到要查找的行键。这个行键要么与用户设定的行一致，要么刚好是设定行键之前的一行。如果没有匹配的结果，则返回 null。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/27/Google-Chubby-学习-Paxos-协议实现/" itemprop="url">
                  Google Chubby 学习: Paxos 协议实现
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-27T14:12:31+08:00" content="2016-10-27">
              2016-10-27
            </time>
          </span>

          

          
            
          

          

          
          
             <span id="/2016/10/27/Google-Chubby-学习-Paxos-协议实现/" class="leancloud_visitors" data-flag-title="Google Chubby 学习: Paxos 协议实现">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Chubby-中-Paxos-协议实现"><a href="#Chubby-中-Paxos-协议实现" class="headerlink" title="Chubby 中 Paxos 协议实现"></a>Chubby 中 Paxos 协议实现</h3><p>Chubby 服务端的基本架构大致分为三层：</p>
<ul>
<li>最底层是容错日志系统，通过 Paxos 算法能够保证集群所有机器上的日志完全一致，同时具备较好的容错性。</li>
<li>日志层上是的 Key - Value 类型的容错数据库，其通过下层的日志来保证一致性和容错性。</li>
<li>存储层之上就是 Chubby 对外提供的分布式锁和小文件存储服务。</li>
</ul>
<p>Paxos 算法的作用在于保证集群内各个副本节点的日志能够保证一致。Chubby 事务日志中的每一个 Value 对应 Paxos 算法中的一个 Instance，由于 Chubby 需要对外提供不间断的服务，因此事务日志会无限增长，于是整个 Chubby 运行过程中，会存在多个 Paxos Instance。同时，Chubby 会为每一个 Paxos Instance 都按序分配一个全局唯一的 Instance 编号，并将其顺序写入到事务日志中去。</p>
<p>在多 Paxos Instance 的模式下，为了提升算法执行的性能，就必须选举一个副本节点作为 Paxos 算法的主节点，以避免因为每一个 Paxos Instance 都提出提案而陷入多个 Paxos Round 并存的情况。同时，Paxos 会保证在 Master 重启或出现故障而进行切换的时候，允许出现短暂的多个 Master 共存却不影响副本之间的一致性。</p>
<p>在 Paxos 中，每一个 Paxos Instance 都需要进行一轮或多轮 “ Prepare -&gt; Promise -&gt; Propose -&gt; Accept “ 这样完整的二阶段请求过程来完成对一个提案值的选定，而多个 Instance 之间是完全独立的，每个 Instance 可以自己决定每一个 Round 的序号，仅仅只需要保证在 Instance 内部不会出现序号重复即可。为了在保证正确性的前提下尽可能地提高算法运行性能，可以让多个 Instance 共用一套序号分配机制，并将 “Prepare -&gt; Promise” 合并为一个阶段，具体做法如下。</p>
<ul>
<li>当某个副本节点通过选举成为 Master 后，就会使用新分配的编号 N 来广播一个 Prepare 消息，该 Prepare 消息会被所有未达成一致的 Instance 和目前还未开始的 Instance 共用。</li>
<li>当 Acceptor 接收到 Prepare 消息后，必须对多个 Instance 同时做出回应，这通常可以通过将反馈信息封装在一个数据包中来实现。假设最多允许 K 个 Instance 同时进行提案值的选定，那么：<ul>
<li>当前至多存在 K 个 未达成一致的 Instance，将这些未决的 Instance 各自最后接受的提案值封装进一个数据包，并作为 Promise 消息返回。</li>
<li>同时，判断 N 是否大于当前 Acceptor 的 highestPromiseNum 值，如果大于该值的话，那么就标记这些未决 Instance 和所有未来的 Instance 的 highestPromisedNum 指为 N — 这样，这些未决 Instance 和所有未来 Instance 都不能再接受任何编号小于 N 的提案。</li>
</ul>
</li>
<li>然后 Master 就可以对所有未决 Instance 和所有未来 Instance 分别执行 “Propose -&gt; Accept” 阶段的处理。如果当前 Master 能够一直稳定运行的话，那么在接下来的算法运行过程中，就不再需要进行 “Prepare -&gt; Promise” 的处理了。但是，一旦 Master 发现 Acceptor 返回了一个 Reject 消息，说明集群中存在另一个 Master，并且试图使用更大的提案编号发送了 Prepare 消息。碰到这种情况，当前 Master 就需要重新分配新的提案编号并再次进行 “Prepare -&gt; Promise” 阶段的逻辑处理。</li>
</ul>
<p>利用上述改进的 Paxos 算法，在 Master 稳定运行的情况下，只需要使用同一个编号来依次执行每一个 Instance 的 “Promise -&gt; Accept” 阶段逻辑处理。在每个 Instance 的运行过程中，一旦接收到多数派的 Accept 反馈后，就可以将对应的提案值写入本地事务日志并广播 COMMIT 消息给集群中的其他副本节点，其他副本节点在接收到这个 COMMIT 消息之后也会将提案值写入到事务日志中去。如果某个副本节点因为宕机或者网络原因没有接收到 COMMIT 消息，可以主动向集群中的其他副本节点进行查询。因此，我们可以看到，在 Chubby 的 Paxos 算法实现中，只要维持集群中存在多数派的机器能够正常运行，即使其他机器在任意时刻发生宕机，也能保证已经提交的提案的安全性。</p>
<h3 id="Hypertable"><a href="#Hypertable" class="headerlink" title="Hypertable"></a>Hypertable</h3><p>Hypertable 以 Google 的 Bigtable 相关论文为基础指导，采用与 HBase 非常相似的分布式模型，其目的是构建一个针对分布式海量数据的高并发数据库。</p>
<p>Hypertable 的核心组件包括 Hyperspace、RangeServer、Master 和 DFS Broker 四部分。其中 Hyperspace 是 Hypertable 中最重要的组件之一，其提供了对分布式锁服务的支持以及对元数据的管理，是保证 Hypertable 数据一致性的核心。Hyperspace 类似于 Chubby，它存储一些元数据信息，同时提供分布式锁服务，另外还负责提供高效、可靠的主机选举服务。</p>
<p>RangeServer 是实际对外提供服务的组件单元，负责数据的读取和写入。在 Hypertable的设计中，对每一张表都按照主键进行切分，形成多个 Range，每个 Range 由一个 RangeServer 负责管理。在 Hypertable 中，通常会部署多个 RangeServer，每个 RangeServer 都负责管理部分数据，由 Master 来负责进行 RangeServer 的集群管理。</p>
<p>Master 是元数据管理中心，管理包括创建表、删除表或是其他表空间变更在内的所有元数据操作，同时负责检测 RangeServer 的工作状态，一旦某一个 RangeServer 宕机或是重启，能够自动进行 Range 的重新分配，从而实现对 RangeServer 集群的管理和负责均衡。</p>
<p>DFS Broker 则是底层分布式文件系统的抽象层，用于衔接上层 Hypertable 和底层文件存储。所有对文件系统的读写操作，都是通过 DFS Broker 来完成的。目前已经可以接入 Hypertable 中的分布式文件系统包括 HDFS、MapR，Ceph 和 KFS。针对任何其他的新文件系统，只需实现一个对应的 DFS Broker，就可以将其快速接入到整个 Hypertable 系统中。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/26/Google-Chubby-学习-基本概念/" itemprop="url">
                  Google Chubby 学习: 基本概念
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-26T15:14:36+08:00" content="2016-10-26">
              2016-10-26
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/分布式系统/" itemprop="url" rel="index">
                    <span itemprop="name">分布式系统</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/10/26/Google-Chubby-学习-基本概念/" class="leancloud_visitors" data-flag-title="Google Chubby 学习: 基本概念">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Google Chubby 是一个很有名的分布式锁服务，GFS 和 Big Table 等大型系统都用它解决分布式协作、元数据存储和 Master 选举等一系列与分布式锁服务相关的问题。Chubby 的底层一致性实现就是以 Paxos 算法为基础。</p>
<h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>Chubby 是一个面向松耦合分布式系统的锁服务，通常用于为一个由大量小型计算机构成的松耦合分布式系统提供可用的分布式锁服务。一个分布式锁服务的目的是允许它的客户端进程同步彼此的操作，并对当前所处环境的基本状态信息达成一致。针对这个目的，Chubby 提供了粗粒度的分布式锁服务，开发人员不需要使用复杂的同学协议，而是直接调用 Chubby 的锁服务接口即可实现分布式系统中多个进程粗粒度的同步控制，从而保证分布式数据的一致性。</p>
<p>Chubby 的客户端接口设计类似于 Unix 文件系统结构，应用程序通过 Chubby 的客户端接口，不仅能够对 Chubby 服务器上的整个文件进行读写操作，还能够添加对文件节点的锁控制，并且能够订阅 Chubby 服务端发出的一系列文件变动的事件通知。</p>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>Chubby 最典型的应用是 机器中服务器的 Master 选举。例如 GFS 中使用 Chubby 锁服务来实现对 GFS Master 服务器的选举。而在 Bigtable 中，Chubby 同样被用于 Master 选举，并且借助 Chubby，Master 能够非常方便地感知到其所控制的那些服务器。同时，通过 Chubby，Bigtable 的客户端还能够方便地定位到当前 Bigtable 集群的 Master 服务器。此外，在 GFS 和 Bigtable 中，都使用 Chubby 来进行系统运行时元数据的存储。</p>
<h3 id="Chubby-技术架构"><a href="#Chubby-技术架构" class="headerlink" title="Chubby 技术架构"></a>Chubby 技术架构</h3><h4 id="系统结构"><a href="#系统结构" class="headerlink" title="系统结构"></a>系统结构</h4><p>Chubby 的整个系统结构主要由服务端和客户端两部分组成，客户端通过 RPC 调用与服务端进行通信。</p>
<p>一个典型的 Chubby 集群，或称为 Chubby cell，通常由 5 台服务器组成。这些副本服务器采用 Paxos 协议，通过投票的方式来选举产生一个获得过半投票的服务器作为 Master。一旦某台服务器成为了 Master， Chubby 就会保证在一段时间内不会再有其他服务器成为 Master —- 这段时期成为 Master 租期。在运行过程中，Master 服务器会通过不断续租的方式来延长 Master 租期，而如果 Master 服务器出现故障，那么余下的服务器就会进行新一轮的 Master 选举，最终产生新的 Master 服务器，开始新的租期。</p>
<p>集群中的每个服务器都维护这一份服务端数据库的副本，但在实际运行过程中，只有 Master 可以对数据库进行写操作，而其他服务器都是使用 Paxos 协议从 Master 服务器上同步数据库数据的更新。</p>
<p>Chubby 客户端通过向记录有 Chubby 服务端机器列表的 DNS 来请求获取所有的 Chubby 服务器列表，然后逐个发起请求获取所有的 Chubby 服务器列表，然后逐个发起请求询问该服务器是否是 Master。在这个询问过程中，那些非 Master 的服务器，则会将当前 Master 所在的服务器标识反馈给客户端，这样客户端就能够非常快地定位到 Master 服务器了。</p>
<p>一旦客户端定位到 Master 服务器之后，只要该 Master 正常运行，那么客户端就会将所有的请求都发送到该 Master 服务器上。针对写请求，Chubby Master 会采用一致性协议将其广播给集群中所有的副本服务器，并且在过半的服务器接受了该写请求之后，再响应给客户端正确的应答。而对于读请求，则不需要在集群内部进行广播处理，直接由 Master 服务器单独处理即可。</p>
<p>在 Chubby 运行过程中，服务器难免会发生故障，如果当前的 Master 服务器崩溃了，那么集群中的其他服务器会在 Master 租期到期后，重新开始新一轮 Master 选举。而如果是任意一台非 Master 服务器崩溃，那么整个集群是不会停止工作的，这个崩溃的服务器会在恢复之后自动加入 Chubby 集群中。</p>
<p>如果集群中的一个服务器发送崩溃并在几小时后仍然无法恢复正常，那么就需要加入新的机器，并同时更新 DNS 列表。</p>
<h3 id="目录与文件"><a href="#目录与文件" class="headerlink" title="目录与文件"></a>目录与文件</h3><p>Chubby 的数据结构可以看作是一个由文件和目录组成的树，其中每一个节点都可以表示为一个使用斜杠分割的字符串，典型的节点路径如下：</p>
<pre><code>/ls/foo/wombat/pouch
</code></pre><p>其中 ls 是所有 Chubby 节点所共有的前缀，代表着锁服务；foo 则指定了 Chubby 机器的名字；剩余部分 /wombat/pouch 则是一个真正包含业务含义的节点名字，由 Chubby 服务器内部解析并定位到数据节点。</p>
<h3 id="锁与锁序列器"><a href="#锁与锁序列器" class="headerlink" title="锁与锁序列器"></a>锁与锁序列器</h3><p>在分布式系统中，锁是一个非常复杂的问题，由于网络通信的不确定性，导致在分布式系统中锁机制变得非常复杂，消息的延迟或是乱序都有可能会引起锁的失效。一个典型的分布式锁错乱案例是，一个客户端 C1 获取到了互斥锁 L，并且在锁 L 的保护下发出请求 R，但请求 R 迟迟没有到达服务端（可能出现网络延时或反复重发等），这时应用程序会认为该客户端进程已经失败，于是便会为另一个客户端 C2 分配锁 L，然后再重新发起之前的请求 R，并成功地应用到了服务器上。此时，如果客户端 C1 发起的请求 R 经过一波三折也到达了服务端，此时，它可能会在不受任何锁控制的情况下被服务端处理，从而覆盖客户端 C2 的操作，于是导致系统数据出现不一致。解决此类问题的方案主要包括虚拟时间和虚拟同步。</p>
<p>在 Chubby 中，任意一个数据节点都可以充当一个读写锁来使用：一种是单个客户端以排他（写）模式持有这个锁，另一种则是任意数目的客户端以共享（读）模式持有这个锁同时，在 Chubby 的锁机制中需要注意，Chubby 舍弃了严格的强制锁，客户端可以在没有获取任何锁的情况下访问 Chubby 的文件，即，持有锁 F 既不是访问文件 F 的必要条件，也不会阻止其他客户端访问文件 F。</p>
<p>在 Chubby 中，主要采用锁延迟和锁序列两种策略来解决上面我们提到的由于消息延迟和重排序引起的分布式锁问题。其中锁延迟是一种比较简单的策略，使用 Chubby 的应用几乎不需要进行任何的代码修改。具体的，如果一个客户端以正常的方式主动释放了一个锁，那么 Chubby 服务端将会允许其他客户端能够立即获取到该锁。而如果一个锁是因为客户端的异常情况（如客户端无响应）而被释放的话，那么 Chubby 服务器会为该锁保留一定的时间，称之为“锁延迟”，在这段时间内，其他客户端无法获取这个锁。锁延迟措施能够很好地防止一些客户端由于网络闪断等原因而与服务器暂时断开的场景出现。另外一种方式称为锁序列器，当然该策略需要 Chubby 的上层应用配合在代码中加入相应的修改逻辑。任何时候，锁的持有者都可以向 Chubby 请求一个锁序列器，包括锁的名字、锁模式，以及锁序号。当客户端应用程序在进行一些需要锁机制保护的操作时，可以将该锁序列一并发送给服务端。Chubby 服务端接收到这样的请求后，会首先检测该序列器是否有效，以及检查客户端是否处于恰当的锁模式；如果没有通过检查，那么服务端就会拒绝该客户端请求。</p>
<h3 id="Chubby-中的事件通知机制"><a href="#Chubby-中的事件通知机制" class="headerlink" title="Chubby 中的事件通知机制"></a>Chubby 中的事件通知机制</h3><p>为了避免大量客户端轮询 Chubby 服务端状态所带来的压力，Chubby 提供了事件通知机制。Chubby 的客户端可以向服务端注册事件通知，当触发这些事件的时候，服务端就会向客户端发送对应的事件通知。在 Chubby 的事件通知机制中，消息通知都是通过异步的方式发送给客户端的，常用的 Chubby 事件如下：</p>
<h4 id="文件内容变更"><a href="#文件内容变更" class="headerlink" title="文件内容变更"></a>文件内容变更</h4><p>BigTable 集群使用 Chubby 锁来确定集群中的哪台 BigTable 机器是 Master；获得锁的 BigTable Master 会将自身信息写入 Chubby 上对应的文件中。 BigTable机器中的其他客户端可以通过监视这个 Chubby 文件的变化来确定新的 BigTable Master 机器。</p>
<h4 id="节点删除"><a href="#节点删除" class="headerlink" title="节点删除"></a>节点删除</h4><p>当 Chubby 上指定节点被删除的时候，会产生“节点删除”事件，通常是临时节点，可以利用该特性来间接判断该临时节点对应的客户端会话是否有效。</p>
<h4 id="子结点新增、删除"><a href="#子结点新增、删除" class="headerlink" title="子结点新增、删除"></a>子结点新增、删除</h4><p>当 Chubby 上指定节点的子节点新增或是减少时，会产生”子节点新增、删除“事件。</p>
<h4 id="Master-服务器转移"><a href="#Master-服务器转移" class="headerlink" title="Master 服务器转移"></a>Master 服务器转移</h4><p>当 Chubby 服务器发生 Master 转移时，会以事件的形式通知客户端。</p>
<h3 id="Chubby-中的缓存"><a href="#Chubby-中的缓存" class="headerlink" title="Chubby 中的缓存"></a>Chubby 中的缓存</h3><p>为了提高 Chubby 的性能，同时也是为了减少客户端和服务端之间频繁的读请求对服务端的压力，Chubby 除了提供事件通知机制之外，还在客户端中实现了缓存，会在客户端对文件内容和元数据信息进行缓存。使用缓存机制在提高系统整体性能的同时，也为系统带来了一定的复杂性，最大的问题是如何保证缓存的一致性。</p>
<p>Chubby 保证缓存一致性的主要方法是使用了缓存的生命周期这一概念。具体的，每个客户端的缓存都有一个租期，一旦该租期到期，客户端就需要向服务端续订租期以继续维持缓存的有效性。当文件数据或元数据信息被修改时，Chubby服务端首先会阻塞该修改操作，然后由 Master 向所有可能缓存了该数据的客户端发送缓存过期信号，以使其缓存失效，等到 Master 在接收到所有相关客户端针对该过期信号的应答后（1. 客户端明确要求更新缓存；2. 客户端允许缓存租期过期。），再继续进行之前的修改操作。</p>
<h3 id="会话和会话激活"><a href="#会话和会话激活" class="headerlink" title="会话和会话激活"></a>会话和会话激活</h3><p>Chubby 客户端和服务端之间通过创建一个 TCP 连接来进行所有的网络通信操作，我们将这一连接称为会话（Session）。会话有生命周期，并且存在一个超时时间，在超时时间内，Chubby客户端和服务端之间可以通过心跳检测来保持会话的活性。</p>
<h3 id="Chubby-Master-故障恢复"><a href="#Chubby-Master-故障恢复" class="headerlink" title="Chubby Master 故障恢复"></a>Chubby Master 故障恢复</h3><p>Chubby 的 Master 服务器上会运行着会话租期计时器，用来管理所有会话的生命周期。如果在运行过程中 Master 出现了故障，那么该计时器会停止，直到新的 Master 选举产生后，计时器才会继续计时，</p>
<p>新的 Master 会设法将上一个 Master 服务器的内存状态构造出来。具体的，由于本地数据库记录了每个客户端的会话信息，以及其持有的锁和临时文件等信息，因此 Chubby 会通过读取本地磁盘上的数据来恢复一部分状态。总的来讲，一个新的 Chubby Master 服务器选举产生以后会进行如下几个主要处理：</p>
<ol>
<li>新的 Master 选举产生之后，首先需要确定 Master 周期。Master 周期用来唯一标识一个 Chubby 集群的 Master 统治轮次，以便区分不同的 Master。一旦新的 Master 周期确定下来之后，Master 就会拒绝所有携带其他 Master 周期编号的客户端请求，同时告知其最新的 Master 周期编号。</li>
<li>选举产生的新 Master 能够立即对客户端的 Master 寻址请求进行响应，但是不会立即开始处理客户端会话相关的请求操作。</li>
<li>Master 根据本地数据库中存储的会话和锁信息，来构建服务器的内存状态。</li>
<li>到现在为止，Master 已经能够处理客户端的 KeepAlive 请求了，但依然无法处理其他会话相关的操作。</li>
<li>Master 会发生一个”Master 故障切换”事件给每一个会话，客户端接收到这个事件后，会清空它的本地缓存，并警告上层应用程序可能已经丢失了别的事件，之后再向 Master反馈应答。</li>
<li>此时，Master会一致等待客户端的应答，直到每一个会话都应答了这个切换事件。</li>
<li>在 Master 接收到了所有客户端的应答之后，就能够开始处理所有的请求操作。</li>
<li>如果客户端使用了一个在故障切换之前创建的句柄，Master 会重新为其创建这个句柄的内存对象，并执行调用。而如果该句柄在之前的 Master 周期中已经被关闭了，那么它就不能在这个 Master 周期内再次被重建了。这样就确保了即使由于网络原因使得 Master 接收到那些延迟或重发的网络数据包，也不会错误地重建一个已经关闭的句柄。</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/25/Linux常用命令-find-和-ping/" itemprop="url">
                  Linux常用命令: find 和 ping
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-25T19:52:43+08:00" content="2016-10-25">
              2016-10-25
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/10/25/Linux常用命令-find-和-ping/" class="leancloud_visitors" data-flag-title="Linux常用命令: find 和 ping">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="find-命令"><a href="#find-命令" class="headerlink" title="find 命令"></a>find 命令</h3><pre><code>$ find &lt;指定目录&gt; &lt;指定条件&gt; &lt;指定动作&gt;

- &lt;指定目录&gt;: 所要搜索的目录及其所有子目录
- &lt;指定条件&gt;: 所要搜索的文件的特征 (eg: -name -type)
- &lt;指定动作&gt;: 对搜索结果进行特定的处理 (eg: -ls, -print,)
</code></pre><h3 id="locate-命令"><a href="#locate-命令" class="headerlink" title="locate 命令"></a>locate 命令</h3><p>locate 其实相当于 “find -name”，但是要比后者快得多，原因在于它不搜索具体目录，而是搜索一个数据库（/var/lib/locatedb），这个数据库中含有本地所有文件信息。Linux系统自动创建这个数据库，并且每天自动更新一次，<strong>所以使用locate命令查不到最新变动过的文件。</strong></p>
<p>为了避免这种情况，可以在使用locate之前，先使用<strong>updatedb</strong>命令，手动更新数据库。</p>
<pre><code>$ locate /etc/sh
搜索etc目录下所有以sh开头的文件。

$ locate ~/m
搜索用户目录下，所有以 m 开头的文件。

$ locate -i ~/m
搜索用户目录下，所有以 m 开头的文件，同时忽略大小写。
</code></pre><h3 id="whereis-命令"><a href="#whereis-命令" class="headerlink" title="whereis 命令"></a>whereis 命令</h3><p>whereis 命令只能用于程序名的搜索，而且只搜索二进制文件（参数-b）、man说明文件（参数-m）和源代码文件（参数-s）。如果省略参数，则返回所有信息。</p>
<h3 id="ping-多个-ip"><a href="#ping-多个-ip" class="headerlink" title="ping 多个 ip"></a>ping 多个 ip</h3><p>假设有一个日志文件，里面是每行的记录如下：172.0.0.1 <strong><em>**</em></strong>，也就是每行都有一个ip，例如在一个分布式系统里面，有很多机器的ip，那么我们要知道哪些机器宕机了，那么只需要ping一下这个ip即可，但是我们不能一个一个的ping啊，Linux 有没有什么命令可以解决。</p>
<p>Linux 自带的 ping 命令本身不可以 ping 多个 ip，但可以用 shell 来实现同时 ping 多个 ip。</p>
<ol>
<li><p>建一个空的输出文件 </p>
<pre><code>touch /output.txt 
</code></pre></li>
<li><p>新建一个脚本。</p>
<pre><code>vim ping.sh
</code></pre></li>
<li><p>脚本内容</p>
<pre><code>#!/bin/bash
A = &apos;cat /ip.txt&apos;
for B in $A 
do
ping -c 3 $B &gt;&gt;/output
done
wq
</code></pre></li>
<li><p>执行脚本</p>
<pre><code>./ ping.sh
</code></pre></li>
<li><p>查看结果</p>
<pre><code>cat output.txt
</code></pre></li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/25/分布式系统学习-Paxos算法/" itemprop="url">
                  分布式系统学习: Paxos算法
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-25T13:54:04+08:00" content="2016-10-25">
              2016-10-25
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/分布式系统/" itemprop="url" rel="index">
                    <span itemprop="name">分布式系统</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/10/25/分布式系统学习-Paxos算法/" class="leancloud_visitors" data-flag-title="分布式系统学习: Paxos算法">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在常见的分布式系统中，总会发生诸如机器宕机或网络异常等情况。Paxos 算法需要解决的问题就是如何在一个可能发生上述异常的分布式系统中快速且正确地在集群内部对某个数据的值达成一致，并且保证不会破坏整个系统的一致性。</p>
<h3 id="Paxos-算法详解"><a href="#Paxos-算法详解" class="headerlink" title="Paxos 算法详解"></a>Paxos 算法详解</h3><h4 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h4><p>假设有一组可以提出提案的进程集合，那么对于一个一致性算法来说需要保证以下几点：</p>
<ul>
<li>在这些提出的提案中，只有一个会被选定</li>
<li>如果没有提案被提出，那么就不会有被选定的提案</li>
<li>当一个提案被选定后，进程应该可以获取被选定的提案信息</li>
</ul>
<p>对于一致性来说，安全性需求如下：</p>
<ul>
<li>只有被提出的提案才能被选定</li>
<li>只能有一个值被选定</li>
<li>如果某个进程认为某个提案被选定了，那么这个提案必须是真的被选定的那个</li>
</ul>
<p><strong>从整体上来说，Paxos 算法的目标就是要保证最终有一个提案会被选定，当提案被选定后，进程最终也能获取到被选定的提案。</strong></p>
<p>在该一致性算法中，有三种参与角色，我们用 Proposer、Acceptor 和 Learner 来表示。在具体的实现中，一个进程可能充当不止一种角色。假设不同参与者之间可以通过收发消息来进行通信，那么：</p>
<ul>
<li>每个参与者以任意的速度执行，可能会因为出错而停止，也可能会重启。同时，即使一个提案被选定后，所有的参与者也都有可能失败或重启，因此除非那些失败或重启的参与者可以记录某些信息，否则将无法确定最终的值。</li>
<li>消息在传输过程中可能会出现不可预知的延迟，也可能会重复或丢失，但是消息不会被损坏，即消息内容不会被篡改。</li>
</ul>
<h4 id="提案的选定"><a href="#提案的选定" class="headerlink" title="提案的选定"></a>提案的选定</h4><p>要选定一个唯一提案的最简单方式莫过于只允许一个 Acceptor 存在，这样的话，Proposer 只能发生提案给该 Acceptor，Acceptor 会选择它接收到的第一个提案作为被选定的提案。这种解决方式尽管实现简单，但也存在单点问题，因为一旦这个 Acceptor 出现问题，那么整个系统就无法工作。</p>
<p>在存在多个 Acceptor 的情况下，如何进行提案的选取：Proposer 向一个 Acceptor 集合发送提案，同样，集合中的每个 Acceptor 都可能会批准（Accept）该提案，当有足够多的 Acceptor 批准这个提案的时候，我们就可以认为该提案被选定。</p>
<p>但是，如何去定义“足够多”这个概念，我们假定足够多的 Acceptor 是整个 Acceptor 集合的一个子集，并且让这个集合大得可以包含 Acceptor 集合中的大多数成员，因为任意两个包含大多数 Acceptor 的子集至少有一个公共成员。另外，我们假定每一个 Acceptor 最多只能批准一个提案，那么就能保证只有一个提案被选定了。</p>
<h4 id="推导过程"><a href="#推导过程" class="headerlink" title="推导过程"></a>推导过程</h4><p>在没有失败和消息丢失的情况下，如果我们希望即使在只有一个提案被提出的情况下，仍然可以选出一个提案，这就暗示了如下的需求：</p>
<pre><code>P1：一个 Acceptor 必须批准它收到的第一个提案
</code></pre><p>但是上面这个存在一点问题：如果有多个提案被不同的 Proposer 同时提出，这可能会导致虽然每个 Acceptor 都批准了它收到的第一个提案，但是没有一个提案是由多数人都批准的。</p>
<p>因此，在 P1 的基础上，再加上一个提案被选定需要由半数以上的 Acceptor 批准的需求暗示着一个 Acceptor 必须能够批准不止一个提案。在这里我们使用一个全局的编号（这种全局唯一编号的生成并不是 Paxos算法 需要关注的地方）来唯一标识每一个被 Acceptor 批准的提案，当一个具有某 Value 值的提案被半数以上的 Acceptor 批准后，我们就认为该 Value 被选定了，此时我们也认为该提案被选定了。注意，这里的提案和 Value 不是同一个概念，提案变成了一个由编号和 Value 组成的组合体，因此我们以 “[编号，Value]”来表示一个提案。</p>
<p>根据上面讲到的内容，我们虽然允许多个提案被选定，但同时必须要保证所有被选定的提案都具有相同的 Value 值—这是一个关于提案 Value 的约定，结合提案的编号，该约定可以定义如下：</p>
<pre><code>P2：如果编号为 M0、Value 值为 V0 的提案（即[M0，V0]）被选定了，那么所有比
编号 M0 更高的，且被选定的提案，其 Value 值必须也是 V0。
</code></pre><p>因为提案的编号是全序的，条件 P2 就保证了只有一个 Value 值被选定这一关键安全性属性。同时，一个提案要被选定，其首先必须被至少一个 Acceptor 批准，因此我们可以通过满足如下条件来满足 P2：</p>
<pre><code>P2a：如果编号为M0、Value 值为 V0 的提案（即[M0，V0]）被选定了，那么所有比
编号 M0 更高的，且被 Acceptor 批准的提案，其 Value 值必须也是 V0。
</code></pre><p>但是由于通信是异步的，一个提案可能会在某个 Acceptor 还未收到任何提案时就被选定了，但是 P1 又要求我们必须批准第一个收到的提案，这与 P2a 矛盾，因此如果要同时满足 P1 和 P2a，需要对 P2a 进行如下强化：</p>
<pre><code>P2b：如果一个提案[M0，V0] 被选定之后，那么之后任何 Proposer 产生的编号更高
的提案，其 Value 值都为 V0。
</code></pre><p>因为一个提案必须在被 Proposer 提出后才能被 Acceptor 批准，因此 P2b 包含了 P2a，进而包含了 P2。所以只需要证明 P2b 成立即可：</p>
<pre><code>假设某个提案 [M0，V0] 已经被选定了，证明任何编号 Mn &gt; M0 的提案，其 Value 
值都是 V0。
</code></pre><h4 id="数学归纳法证明"><a href="#数学归纳法证明" class="headerlink" title="数学归纳法证明"></a>数学归纳法证明</h4><p>我们可以通过对 Mn 进行第二数学归纳法来进行证明，即：</p>
<pre><code>假设编号在 M0 到 Mn-1 之间的提案，其 Value 值都是 V0，证明编号为 Mn 的提案
的 Value 值也为 V0。
</code></pre><p>因为编号为 M0 的提案已经被选定了，这就意味着肯定存在一个由半数以上的 Acceptor 组成的集合 C，C 中的每个 Acceptor 都批准了该提案。再结合归纳假设，“编号为 M0 的提案被选定” 意味着：</p>
<pre><code>C 中的每个 Acceptor 都批准了一个编号在 M0 到 Mn-1范围内的提案，并且每个编
号在 M0 到 Mn-1 范围内的被 Acceptor 批准的提案，其 Value 值都是 V0。
</code></pre><p>因为任何包含半数以上的 Acceptor 的集合 S 都至少包含 C 中的一个成员，因此我们可以认为如果保持了下面 P2c 的不变性，那么编号为 Mn 的提案的 Value 也为 V0。</p>
<pre><code>P2c：对于任意的 Mn 和 Vn，如果提案 [Mn，Vn] 被提出，那么肯定存在一个由半数
以上的 Acceptor 组成的集合 S，满足以下两个条件中的任意一个：
    1. S 中不存在任何批准过编号小于 Mn 的提案的 Acceptor
    2. 选取 S 中所有 Acceptor 批准的编号小于 Mn 的提案，其中编号最大的那个
       提案其 Value 值是 Vn
</code></pre><p>至此，只需要通过保持 P2c，我们就能满足 P2b。</p>
<p>从 P1 到 P2c 是对一系列条件的逐步加强，实际上 P2c 规定了每个 Proposer 如何产生一个提案：对于产生的每个提案 [Mn，Vn]，需要满足以下条件：</p>
<pre><code>存在一个由超过半数的 Acceptor 组成的集合 S：
1. 要么 S 中没有 Acceptor 批准过编号小于 Mn 的任何提案
2. 要么 S 中的所有 Acceptor 批准的所有编号小于 Mn 的提案中，编号最大的那个
   提案的Value值为 Vn
</code></pre><p> 当每个 Proposer 都按照这个规则来产生提案时，就可以保证满足 P2b 了， P2c 可以用第二数学归纳法证明，此处省略。</p>
<h4 id="Proposer-生成提案"><a href="#Proposer-生成提案" class="headerlink" title="Proposer 生成提案"></a>Proposer 生成提案</h4><p>对于一个 Proposer 来说，获取那些已经被通过的提案远比预测未来可能会被通过的提案简单。因此，Proposer 在产生一个编号为 Mn 的提案时，必须要知道当前某一个将要或已经被半数以上 Acceptor 批准的编号小于 Mn 但为最大编号的提案。并且，Proposer 会要求所有的 Acceptor 都不要再批准任何编号小于 Mn 的提案—这便是下面的提案生产算法。</p>
<ol>
<li><p>Proposer 选择一个新的提案编号 Mn，然后向某个 Acceptor 集合的成员发送请求，要求该集合中的 Acceptor 作出如下回应。</p>
<ul>
<li>像 Proposer 承诺，保证不再批准任何编号小于 Mn 的提案。</li>
<li><p>如果 Acceptor 已经批准过任何提案，那么其就向 Proposer 反馈当前该 Acceptor 已经批准的编号小于 Mn 但为最大编号的那个提案的值。</p>
<p>我们将该请求称为编号为 Mn 的提案的 Prepare 请求。</p>
</li>
</ul>
</li>
<li><p>如果 Proposer 收到了来自半数以上的 Acceptor 的响应结果，那么它就可以产生编号为 Mn， Value 值为 Vn 的提案，这里的 Vn 是所有响应中编号最大的提案的 Value 值。还有一种情况，就是半数以上的 Acceptor 都没有批准过任何提案，即响应中不包含任何的提案，那么此时 Vn 值就可以由 Proposer 任意选择</p>
</li>
</ol>
<p>在确定提案之后，Proposer 就会将该提案再次发送给某个 Acceptor 集合，并期望获得它们的批准，这称为 Accept 请求。</p>
<h4 id="Paxos-提案选定的整个流程"><a href="#Paxos-提案选定的整个流程" class="headerlink" title="Paxos 提案选定的整个流程"></a>Paxos 提案选定的整个流程</h4><p><strong>阶段一</strong></p>
<ol>
<li><p>Proposer 选择一个提案编号 Mn，然后向 Acceptor 的某个超过半数的子集成员发送编号为 Mn 的 Prepare 请求。</p>
</li>
<li><p>如果一个 Acceptor 收到一个编号为 Mn 的 Prepare 请求， 且编号 Mn 大于该 Acceptor 已经响应的所有 Prepare 请求的编号，那么它就会将它已经批准过的最大编号的提案作为响应反馈给 Proposer，同时该 Acceptor 会承诺不会再批准任何编号小于 Mn 的提案。</p>
</li>
</ol>
<p><strong>阶段二</strong></p>
<ol>
<li><p>如果 Proposer 收到来自半数以上的 Acceptor 对于其发出的编号为 Mn 的 Prepare 请求的响应，那么它就会发送一个针对 [Mn, Vn] 提案的 Accept 请求给 Acceptor。</p>
</li>
<li><p>如果 Acceptor 收到这个针对 [Mn, Vn]提案的 Accept 请求，只要该 Acceptor 尚未对编号大于 Mn 的 Prepare 请求做出响应，它就可以通过这个提案。</p>
</li>
</ol>
<h4 id="提案的获取"><a href="#提案的获取" class="headerlink" title="提案的获取"></a>提案的获取</h4><p>Learner 获取提案，有以下几种方案。</p>
<p><strong>方案一</strong></p>
<p>Learner 获取一个已经被选定的提案的前提是，该提案已经被半数以上的 Acceptor 批准。因此，最简单的做法是一旦 Acceptor 批准了一个提案，就将该提案发送给所有的 Learner。</p>
<p>这种方式需要让每个 Acceptor 与所有的 Learner 逐个进行一次通信，通信的次数至少为二者个数的乘积。</p>
<p><strong>方案二</strong></p>
<p>另一种可行的方案是，我们可以让所有的 Acceptor 将它们对提案的批准情况，统一发给一个特定的 Learner (主 Learner)，我们假定 Learner 之间可以通过消息通信来互相感知提案的选定情况。这样来说，当主 Learner 被通知一个提案已经被选定时，它会负责通知其他的 Learner。</p>
<p>这种方案下，Acceptor 首先会将被批准的提案发送给 Learner，再由其同步给其他 Learner，因此方案二的通信次数较方案一而言，大大减少了，通常只是 Acceptor 和 Learner 的总和。但同时又引入了单点问题，即主 Learner 随时可能故障。</p>
<p><strong>方案三</strong></p>
<p>针对方案二的单点问题，可以将主 Learner 的范围扩大，即 Acceptor 可以将批准的提案发送给一个特定的 Learner 集合，该集合中的每个 Learner 都可以在一个提案被选定后通知所有其他的 Learner。</p>
<h4 id="通过选取主-Proposer-保证算法的活性"><a href="#通过选取主-Proposer-保证算法的活性" class="headerlink" title="通过选取主 Proposer 保证算法的活性"></a>通过选取主 Proposer 保证算法的活性</h4><p>假设存在这样一种极端情况，有两个 Proposer 依次提出了一系列编号递增的议案，但是最终都无法确定，从而陷入死循环。</p>
<p>为了保证 Paxos 算法流程的可持续性，以避免陷入上述提到的“死循环”，就必须选择一个主 Proposer，并规定只有主 Proposer 才能提出议案。这样一来，只要主 Proposer 和过半的 Acceptor 能够正常进行网络通信，那么但凡主 Proposer 提出一个编号更高的提案，该提案最终将会被批准。当然，如果当前有一个编号更高的提案被提出或正在接受批准，那么它会丢弃当前这个编号较小的提案，并最终能够选出一个编号足够大的提案。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>2PC、3PC 和 Paxos都是典型的分布式一致性协议，都从不同方面不同程度地解决了分布式一致性问题。其中二阶段提交协议解决了分布式事务的原子性问题，保证了分布式事务的多个参与者要么执行成功，要么执行失败。但是，二阶段存在一些诸如同步阻塞和无限期等待的问题。三阶段提交协议则是在二阶段的基础上，添加了 PreCommit 过程，从而避免了二阶段提交协议中的无限期等待问题。而 Paxos 算法中引入 “过半” 的理念，同时支持分布式节点角色之间的轮换。从而避免了分布式单点的出现。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/24/分布式系统学习-一致性协议/" itemprop="url">
                  分布式系统学习: 2PC 与 3PC
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-24T15:09:41+08:00" content="2016-10-24">
              2016-10-24
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/分布式系统/" itemprop="url" rel="index">
                    <span itemprop="name">分布式系统</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/10/24/分布式系统学习-一致性协议/" class="leancloud_visitors" data-flag-title="分布式系统学习: 2PC 与 3PC">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在对一个分布式系统进行架构设计的过程中、往往会在系统的可用性和数据一致性之间进行反复的权衡，于是就产生了一系列的一致性协议。其中最近经典的就是二阶段提交协议、三阶段提交协议和Paxos算法了。</p>
<h3 id="2PC-与-3PC"><a href="#2PC-与-3PC" class="headerlink" title="2PC 与 3PC"></a>2PC 与 3PC</h3><p>在分布式系统中，每一个机器节点虽然能够明确知道自己在进行事务操作中的结果是成功或失败，但却无法直接获取到其他分布式结点的操作结果。因此，当一个事务操作需要跨越多个分布式节点的时候，为了保持事务处理的 ACID 特性，就需要引入一个称为“协调者”的组件来统一调度所有分布式节点的执行逻辑，这些被调度的分布式节点则被称为“参与者”，协调者辅助调度参与者的行为，并最终决定这些参与者是否要把事务真正的提交。基于这个思想，衍生出了二阶段提交(2PC)和三阶段提交(3PC)两种协议。</p>
<h3 id="2PC"><a href="#2PC" class="headerlink" title="2PC"></a>2PC</h3><p>2PC是计算机网络尤其是在数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务处理过程中能够保持原子性和一致性而设计的一种算法。目前，绝大部分的关系型数据库都是采用二阶段提交协议来完成分布式事务处理的，利用该协议能够非常方便地完成所有分布式事务参与者的协调，统一决定事务的提交或回滚，从而能够有效的保证分布式数据一致性，因此二阶段提交协议被广泛地应用在许多分布式系统中。</p>
<h4 id="协议说明"><a href="#协议说明" class="headerlink" title="协议说明"></a>协议说明</h4><p>二阶段协议将事务的提交过程分成两个阶段来进行处理。</p>
<h4 id="阶段一：提交事务请求"><a href="#阶段一：提交事务请求" class="headerlink" title="阶段一：提交事务请求"></a>阶段一：提交事务请求</h4><ol>
<li><p>事务询问</p>
<p> 协调者向所有的参与者发送事务内容，询问是否可以执行事务提交操作，并开始等待各参与者的响应。</p>
</li>
<li><p>执行事务</p>
<p> 各参与者节点执行事务操作，并将 Undo 和 Redo 信息记入事务日志中。</p>
</li>
<li><p>各参与者向协调者反馈事务询问的响应</p>
<p> 如果参与者成功执行了事务操作，那么就反馈给协调者 Yes 响应，表示事务可以执行；如果参与者没有成功执行事务，那么就反馈给协调者 No 响应，表示事务不可以执行。</p>
</li>
</ol>
<h4 id="阶段二：执行事务提交"><a href="#阶段二：执行事务提交" class="headerlink" title="阶段二：执行事务提交"></a>阶段二：执行事务提交</h4><p>阶段二中，协调者会根据各参与者的反馈情况来决定最终是否可以进行事务提交操作，正常情况下，包括两种可能。</p>
<p><strong>执行事务提交</strong></p>
<p>假如协调者从所有的参与者获得的反馈都是 Yes 响应，那么就会执行事务提交。</p>
<ol>
<li><p>发送提交请求</p>
<p> 协调者向所有参与者结点发出 Commit 请求。</p>
</li>
<li><p>事务提交</p>
<p> 参与者接收到 Commit 请求后，会正式执行事务提交操作，并在完成提交之后释放在整个事务执行期间占用的事务资源。</p>
</li>
<li><p>反馈事务提交结果</p>
<p> 参与者在完成事务提交之后，向协调者发送 ACK 消息。</p>
</li>
<li><p>完成事务。</p>
<p> 协调者接收到所有参与者反馈的 ACK 消息后，完成事务。</p>
</li>
</ol>
<p><strong>中断事务</strong></p>
<p>假如任何一个参与者向协调者反馈了 No 响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务。</p>
<ol>
<li><p>发送回滚请求</p>
<p> 协调者向所有参与者节点发送 Rollback 请求。</p>
</li>
<li><p>事务回滚</p>
<p> 参与者接收到 Rollback请求后，会利用其在阶段一中记录的 Undo 信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源。</p>
</li>
<li><p>反馈事务回滚结果</p>
<p> 参与者在完成事务回滚之后，向协调者发送 ACK 消息。</p>
</li>
<li><p>中断事务</p>
<p> 协调者接收到所有参与者反馈的 ACK 消息后，完成事务中断。</p>
</li>
</ol>
<p>简单来说，二阶段提交将一个事务的处理过程分为了投票和执行两个阶段，其核心是对每个事务都采用先尝试后提交的处理方式，因此也可以将二阶段提交看作一个强一致性的算法。</p>
<h3 id="2PC-的优缺点"><a href="#2PC-的优缺点" class="headerlink" title="2PC 的优缺点"></a>2PC 的优缺点</h3><p>优点： 原理简单，实现方便</p>
<p>缺点：</p>
<ol>
<li><p>同步阻塞</p>
<p> 在二阶段提交的执行过程中，所有参与该事务操作的逻辑都处于阻塞状态。</p>
</li>
<li><p>单点问题</p>
<p> 一旦协调者出现问题，那么整个二阶段提交流程将无法运，其他参与者将会一直处于锁定事务资源的状态中。</p>
</li>
<li><p>数据不一致性</p>
<p> 当发生局部网络异常或者是协调者在尚未发生完 Commit 请求之前自身发生了崩溃，导致最终只有部分参与者收到了Commit请求，于是，就只有部分参与者会进行事务的提交。</p>
</li>
<li><p>太过保守</p>
<p> 没有完善的容错机制，任意几个节点的失败都会导致整个事务的失败。</p>
</li>
</ol>
<h3 id="3PC"><a href="#3PC" class="headerlink" title="3PC"></a>3PC</h3><p>3PC 将 2PC 的“提交事务请求”过程一分为二，形成了CanCommit、PreCommit和do Commit 三个阶段组成的事务处理协议</p>
<h4 id="阶段一：CanCommit"><a href="#阶段一：CanCommit" class="headerlink" title="阶段一：CanCommit"></a>阶段一：CanCommit</h4><ol>
<li><p>事务询问</p>
<p> 协调者向所有的参与者发送一个包含事务内容的 canCommit 请求，询问是否可以执行事务提交操作，并开始等待各参与者的响应。</p>
</li>
<li><p>各参与者向协调者反馈事务询问的响应</p>
<p> 参与者在接收到来自协调者的 canCommit 请求后，正常情况下，如果自身认为可以顺利执行事务，那么会反馈 Yes，并且进入预备状态；否则，反馈No。</p>
</li>
</ol>
<h4 id="阶段二：PreCommit"><a href="#阶段二：PreCommit" class="headerlink" title="阶段二：PreCommit"></a>阶段二：PreCommit</h4><p>在阶段二中，协调者会根据各参与者的反馈情况来决定是否可以进行事务的PreCommit操作、正常情况下，包含两种可能。</p>
<p><strong>执行事务预提交</strong></p>
<p>假如协调者从所有的参与者获得的反馈都是 Yes，那么会进入预提交。</p>
<ol>
<li><p>发送预提交请求</p>
</li>
<li><p>事务预提交</p>
<p> 参与者接收到 preCommit 请求后，会执行事务操作，并将 Undo 和 Redo信息记录到事务日志中</p>
</li>
<li><p>各参与者向协调者反馈事务执行的响应</p>
<p> 如果参与者成功执行了事务操作，那么就会反馈给协调者 ACK 响应，同时等待最终的指令：提交或终止</p>
</li>
</ol>
<p><strong>中断事务</strong></p>
<p>假如任何一个参与者向协调者反馈了No响应，或者在等待超时之后，协调者尚无法接收到所有参与者的反馈响应，那么就会中断事务。</p>
<ol>
<li><p>发送中断请求</p>
<p> 协调者向所有参与者节点发出了 abort 请求。</p>
</li>
<li>中断事务</li>
</ol>
<h4 id="阶段三：doCommit"><a href="#阶段三：doCommit" class="headerlink" title="阶段三：doCommit"></a>阶段三：doCommit</h4><p>该阶段真正实现事务提交，会存在以下两种情况：</p>
<p><strong>执行提交</strong></p>
<ol>
<li><p>发送提交请求</p>
<p> 进入这一阶段，假设协调者处于正常工作状态，并且它接收了来自索引参与者的Ack响应，那么它将从“预提交”状态转换到“提交”状态，并向所有的参与者发送 doCommit 请求。</p>
</li>
<li><p>事务提交</p>
<p> 参与者收到 doCommit 请求之后，会正式执行事务提交操作，完成后释放资源。</p>
</li>
<li><p>反馈事务提交结果</p>
<p> 参与者在完成事务提交操作之后，向协调者发送 ACK 消息。</p>
</li>
<li>完成事务</li>
</ol>
<p><strong>中断事务</strong></p>
<p>进入这一阶段，假设协调者处于正常工作状态，并且任一参与者向协调者反馈了 No 响应，或者在等待超时之后，协调者无法收到所有参与者的反馈响应</p>
<ol>
<li><p>发送中断请求</p>
</li>
<li><p>事务回滚</p>
<p> 参与者接收到abort请求后，会利用其在阶段二中记录的Undo信息来执行事务回滚操作，并在完成回滚之后释放在整个事务执行期间占用的资源。</p>
</li>
<li><p>反馈事务回滚结果</p>
<p> 参与者在完成事务回滚之后，向协调者发送 ACK 消息。</p>
</li>
<li><p>中断事务</p>
</li>
</ol>
<p>需要注意的是，一旦进入阶段三，会出现2个问题：</p>
<ul>
<li>协调者出现问题</li>
<li>协调者和参与者之间网络出现故障</li>
</ul>
<p>这两种情况会导致参与者无法及时接收到协调者发来的消息。针对这种情况，参与者都会在等待超时之后，继续进行事务提交。</p>
<h3 id="3PC-的优缺点"><a href="#3PC-的优缺点" class="headerlink" title="3PC 的优缺点"></a>3PC 的优缺点</h3><p>相比 2PC，3PC 降低了参与者的阻塞范围，并且能够在出现单点故障后继续达成一致。但是，3PC 在参与者接收到 preCommit 消息后，如果出现网络分区，此时协调者所在的节点和参与者无法进行正常的网络通信，在这种情况下，该参与者依然会进行事务的提交，这必然会出现数据不一致的情况。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/24/Java集合学习：HashMap实现原理/" itemprop="url">
                  Java集合学习：HashMap实现原理
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-24T14:33:21+08:00" content="2016-10-24">
              2016-10-24
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/数据结构/" itemprop="url" rel="index">
                    <span itemprop="name">数据结构</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/10/24/Java集合学习：HashMap实现原理/" class="leancloud_visitors" data-flag-title="Java集合学习：HashMap实现原理">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="HashMap概述"><a href="#HashMap概述" class="headerlink" title="HashMap概述"></a>HashMap概述</h3><p>HashMap 是基于哈希表的Map接口的非同步实现。此实现提供所有可选的映射操作，并允许使用 null 值 和 null 键。此类不保证映射的顺序，特别是它不保证该顺序恒久不变。</p>
<p>Hashmap 不是同步的，如果多个线程同时访问一个 HashMap，而其中至少一个线程从结构上（指添加或者删除一个或多个映射关系的任何操作）修改了，则必须保持外部同步，以防止对映射进行意外的非同步访问。</p>
<h3 id="HashMap的数据结构"><a href="#HashMap的数据结构" class="headerlink" title="HashMap的数据结构"></a>HashMap的数据结构</h3><p>HashMap底层就是一个数组结构，数组中的每一项又是一个链表。当新键一个 HashMap 的时候，就会初始化一个数组。下面看下HashMap的构造函数：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal initial capacity: "</span> +</span><br><span class="line">                                               initialCapacity);</span><br><span class="line">        <span class="keyword">if</span> (initialCapacity &gt; MAXIMUM_CAPACITY)</span><br><span class="line">            initialCapacity = MAXIMUM_CAPACITY;</span><br><span class="line">        <span class="keyword">if</span> (loadFactor &lt;= <span class="number">0</span> || Float.isNaN(loadFactor))</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal load factor: "</span> +</span><br><span class="line">                                               loadFactor);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// Find a power of 2 &gt;= initialCapacity</span></span><br><span class="line">        <span class="keyword">int</span> capacity = <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">while</span> (capacity &lt; initialCapacity)</span><br><span class="line">            capacity &lt;&lt;= <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">this</span>.loadFactor = loadFactor;</span><br><span class="line">        threshold = (<span class="keyword">int</span>)Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + <span class="number">1</span>);</span><br><span class="line">        table = <span class="keyword">new</span> Entry[capacity];</span><br><span class="line">        useAltHashing = sun.misc.VM.isBooted() &amp;&amp;</span><br><span class="line">                (capacity &gt;= Holder.ALTERNATIVE_HASHING_THRESHOLD);</span><br><span class="line">        init();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>注意，这里有一个新键 entry 的过程：</p>
<pre><code class="java">table = <span class="keyword">new</span> Entry[capacity];
</code></pre>
<p>那什么是entry呢，我们看下 Entry 的源码实现：</p>
<pre><code class="java"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>{
    <span class="keyword">final</span> K key;
    V value;
    Entry&lt;K,V&gt; next;
    <span class="keyword">final</span> <span class="keyword">int</span> hash;
    ……
}
</code></pre>
<p>我们目前还是只着重核心的部分，Entry 是一个 static class，其中包含了 key 和 value，也就是键值对，另外还包含了一个 next 的 Entry 指针。我们可以总结出：Entry 就是数组中的元素，每个 Entry 其实就是一个 key-value 对，它持有一个指向下一个元素的引用，这就构成了链表。</p>
<h3 id="HashMap-的核心方法解读"><a href="#HashMap-的核心方法解读" class="headerlink" title="HashMap 的核心方法解读"></a>HashMap 的核心方法解读</h3><pre><code>/**
     * Associates the specified value with the specified key in this map.
     * If the map previously contained a mapping for the key, the old
     * value is replaced.
     *
     * @param key key with which the specified value is to be associated
     * @param value value to be associated with the specified key
     * @return the previous value associated with &lt;tt&gt;key&lt;/tt&gt;, or
     *         &lt;tt&gt;null&lt;/tt&gt; if there was no mapping for &lt;tt&gt;key&lt;/tt&gt;.
     *         (A &lt;tt&gt;null&lt;/tt&gt; return can also indicate that the map
     *         previously associated &lt;tt&gt;null&lt;/tt&gt; with &lt;tt&gt;key&lt;/tt&gt;.)
     */
public V put(K key, V value) {
        //其允许存放null的key和null的value，当其key为null时，调用putForNullKey方法，放入到table[0]的这个位置
        if (key == null)
            return putForNullKey(value);
        //通过调用hash方法对key进行哈希，得到哈希之后的数值。该方法实现可以通过看源码，其目的是为了尽可能的让键值对可以分不到不同的桶中
        int hash = hash(key);
        //根据上一步骤中求出的hash得到在数组中是索引i
        int i = indexFor(hash, table.length);
        //如果i处的Entry不为null，则通过其next指针不断遍历e元素的下一个元素。
        for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) {
            Object k;
            if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) {
                V oldValue = e.value;
                e.value = value;
                e.recordAccess(this);
                return oldValue;
            }
        }
        modCount++;
        addEntry(hash, key, value, i);
        return null;
}
</code></pre><p>我们看一下方法的标准注释：在注释中首先提到了，当我们 put 的时候，如果 key 存在了，那么新的 value 会代替旧的 value，并且如果 key 存在的情况下，该方法返回的是旧的 value，如果 key 不存在，那么返回 null。</p>
<p>从上面的源代码中可以看出：当我们往 HashMap 中 put 元素的时候，先根据 key 的 hashCode 重新计算 hash 值，根据 hash 值得到这个元素在数组中的位置（即下标），如果数组该位置上已经存放有其他元素了，那么在这个位置上的元素将以链表的形式存放，新加入的放在链头，最先加入的放在链尾。如果数组该位置上没有元素，就直接将该元素放到此数组中的该位置上。</p>
<p>addEntry(hash, key, value, i)方法根据计算出的 hash 值，将 key-value 对放在数组 table 的 i 索引处。addEntry 是 HashMap 提供的一个包访问权限的方法，代码如下：</p>
<pre><code>/**
     * Adds a new entry with the specified key, value and hash code to
     * the specified bucket.  It is the responsibility of this
     * method to resize the table if appropriate.
     *
     * Subclass overrides this to alter the behavior of put method.
     */
void addEntry(int hash, K key, V value, int bucketIndex) {
        if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) {
            resize(2 * table.length);
            hash = (null != key) ? hash(key) : 0;
            bucketIndex = indexFor(hash, table.length);
        }

        createEntry(hash, key, value, bucketIndex);
}
void createEntry(int hash, K key, V value, int bucketIndex) {
        // 获取指定 bucketIndex 索引处的 Entry
        Entry&lt;K,V&gt; e = table[bucketIndex];
        // 将新创建的 Entry 放入 bucketIndex 索引处，并让新的 Entry 指向原来的 Entr
        table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e);
        size++;
}
</code></pre><p>当系统决定存储 HashMap 中的 key-value 对时，完全没有考虑 Entry 中的 value，仅仅只是根据 key 来计算并决定每个 Entry 的存储位置。我们完全可以把 Map 集合中的 value 当成 key 的附属，当系统决定了 key 的存储位置之后，value 随之保存在那里即可。</p>
<p>hash(int h)方法根据 key 的 hashCode 重新计算一次散列。此算法加入了高位计算，防止低位不变，高位变化时，造成的 hash 冲突。</p>
<pre><code>final int hash(Object k) {
        int h = 0;
        if (useAltHashing) {
            if (k instanceof String) {
                return sun.misc.Hashing.stringHash32((String) k);
            }
            h = hashSeed;
        }
        //得到k的hashcode值
        h ^= k.hashCode();
        //进行计算
        h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12);
        return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);
}
</code></pre><p>我们可以看到在 HashMap 中要找到某个元素，需要根据 key 的 hash 值来求得对应数组中的位置。如何计算这个位置就是 hash 算法。前面说过 HashMap 的数据结构是数组和链表的结合，所以我们当然希望这个 HashMap 里面的 元素位置尽量的分布均匀些，尽量使得每个位置上的元素数量只有一个，那么当我们用 hash 算法求得这个位置的时候，马上就可以知道对应位置的元素就是我们要的，而不用再去遍历链表，这样就大大优化了查询的效率。</p>
<p>对于任意给定的对象，只要它的 hashCode() 返回值相同，那么程序调用 hash(int h) 方法所计算得到的 hash 码值总是相同的。我们首先想到的就是把 hash 值对数组长度取模运算，这样一来，元素的分布相对来说是比较均匀的。但是，“模”运算的消耗还是比较大的，在 HashMap 中是这样做的：调用 indexFor(int h, int length) 方法来计算该对象应该保存在 table 数组的哪个索引处。indexFor(int h, int length) 方法的代码如下：</p>
<pre><code>/**
     * Returns index for hash code h.
     */
static int indexFor(int h, int length) {  
    return h &amp; (length-1);
}
</code></pre><p>这个方法非常巧妙，它通过 h &amp; (table.length -1) 来得到该对象的保存位，而 HashMap 底层数组的长度总是 2 的 n 次方，这是 HashMap 在速度上的优化。在 HashMap 构造器中有如下代码：</p>
<pre><code>// Find a power of 2 &gt;= initialCapacity
int capacity = 1;
while (capacity &lt; initialCapacity)  
    // capacity = capacity &lt;&lt; 1
    capacity &lt;&lt;= 1; 
</code></pre><p>这段代码保证初始化时 HashMap 的容量总是 2 的 n 次方，即底层数组的长度总是为 2 的 n 次方。</p>
<p>当 length 总是 2 的 n 次方时，h&amp; (length-1)运算等价于对 length 取模，也就是 h%length，但是 &amp; 比 % 具有更高的效率。这看上去很简单，其实比较有玄机的，我们举个例子来说明：</p>
<p>假设数组长度分别为 15 和 16，优化后的 hash 码分别为 8 和 9，那么 &amp; 运算后的结果如下：</p>
<table>
<thead>
<tr>
<th>h &amp; (table.length-1)</th>
<th>hash</th>
<th></th>
<th>table.length-1</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>8 &amp; (15 - 1)</td>
<td>0100</td>
<td>&amp;</td>
<td>1110</td>
<td>= 0100</td>
</tr>
<tr>
<td>9 &amp; (15 - 1)</td>
<td>0101</td>
<td>&amp;</td>
<td>1110</td>
<td>= 0100</td>
</tr>
<tr>
<td>8 &amp; (16 - 1)</td>
<td>0100</td>
<td>&amp;</td>
<td>1111</td>
<td>= 0100</td>
</tr>
<tr>
<td>8 &amp; (16 - 1)</td>
<td>0101</td>
<td>&amp;</td>
<td>1111</td>
<td>= 0101</td>
</tr>
</tbody>
</table>
<p>从上面的例子中可以看出：当它们和 15-1（1110）“与”的时候，产生了相同的结果，也就是说它们会定位到数组中的同一个位置上去，这就产生了碰撞，8 和 9 会被放到数组中的同一个位置上形成链表，那么查询的时候就需要遍历这个链 表，得到8或者9，这样就降低了查询的效率。同时，我们也可以发现，当数组长度为 15 的时候，hash 值会与 15-1（1110）进行“与”，那么最后一位永远是 0，而 0001，0011，0101，1001，1011，0111，1101 这几个位置永远都不能存放元素了，空间浪费相当大，更糟的是这种情况中，数组可以使用的位置比数组长度小了很多，这意味着进一步增加了碰撞的几率，减慢了查询的效率！而当数组长度为16时，即为2的n次方时，2n-1 得到的二进制数的每个位上的值都为 1，这使得在低位上&amp;时，得到的和原 hash 的低位相同，加之 hash(int h)方法对 key 的 hashCode 的进一步优化，加入了高位计算，就使得只有相同的 hash 值的两个值才会被放到数组中的同一个位置上形成链表。</p>
<p>所以说，当数组长度为 2 的 n 次幂的时候，不同的 key 算得得 index 相同的几率较小，那么数据在数组上分布就比较均匀，也就是说碰撞的几率小，相对的，查询的时候就不用遍历某个位置上的链表，这样查询效率也就较高了。</p>
<p>根据上面 put 方法的源代码可以看出，当程序试图将一个key-value对放入HashMap中时，程序首先根据该 key 的 hashCode() 返回值决定该 Entry 的存储位置：如果两个 Entry 的 key 的 hashCode() 返回值相同，那它们的存储位置相同。如果这两个 Entry 的 key 通过 equals 比较返回 true，新添加 Entry 的 value 将覆盖集合中原有 Entry 的 value，但key不会覆盖。如果这两个 Entry 的 key 通过 equals 比较返回 false，新添加的 Entry 将与集合中原有 Entry 形成 Entry 链，而且新添加的 Entry 位于 Entry 链的头部——具体说明继续看 addEntry() 方法的说明。</p>
<h3 id="读取"><a href="#读取" class="headerlink" title="读取"></a>读取</h3><pre><code>/**
     * Returns the value to which the specified key is mapped,
     * or {@code null} if this map contains no mapping for the key.
     *
     * &lt;p&gt;More formally, if this map contains a mapping from a key
     * {@code k} to a value {@code v} such that {@code (key==null ? k==null :
     * key.equals(k))}, then this method returns {@code v}; otherwise
     * it returns {@code null}.  (There can be at most one such mapping.)
     *
     * &lt;p&gt;A return value of {@code null} does not &lt;i&gt;necessarily&lt;/i&gt;
     * indicate that the map contains no mapping for the key; it&apos;s also
     * possible that the map explicitly maps the key to {@code null}.
     * The {@link #containsKey containsKey} operation may be used to
     * distinguish these two cases.
     *
     * @see #put(Object, Object)
     */
    public V get(Object key) {
        if (key == null)
            return getForNullKey();
        Entry&lt;K,V&gt; entry = getEntry(key);

        return null == entry ? null : entry.getValue();
    }
    final Entry&lt;K,V&gt; getEntry(Object key) {
        int hash = (key == null) ? 0 : hash(key);
        for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)];
             e != null;
             e = e.next) {
            Object k;
            if (e.hash == hash &amp;&amp;
                ((k = e.key) == key || (key != null &amp;&amp; key.equals(k))))
                return e;
        }
        return null;
    }
</code></pre><p>有了上面存储时的 hash 算法作为基础，理解起来这段代码就很容易了。从上面的源代码中可以看出：从 HashMap 中 get 元素时，首先计算 key 的 hashCode，找到数组中对应位置的某一元素，然后通过 key 的 equals 方法在对应位置的链表中找到需要的元素。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>简单地说，HashMap 在底层将 key-value 当成一个整体进行处理，这个整体就是一个 Entry 对象。HashMap 底层采用一个 Entry[] 数组来保存所有的 key-value 对，当需要存储一个 Entry 对象时，会根据 hash 算法来决定其在数组中的存储位置，在根据 equals 方法决定其在该数组位置上的链表中的存储位置；当需要取出一个Entry 时，也会根据 hash 算法找到其在数组中的存储位置，再根据 equals 方法从该位置上的链表中取出该Entry。</p>
<p>HashMap 的 resize（rehash）<br>当 HashMap 中的元素越来越多的时候，hash 冲突的几率也就越来越高，因为数组的长度是固定的。所以为了提高查询的效率，就要对 HashMap 的数组进行扩容，数组扩容这个操作也会出现在 ArrayList 中，这是一个常用的操作，而在 HashMap 数组扩容之后，最消耗性能的点就出现了：原数组中的数据必须重新计算其在新数组中的位置，并放进去，这就是 resize。</p>
<p>那么 HashMap 什么时候进行扩容呢？当 HashMap 中的元素个数超过数组大小 *loadFactor时，就会进行数组扩容，loadFactor的默认值为 0.75，这是一个折中的取值。也就是说，默认情况下，数组大小为 16，那么当 HashMap 中元素个数超过 16*0.75=12 的时候，就把数组的大小扩展为 2*16=32，即扩大一倍，然后重新计算每个元素在数组中的位置，而这是一个非常消耗性能的操作，所以如果我们已经预知 HashMap 中元素的个数，那么预设元素的个数能够有效的提高 HashMap 的性能。</p>
<h3 id="HashMap-的性能参数"><a href="#HashMap-的性能参数" class="headerlink" title="HashMap 的性能参数"></a>HashMap 的性能参数</h3><p>HashMap 包含如下几个构造器：</p>
<ul>
<li>HashMap()：构建一个初始容量为 16，负载因子为 0.75 的 HashMap。</li>
<li>HashMap(int initialCapacity)：构建一个初始容量为 initialCapacity，负载因子为 0.75 的 HashMap。</li>
<li>HashMap(int initialCapacity, float loadFactor)：以指定初始容量、指定的负载因子创建一个 HashMap。</li>
</ul>
<p>HashMap 的基础构造器 HashMap(int initialCapacity, float loadFactor) 带有两个参数，它们是初始容量 initialCapacity 和负载因子 loadFactor。</p>
<p>负载因子 loadFactor 衡量的是一个散列表的空间的使用程度，负载因子越大表示散列表的装填程度越高，反之愈小。对于使用链表法的散列表来说，查找一个元素的平均时间是 O(1+a)，因此如果负载因子越大，对空间的利用更充分，然而后果是查找效率的降低；如果负载因子太小，那么散列表的数据将过于稀疏，对空间造成严重浪费。</p>
<p>HashMap 的实现中，通过 threshold 字段来判断 HashMap 的最大容量：</p>
<pre><code>threshold = (int)(capacity * loadFactor);
</code></pre><p>结合负载因子的定义公式可知，threshold 就是在此 loadFactor 和 capacity 对应下允许的最大元素数目，超过这个数目就重新 resize，以降低实际的负载因子。默认的的负载因子 0.75 是对空间和时间效率的一个平衡选择。当容量超出此最大容量时， resize 后的 HashMap 容量是容量的两倍：</p>
<h3 id="Fail-Fast-机制"><a href="#Fail-Fast-机制" class="headerlink" title="Fail-Fast 机制"></a>Fail-Fast 机制</h3><h4 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h4><p>我们知道 java.util.HashMap 不是线程安全的，因此如果在使用迭代器的过程中有其他线程修改了 map，那么将抛出 ConcurrentModificationException，这就是所谓 fail-fast 策略。</p>
<p>ail-fast 机制是 java 集合(Collection)中的一种错误机制。 当多个线程对同一个集合的内容进行操作时，就可能会产生 fail-fast 事件。</p>
<p>例如：当某一个线程 A 通过 iterator去遍历某集合的过程中，若该集合的内容被其他线程所改变了；那么线程 A 访问集合时，就会抛出 ConcurrentModificationException 异常，产生 fail-fast 事件。</p>
<p>这一策略在源码中的实现是通过 modCount 域，modCount 顾名思义就是修改次数，对 HashMap 内容（当然不仅仅是 HashMap 才会有，其他例如 ArrayList 也会）的修改都将增加这个值（大家可以再回头看一下其源码，在很多操作中都有 modCount++ 这句），那么在迭代器初始化过程中会将这个值赋给迭代器的 expectedModCount。</p>
<pre><code>HashIterator() {
    expectedModCount = modCount;
    if (size &gt; 0) { // advance to first entry
    Entry[] t = table;
    while (index &lt; t.length &amp;&amp; (next = t[index++]) == null)  
        ;
    }
}
</code></pre><p>在迭代过程中，判断 modCount 跟 expectedModCount 是否相等，如果不相等就表示已经有其他线程修改了 Map：</p>
<p>注意到 modCount 声明为 volatile，保证线程之间修改的可见性。</p>
<pre><code>final Entry&lt;K,V&gt; nextEntry() {
    if (modCount != expectedModCount)
        throw new ConcurrentModificationException();
</code></pre><p>在 HashMap 的 API 中指出：</p>
<p>由所有 HashMap 类的“collection 视图方法”所返回的迭代器都是快速失败的：在迭代器创建之后，如果从结构上对映射进行修改，除非通过迭代器本身的 remove 方法，其他任何时间任何方式的修改，迭代器都将抛出 ConcurrentModificationException。因此，面对并发的修改，迭代器很快就会完全失败，而不冒在将来不确定的时间发生任意不确定行为的风险。</p>
<p>注意，迭代器的快速失败行为不能得到保证，一般来说，存在非同步的并发修改时，不可能作出任何坚决的保证。快速失败迭代器尽最大努力抛出 ConcurrentModificationException。因此，编写依赖于此异常的程序的做法是错误的，正确做法是：迭代器的快速失败行为应该仅用于检测程序错误。</p>
<h3 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h3><p>在上文中也提到，fail-fast 机制，是一种错误检测机制。它只能被用来检测错误，因为 JDK 并不保证 fail-fast 机制一定会发生。若在多线程环境下使用 fail-fast 机制的集合，建议使用“java.util.concurrent 包下的类”去取代“java.util 包下的类”。</p>
<h4 id="HashMap-的两种遍历方式"><a href="#HashMap-的两种遍历方式" class="headerlink" title="HashMap 的两种遍历方式"></a>HashMap 的两种遍历方式</h4><p><strong>第一种</strong></p>
<pre><code>　　Map map = new HashMap();
　　Iterator iter = map.entrySet().iterator();
　　while (iter.hasNext()) {
　　Map.Entry entry = (Map.Entry) iter.next();
　　Object key = entry.getKey();
　　Object val = entry.getValue();
　　}
　　
</code></pre><p>效率高</p>
<p><strong>第二种</strong></p>
<pre><code>　　Map map = new HashMap();
　　Iterator iter = map.keySet().iterator();
　　while (iter.hasNext()) {
　　Object key = iter.next();
　　Object val = map.get(key);
　　}
　　
</code></pre><p>效率低</p>
<h3 id="参考资料："><a href="#参考资料：" class="headerlink" title="参考资料："></a>参考资料：</h3><ol>
<li><a href="http://wiki.jikexueyuan.com/project/java-collection/hashmap.html" target="_blank" rel="external">HashMap 的实现原理</a></li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/23/分布式系统学习-事务处理与数据一致性/" itemprop="url">
                  分布式系统学习: 事务处理与数据一致性
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-23T19:21:47+08:00" content="2016-10-23">
              2016-10-23
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/分布式系统/" itemprop="url" rel="index">
                    <span itemprop="name">分布式系统</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/10/23/分布式系统学习-事务处理与数据一致性/" class="leancloud_visitors" data-flag-title="分布式系统学习: 事务处理与数据一致性">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="ACID"><a href="#ACID" class="headerlink" title="ACID"></a>ACID</h3><p>事务 (Transaction) 是由一些列对系统中数据进行访问与更新的操作所组成的一个程序执行逻辑单元 (Unit)，狭义上的事务特指数据库事务。一方面，当多个应用程序并发访问数据库时，事务可以在这些应用之间提供一个隔离方法，以防止彼此的操作互相干扰。另一方面，事务为数据库操作序列提供一个从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍然保持数据一致性的方法。</p>
<p>事务具有四个特征，分别是原子性、一致性，隔离性和持久性。</p>
<h4 id="原子性"><a href="#原子性" class="headerlink" title="原子性"></a>原子性</h4><p>事务的原子性是指事务必须是一个原子的操作序列单元。事务中包含的各项操作在一次执行过程中，只允许出现以下两种状态之一。</p>
<ul>
<li>全部执行成功</li>
<li>全部不执行</li>
</ul>
<p>任何一项操作失败都将导致整个事务失败，同时其他已经被执行的操作都将被撤销并回滚，只有所有的操作全部成功，整个事务才算是成功完成。</p>
<h4 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h4><p>事务的一致性是指事务的执行不能破坏数据库数据的完整性和一致性，一个事务在执行之前和执行之后，数据库都必须处于一致性状态。即，事务执行的结果必须是使数据库从一个一致性状态转变到另一个一致性状态。而如果数据库系统在运行过程中发生故障，有些事务尚未完成就被迫中断，这些未完成事务对数据库所做的修改有一半已经写入物理数据库，这时数据库就处于一种不正确的状态，或者是不一致的状态。</p>
<h4 id="隔离性"><a href="#隔离性" class="headerlink" title="隔离性"></a>隔离性</h4><p>事务的隔离性是指在并发环境中、并发的事务是相互隔离的，一个事务的执行不能被其他事务干扰。也就是说，不同的事务并发操纵相同的数据时，每个事务都有各自完整的数据空间。即一个事务内部的操作及使用的数据对其他并发事务是隔离的，并发执行的各个事务之间不能相互干扰。</p>
<p>在标准 SQL 规范中，定义了4个事务隔离级别，不同的隔离级别对事务的处理不同，如未授权读取、授权读取、可重复读取和串行化。</p>
<p><strong>未授权读取</strong></p>
<p>未授权读取也被称为读未提交，该隔离级别允许脏读取，其隔离级别最低。比如，事务 A 和 事务 B 同时进行，事务 A 在整个执行阶段，会将某数据项的值从 1 开始，做一些列加法操作直到变成 10 之后进行事务提交，此时，事务 B 能够看到这个数据项在事务 A 操作过程中的所有中间值（如 1 变成 2、2 变成 3等），而对这一系列的中间值的读取就是未授权读取。</p>
<p><strong>授权读取</strong></p>
<p>授权读取也叫读已提交，它和未授权读取很像，唯一的区别就是授权读取只允许获取已经被提交的数据。以上面那个为例，事务 A 和 事务 B 同时进行，事务 A 进行与上述同样的操作，此时，事务 B 无法看到这个数据项在事务 A 操作过程中的所有中间值，只看到最终的 10。另外，如果说有一个事务 C，和事务 A 进行非常类似的操作，只是事务 C 是将数据项从 10 加到 20，此时事务 B 也同样可以读取到 20，即授权读取允许不可重复读取。</p>
<p><strong>可重复读取</strong></p>
<p>可重复读取，就是保证在事务处理过程中，多次读取同一个数据时，其值都和事务开始时刻是一致的，因此该事务级别禁止了不可重复读取和脏读取，但是有可能出现幻影数据，就是指同样的事务操作，在前后两个时间段内执行对同一个数据项的读取，可能出现不一致的结果。以上面为例，事务 B 第一次事务操作的过程中，始终对数据项读取到 1，但是在下一次事务操作中，即使事务 B 采用同样的查询方式，就可能会读取到10 或 20。</p>
<p><strong>串行化</strong></p>
<p>串行化是最严格的事务隔离级别。它要求所有事务都被串行执行，即事务只能一个接一个地进行处理，不能并发执行。</p>
<p>事务隔离级别越高，就越能保证数据的完整性和一致性，但同时对并发性能的影响也越大。通常，对绝大多数的应用程序来说，可以优先考虑将数据库系统的隔离级别设置为授权读取，这能够在避免脏读取的同时保证较好的并发性能。</p>
<h4 id="持久性"><a href="#持久性" class="headerlink" title="持久性"></a>持久性</h4><p>事务的持久性也被称为永久性，是指一个事务一旦提交，它对数据库中对应数据的状态的变更就应该是永久性的。换句话说，一旦某个事务成功结束，那么它对数据库所做的更新就必须被永久保存下来</p>
<h3 id="分布式事务"><a href="#分布式事务" class="headerlink" title="分布式事务"></a>分布式事务</h3><p>在单机数据库中，我们很容易就能够实现一套满足 ACID 特性的事务处理系统，但在分布式数据库中，时间分散在各台不同的机器上，如何对这些数据进行分布式的事务处理具有非常大的挑战。</p>
<p>我们可以设想一个最典型的分布式事务场景：一个跨银行的转账操作涉及调用两个异地的银行服务，其中一个是本地银行提供的取款服务，另一个则是目标银行提供的存款服务，这两个服务本身是无状态并且是互相独立的，共同构成一个完整的分布式事务。如果从本地银行取款成功，但是因为某种原因存款服务失败了，那么就必须回滚到取款前的状态，否则用户可能会发现自己的钱不翼而飞了。</p>
<h3 id="CAP-和-BASE-理论"><a href="#CAP-和-BASE-理论" class="headerlink" title="CAP 和 BASE 理论"></a>CAP 和 BASE 理论</h3><h4 id="CAP-定理"><a href="#CAP-定理" class="headerlink" title="CAP 定理"></a>CAP 定理</h4><p>CAP 理论告诉我们，一个人分布式系统不可能同时满足一致性 (C：Consistency)、可用性(A：Availability)和分区容错性(P：Partition tolerance)这三个基本需求，最多同时满足其中的两项。</p>
<p><strong>一致性</strong></p>
<p>在分布式环境中，一致性是指数据在多个副本之间是否能够保持一致的特性。在一致性的需求下，当一个系统在数据一致的状态下更新操作后，应该保证系统的数据仍然处于一致的状态。</p>
<p><strong>可用性</strong></p>
<p>可用性是指系统提供的服务必须一直处于可用的状态，对于用户的每个操作请求总是能够在有限的时间内返回结果。这里我们重点看下“有限的时间内”和“返回结果”。</p>
<p>“有限的时间内”是指，对于用户的一个操作请求，系统必须能够在指定的时间内返回对应的处理结果，如果超过了这个时间范围，那么系统就被认为是不可用的。</p>
<p><strong>分区容错性</strong></p>
<p>分区容错性约束了一个分布式系统需要具有如下特性：分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务，除非是整个网络环境都发生了故障。</p>
<p>网络分区是指在分布式系统中，不同的结点分布在不同的子网络中，由于一些特殊的原因导致这些子网络之间出现网络不连通的状况，但各个子网络的内部网络是正常的，从而导致整个系统的网络环境被切分成了若干个孤立的区域。</p>
<h4 id="CAP-定理应用"><a href="#CAP-定理应用" class="headerlink" title="CAP 定理应用"></a>CAP 定理应用</h4><table>
<thead>
<tr>
<th>放弃CAP定理</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>放弃P</td>
<td>如果希望能够避免系统出现分区容错性问题，一种较为简单的做法是将所有的数据（或者仅仅是那些与事务相关的数据）都放在一个分布式结点上。这样的做法虽然无法100%保证系统不会出错，但至少不会碰到由于网络分区带来的负面影响。但这样也放弃了系统的可扩展性</td>
</tr>
<tr>
<td>放弃A</td>
<td>相对于放弃“分区容错性”来说，放弃可用性则正好相反，其做法是一旦系统遇到网络分区或其他故障时，那么受到影响的服务需要等待一定的时间，因此在等待期间系统无法对外提供正常的服务，即不可用</td>
</tr>
<tr>
<td>放弃C</td>
<td>这里是放弃数据的强一致性。这样的系统无法保证数据实时的一致性，但是能够承诺的是，数据最终会达到一个一致的状态。</td>
</tr>
</tbody>
</table>
<p>需要明确说明的是，对于一个分布式系统而言，分区容错性是一个最基本的要求。</p>
<h4 id="BASE-理论"><a href="#BASE-理论" class="headerlink" title="BASE 理论"></a>BASE 理论</h4><p>BASE 是 Basically Available（基本可用）、Soft state（软状态）和 Eventually consistent（最终一致性）三个短语的简写。</p>
<p>BASE 是对 CAP 中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的，其核心思想是即使无法做到强一致性，但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性。</p>
<p><strong>基本可用</strong></p>
<p>基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性，如</p>
<ul>
<li>响应时间上的损失</li>
</ul>
<p>正常情况下，一个在线搜索引擎在0.5秒之内返回查询结果，但由于出现故障，查询结果变为2秒</p>
<ul>
<li>功能上的损失</li>
</ul>
<p>正常情况下，在一个电子商务网站上进行购物，消费者几乎能够顺利的完成每一笔订单，但是在高峰的时候，由于购物行为激增，部分消费者可能会被引导到一个降级页面。</p>
<p><strong>弱状态</strong></p>
<p>弱状态也称为软状态，和硬状态相对，是指允许系统中的数据存在的中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允许系统在不同节点的数据副本之间进行数据同步的过程存在延时。</p>
<p><strong>最终一致性</strong></p>
<p>最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强一致性。</p>
<p>在实际的工程实践中，最终一致性存在以下五类主要变种：</p>
<ul>
<li>因果一致性</li>
</ul>
<p>因果一致性是指，如果进程 A 在更新完某个数据项后通知了进程 B，那么进程 B 之后对该数据项的访问都应该能够获取到进程 A 更新后的最新值，即不能发生丢失更新情况。但与进程 A 无因果关系的进程 C 的数据访问则没有这样的限制。</p>
<ul>
<li>读已之所写</li>
</ul>
<p>读已之所写是指，进程 A 更新一个数据项之后，它自己总是能够访问到更新过的最新值，而不会看到旧值。也就是说，对于单个数据获取者来说，其读取到的数据，一定不会比自己上次写入的值旧。</p>
<ul>
<li>会话一致性</li>
</ul>
<p>会话一致性将对系统数据的访问过程框定在了一个会话当中：系统能保证在同一个有效的会话中实现“读已之所写”的一致性，即，执行更新操作之后，客户端能够在同一个会话中始终读取到该数据项的最新值。</p>
<ul>
<li>单调读一致性</li>
</ul>
<p>单调读一致性是指如果一个进程从系统中读取出一个数据项的某个值后，那么系统对该进程后续的任何数据访问都不应该返回更旧的值。</p>
<ul>
<li>单调写一致性</li>
</ul>
<p>单调写一致性是指，一个系统需要能够保证来自同一个进程的写操作被顺序地执行。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>事实上，最终一致性并不是只有那些大型分布式系统才涉及的特性，许多现代的关系型数据库都采用了最终一致性模型。在现代关系型数据库中，大多数都会采用同步和异步方式来实现主备数据复制技术。在同步方式中，数据的复制通常是更新事务的一部分，因此在事务完成后，主备数据库的数据就会达到一致。而在异步方式中，备库的更新往往会存在延时，这取决于事务日志在主备数据库之间传输的时间长短，如果时间过长，那么显然，会出现数据不一致的情况，所以，这里就会用到最终一致性模型。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/22/数据库系统实现-索引结构小结/" itemprop="url">
                  数据库系统实现: 索引结构小结
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-22T15:22:02+08:00" content="2016-10-22">
              2016-10-22
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/10/22/数据库系统实现-索引结构小结/" class="leancloud_visitors" data-flag-title="数据库系统实现: 索引结构小结">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>顺序文件</strong>：几种简单的文件组织，其产生方式是将数据文件按某个排序键排序并在该文件上建立索引。</p>
<p><strong>稠密索引和稀疏索引</strong>：稠密索引为数据文件的每个记录设一个键 - 指针对，而稀疏索引为数据文件的每个存储块设一个键 - 指针对。</p>
<p><strong>多级索引</strong>：在索引文件上再建立索引，在索引的索引上再建索引……这在有时候是很有用的。高级索引必须是稀疏的。</p>
<p><strong>辅助索引</strong>：即使数据文件没有按查找键 K 排序，我们也可以在键 K 上建立索引。这样的索引必须是稠密的。</p>
<p><strong>倒排索引</strong>：文件及其包含的词之间的关系通常可通过一个词 - 指针对的索引结构来表示。指针指向“桶”文件的某个位置，该位置上有一个指向文件中该词出现的地方的指针列表。</p>
<p><strong>B - 树</strong>：这些结构实质上是有着很好的扩充性能的多级索引。带有 N 个键和 N + 1 个指针的存储块被组织成一棵树。叶结点指向记录。任何时候所有非根索引块都在半满与全满之间。</p>
<p><strong>散列表</strong>：同我们创建主存散列表一样，我们也可以基于辅存的存储块来建立散列表。散列函数将键值映射到桶，有效地将数据文件的记录分配到多个小组（桶）。桶用一个存储块和可能出现的溢出块表示。</p>
<p><strong>可扩展散列</strong>：这种方法允许在存在记录数太多的桶时将桶的数目加倍。它使用指向块的指针数组来表示同。为了避免块过多，几个桶可以用同一个块表示。</p>
<p><strong>线性散列</strong>：这种方法每当桶中的记录比例超出阈值时增加一个桶。由于单个桶的记录不会引起表的扩展，所以在某些情形下需要溢出块。</p>
<p><strong>需要多维索引的查询</strong>：在多维数据上需要被支持的查询种类有：部分匹配、范围查询、最近邻查询和 where-am-I(包含一个给定点的区域或区域集)查询。</p>
<p><strong>最近邻查询的执行</strong>：许多数据结构允许通过执行一个围绕给定点的范围查询来执行最近邻查询。要是在该范围内不存在点，则扩大这个范围。因为在矩形范围内找到了点并不排除在矩形外有更近点的可能性，所以我们必须小心。</p>
<p><strong>网格文件</strong>：网格文件在每一维上切分点空间。网格线间的距离可以不同，且每一维上的网格线也可以不同。只有数据分布得相当均匀，网格文件就能很好的支持范围查询、部分匹配查询和最近邻查询。</p>
<p><strong>分段散列表</strong>：分段散列函数从每一维上构造桶号的一些二进制位。它们支持部分匹配查询较好，且不依赖于数据的均匀分布。</p>
<p><strong>多键索引</strong>：一个简单的多维结构有一个根，根是某个属性的索引，它导入第二个属性上的索引集合，而第二个属性的索引又导入第三个属性的索引集合等等。它们对于范围和最近邻查询有用。</p>
<p><strong>kd - 树</strong>：kd - 树像二叉搜索树，但它们按不同层次在不同属性上分支。它们较好地支持部分匹配、范围和最近邻查询。为了使该结构适合二维辅存操作，需要把多个树结点压缩到一个块。</p>
<p><strong>四叉树</strong>：四叉树划分多维立方体成四个象限，且若它们有太多的点，则递归地用同样的方式划分这些象限。它们支持部分匹配、范围和最近邻查询。</p>
<p><strong>R - 树</strong>：这种树的结构通常表示成区域的集合，且通过聚集它们成一个更大区域的层次结构。它对 where-am-I 查询有帮助。</p>
<p><strong>位图索引</strong>：这种索引结构支持多维查询。它排序点或记录并且通过位向量表示记录的位置。这些索引支持范围、最近邻和部分匹配查询。</p>
<p><strong>压缩位图</strong>：为了节省由很少个 1 的向量组成位的图索引的空间，通过采用分段长度编码来对位图索引进行压缩。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/5/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="PengShuang" />
          <p class="site-author-name" itemprop="name">PengShuang</p>
          <p class="site-description motion-element" itemprop="description">在路上，慢慢走！</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">74</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">20</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">28</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/pengshuang" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/2176899852/profile?rightmod=1&wvr=6&mod=personnumber&is_all=1" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://bbs.byr.cn/" title="北邮人" target="_blank">北邮人</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://coolshell.cn/" title="酷壳" target="_blank">酷壳</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.dongwm.com" title="小明明的博客" target="_blank">小明明的博客</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PengShuang</span>
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
  <p>Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a></p>
</div>

<script>
(function(){
    var bp = document.createElement('script');
    bp.src = '//push.zhanzhang.baidu.com/push.js';
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>



        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("DKbLgBme7UkAx9JX6sM3D4Hj-gzGzoHsz", "GXjJ9Ox3pUGI9PJhm6CNfJGN");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

</body>
</html>
