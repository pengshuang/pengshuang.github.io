<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="在路上，慢慢走！">
<meta property="og:type" content="website">
<meta property="og:title" content="小沙文的博客">
<meta property="og:url" content="http://pengshuang.space/page/6/index.html">
<meta property="og:site_name" content="小沙文的博客">
<meta property="og:description" content="在路上，慢慢走！">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="小沙文的博客">
<meta name="twitter:description" content="在路上，慢慢走！">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://pengshuang.space/page/6/"/>

  <title> 小沙文的博客 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">小沙文的博客</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/11/数据库系统实现-索引结构/" itemprop="url">
                  数据库系统实现:索引结构
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-11T22:35:45+08:00" content="2016-10-11">
              2016-10-11
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/10/11/数据库系统实现-索引结构/" class="leancloud_visitors" data-flag-title="数据库系统实现:索引结构">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>数据库系统中最常用的索引结构为：B-树 和 散列表索引。最近在看《数据库系统实现》这本书，特此学习总结一下。</p>
<h3 id="索引结构基础"><a href="#索引结构基础" class="headerlink" title="索引结构基础"></a>索引结构基础</h3><p>数据库存储结构由文件构成，一个数据文件可以用来存储一个关系。一个数据文件可能拥有一个或多个索引文件，每个索引文件建立查找键和数据记录之间的关联，查找键的指针指向与查找键具有相同属性值的记录。</p>
<p>索引的个数视情况而定，可以稠密也可以稀疏。即数据文件中每个记录在索引文件中都设有一个索引项；索引也可以是稀疏的，即数据文件中只有部分记录在索引文件中表示出来，通常为每个数据块在索引文件中设一个索引项。索引还可以是“主索引”或者“辅助索引”。主索引能确定记录在数据文件中的位置，而辅助索引不能。通常，我们会在关系的主键上建立主索引，而在其他的属性上建立辅助索引。</p>
<h4 id="顺序文件"><a href="#顺序文件" class="headerlink" title="顺序文件"></a>顺序文件</h4><p><strong>顺序文件</strong>是对关系中的元组按主键进行排序而生成的文件。关系中的元组按照这个次序分布在多个数据块中。如图3-2所示，它的右半部分显示了一个顺序文件，这里假定主键是整数，并且每个存储块中只可存放两条记录。这里我们以尽量紧凑的方式将数据记录存入数据块中，但是在一般情况下，我们会为每个数据块预留一些空间，以容纳之后可能插入关系中的新元组。还有一种方法是将新插入的元组存储在溢出块中。</p>
<h4 id="稠密索引"><a href="#稠密索引" class="headerlink" title="稠密索引"></a>稠密索引</h4><p>如果记录是排好序的，我们就可以在记录上建立稠密索引，它是这样的一系列存储块：块中只存放记录的键以及指向记录本身的指针。稠密索引文件中的索引块保存键的顺序与文件中的排序顺序一致。既然我们假定查找键和指针所占存储空间远小于记录本身，我们就可以认为存储索引文件比存储数据文件所需存储块要少得多。当内存容纳不下数据文件，但容纳得下索引文件时，索引的优势尤为明显。这时，通过使用索引文件，我们每次查询只用一次I/O操作就能找到给定键值的记录</p>
<p>如图3-2所示，它为一个建立在顺序文件上的稠密索引。第一个索引块存放指向前四个记录的指针，第二存放指向接下来四个记录的指针，依次类推。</p>
<p>稠密索引支持按给定键值查找相应记录的查询。给定一个键值K，我们现在索引块中查找K。当找到K后，我们按照K所对应的指针到数据文件中找到相应的记录。似乎在找到K之前我们需要检索索引文件中的每个存储快，或平均一半的存储块。然后，由于有下面几个因素，基于索引的查找还是相对更高效：</p>
<ol>
<li>索引块的数量通常比数据块要少</li>
<li>由于键被排序，我们可以使用二分查找法来查找K。若有n个索引块，我们只需查找log2(n)个块。</li>
<li>索引文件可能足够小，以至可以永久地存放在主存缓冲区中。这样查找键K时就只涉及主存访问而不需执行I/O操作。</li>
</ol>
<p><img src="/img/index1.png" alt=""></p>
<h4 id="稀疏索引"><a href="#稀疏索引" class="headerlink" title="稀疏索引"></a>稀疏索引</h4><p><strong>稀疏索引</strong>只为数据文件的每个存储块设一个键—指针对，它比稠密索引节省了更多的存储空间，但查找给定值的记录需要更多的时间。只有当数据文件是按照某个查找键排序时，在该查找键上建立的稀疏索引才能被使用，而稠密索引则可以应用在任何的查找键。如下图所示，稀疏索引只为每个存储块设一个键-指针对。键值是每个数据块中的第一个记录的对应值。</p>
<p>在下图中，我们假定数据文件已经排序好，而且其键值为连续的10的倍数，直至某个较大的数。我们还继续假定每个存储块可存放四个键-指针对。这样，第一个索引存储块中为前四个数据存储块的第一个键值的索引项，它们分别为10、30、50和70，后面的以此类推，不在解释。</p>
<p>在已有稀疏索引的情况下，要找出查找键值为K的记录，我们得在索引中查找到键值小于或等于K的最大键值。由于索引文件已按键排序，我们可以使用二分查找法来定位这个索引项，然后根据它的指针找到相应的数据块。</p>
<p><img src="/img/index2.png" alt=""></p>
<h4 id="多级索引"><a href="#多级索引" class="headerlink" title="多级索引"></a>多级索引</h4><p>索引文件可能占据多个存储块，即便我们能定位索引存储块，并且能使用二分查找法找到所需索引项，我们仍可能需要执行多次I/O操作才能得到我们所需的记录。通过在索引上再见了索引，我们能够使第一级索引的使用更为有效。</p>
<p>下图展示了一个典型的二级索引，在这个例子中，一级索引是稀疏的，虽然我们也可以选择稠密索引来作为一级索引。但是，二级和更高级的索引必须是稀疏的，原因在于一个索引上的稠密索引将需要和其前一级索引同样多的键-指针对，因而也就需要同样的存储空间。</p>
<p><img src="/img/index3.png" alt=""></p>
<h4 id="辅助索引"><a href="#辅助索引" class="headerlink" title="辅助索引"></a>辅助索引</h4><p>辅助索引可用于任何索引目的，这种数据结构有助于查找给定一个或多个字段值的记录。但是，辅助索引与主索引最大的差别在于辅助索引不决定数据文件中记录的存放位置。而仅能告诉我们记录的当前存放位置，这一位置可能是建立在其他某个字段上的主索引确定的。辅助索引和主索引这一差别有一个有趣的推论：</p>
<ul>
<li>辅助索引总是稠密索引。一个稀疏的辅助索引没有意义，因为辅助索引不影响记录的存储位置，我们也就不能根据它来预测键值不在索引中显示指明的任何记录的位置。 </li>
</ul>
<p>下图为一个典型的辅助索引，我们发现，索引文件中的键是排序的，而数据文件没有按查找键排序。这样就造成索引块中的指针并不是指向一个或少数几个连续的存储块，而是指向许多不同的的数据块。例如，为了检索键值为20的所有记录，我们不仅需要查找两个索引块，而且还得访问指针指向的三个不同的数据块。因此，查找同样数量的记录，使用辅助索引比使用主索引可能需要更多的磁盘I/O。</p>
<p><img src="/img/index4.png" alt=""></p>
<h3 id="辅助索引的运用"><a href="#辅助索引的运用" class="headerlink" title="辅助索引的运用"></a>辅助索引的运用</h3><p>除了能在被组织成顺序文件的关系上建立附件索引外，辅助索引还可以用作某种数据结构的主键索引。这样的结构比如说有“堆”，在这种结构中，关系的记录之间没有特定的顺序。</p>
<p>第二种需要辅助索引的常见数据结构是<strong>聚集文件</strong>。假设有关系R和S，R中的元组和S中的元组具有多对一的对应关系。一种组织结构是把关系R的每个元组和关系S中的相关的元组存储在一起，另一种结构是按照主键来存储关系R。前一种结构在某些情况下更加合理。下面的一个例子说明了这种组织结构在特定情况下的合理性。</p>
<p>考虑<strong>movie</strong>和<strong>studio</strong>两个标准的关系：</p>
<pre><code>Movie(title, year, length, genre, studioName, producerC#)
Studio(name, address, presC#)
</code></pre><p>进一步假定查询的常见形式如下：</p>
<pre><code>SELECT title, year
FROM Movie, Studio
WHERE presC# = zzz AND Movie.studioName = Studio.name;
</code></pre><p>这里， zzz可以表示任意制片厂经理的证件号，即，已知一个制片厂的经理，我们需要找到由该制片厂制作的所有电影。</p>
<p>当我们确信上面这类查询是典型的查询，那么我们就可不按主键title和year排序，而是为Studio和Movie两个关系建立一个聚集文件结构，如下图所示。我们在每个Studio的元组后面存放关系Movie中该制片厂的所有电影元组。</p>
<p><img src="/img/index5.png" alt=""></p>
<p>如果我们为关系Studio在查找键presC#上建立索引，那么不管zzz是什么，我们都可以快速的找到所有符合条件的制片厂的元组。并且，Movie中所有studioName属性和某个制片厂的name属性匹配的元组。并且，Movie中所有studioName属性和某个制片厂的name属性匹配的元组，都会在聚集文件中紧跟在该制片厂的元组后出现。这样的话，我们可以用尽量少的几次I/O就找到该制片厂的所有电影，因为要查找的Movie元组已经以尽可能稠密的方式存储在紧跟着的数据块里。尽管如此，在Movie上对任意属性建立的索引只能是辅助索引。</p>
<h3 id="辅助索引中的间接"><a href="#辅助索引中的间接" class="headerlink" title="辅助索引中的间接"></a>辅助索引中的间接</h3><p>采用辅助索引的方式存放数据，有时空间浪费很大。假如某个索引键值在数据文件中出现n次，那么这个键值在索引文件中就要写n次，如果我们只为指向该键值的所有指针存储一次键值，这样比较节省空间。</p>
<p>避免键值重复的一种简便方法是使用一个称为桶的间接层，它介于辅助索引文件和数据文件之间。如下图所示，每个查找键K有一个键-指针对，指针指向一个桶文件，该文件中存放K的桶。从这个位置开始，直到索引指向的下一个位置，期间指针指向索引键值为K的所有记录。</p>
<p><img src="/img/index6.png" alt=""></p>
<p>在上图的例子中，我们沿索引键为50的索引项指针找到中间“桶”文件。这一指针刚好将我们带到桶文件中的第一个块的最后一个指针。我们继续向前查找，找到下一块的第一个指针。因为索引文件中键值为60的索引项指针刚好指向桶文件的第二个块的第二个指针，所以我们停止查找。</p>
<p>在辅助索引上使用间接层有一个重要的好处：我们通常可以在不访问数据文件记录的前提下利用桶的指针来帮助回答一些查询。特别是，当查询有多个条件，而每个条件都有一个可用的辅助索引时，我们可以通过在主存中将指针集合求交来找到满足所有条件的指针，然后只需要检索交集中指针指向的记录。这样，我们就节省了检索满足部分条件而非所有条件的记录所需的I/O开销。</p>
<p>举例：</p>
<p>考虑常用的Movie关系：</p>
<pre><code>Movie(title, year, length, genere, studioName, producerC#)
</code></pre><p>假定我们在studioName和year上都建立了有间接的桶的辅助索引，而且我们要执行如下查询：</p>
<pre><code>SELECT title
FROM Movie
WHERE studioName = &apos;Disney&apos; AND year = 2005;
</code></pre><p>下图说明我们如何使用索引来回答这个查询。通过studioName上的索引，我们找出了所有指向Disney制作的电影的指针。但是，我们并不把这些记录从磁盘上取到主存中，而是通过year上的索引，再找出所有指向2005年制作的电影的指针。然后我们求两个指针集的交集，正好得到2005年Disney制作的所有电影。最后我们到磁盘上去检索所有包含一部或几部这样的电影的块，这样只需检索尽可能少的数据块。</p>
<p><img src="/img/index7.png" alt=""></p>
<h3 id="文档索引和倒排索引"><a href="#文档索引和倒排索引" class="headerlink" title="文档索引和倒排索引"></a>文档索引和倒排索引</h3><h4 id="文档索引"><a href="#文档索引" class="headerlink" title="文档索引"></a>文档索引</h4><ul>
<li><p>一个文档可被看成是关系Doc的元组。这个关系有很多的属性，每个属性对应于文档可能出现的一个词。每个属性都是布尔型的—-表明该词在该文档出现还是没有出现。因此，这一关系模型可以被看作：</p>
<pre><code>Doc(hasCat, hasDog, ...)
</code></pre><p>其中<strong>hasCat</strong>取值为真当且仅当该文档中至少出现一次“cat”这个词</p>
</li>
<li><p>关系Doc的每个属性上都建有辅助索引。不过，我们不必费心为属性值为False的元组建索引项；相反，索引只会将我们带到出现该词的那些文档。也就是说，索引中只有查找键值为TRUE的索引项</p>
</li>
<li>我们不是给每个属性(即每个词）建立一个单独的索引，而是把所有的索引合成一个，称为倒排索引。这个索引使用间接桶来提高空间利用率。</li>
</ul>
<p>如下图所示，展示了一个倒排索引。这里取代记录数据文件的是一个文档集合，每个文档可以被存放在一个或多个磁盘块上。倒排索引本身由一系列词-指针对组成；词实际上是索引的查找键。正如之前讨论的任何一种索引那样，倒排索引被存储在连续的块中。</p>
<p><img src="/img/index8.png" alt=""></p>
<p>指针指向“桶”文件中的位置。例如，在上图中，“cat”一词有一个指针指向桶文件。该指针指向所有包含“cat”的文档的指针列表的表头。</p>
<p>桶文件中指针可以是：</p>
<ol>
<li>指向文档本身的指针。</li>
<li>指向词的一个出现的指针。在这种情况下，指针可以是由文档的第一个块和一个表示该词在文档中出现次数的整数构成的对。</li>
</ol>
<p>当我们使用指针“桶”指向每个词的多次出现的时候，我们可能就会想扩展这个想法，使桶数组包含更多有关词的出现的信息。这样，桶文件本身就成了有重要结构的记录集合。这种早期应用在区分一个词出现在文档的题目、摘要还是正文中的情况。随着Web上文档的增长，尤其是使用HTML、XML或者其他标记语言的文档的增长，我们也可以指明与词关联的的标记。例如，我们不仅可以区分出现在题头或表中的词，而且可以区分以不同字体和字号出现的词。</p>
<p>举例：</p>
<p>下图所示为一个标明HTML文档中词的出现情况的桶文件。如果有出现类型（即标记），就在第一列表明。第二、第三列一起构成指针指向词的出现：第三列指明文档，而第二列给出了该文档中该词出现的位置。</p>
<p><img src="/img/index9.png" alt=""></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/09/Spark-RDD学习-aggregate函数/" itemprop="url">
                  Spark RDD学习: aggregate函数
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-09T11:24:07+08:00" content="2016-10-09">
              2016-10-09
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/10/09/Spark-RDD学习-aggregate函数/" class="leancloud_visitors" data-flag-title="Spark RDD学习: aggregate函数">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近在做项目的时候遇到了<strong>Spark RDD</strong>里面的一个<strong>aggregate</strong>函数，觉得它的用法挺有意思的，在此记录一下。</p>
<p>Spark 文档中对 <strong>aggregate</strong>的函数定义如下：</p>
<pre><code>def aggregate[U](zeroValue: U)(seqOp: (U, T) =&gt; U, combOp: (U, U) 
=&gt; U)(implicit arg0: ClassTag[U]): U
</code></pre><p>注释：</p>
<pre><code>Aggregate the elements of each partition, and then the results for 
all the partitions, using given combine functions and a neutral 
&quot;zero value&quot;. 
This function can return a different result type, U, 
than the type of this RDD, T. 
Thus, we need one operation for merging a T into an U 
and one operation for merging two U&apos;s, as in 
Scala.TraversableOnce. Both of these functions are allowed to 
modify and return their first argument instead of creating a new U 
to avoid memory allocation. 
</code></pre><p><strong>aggregate</strong>函数首先对每个分区里面的元素进行聚合，然后用combine函数将每个分区的结果和初始值（zeroValue）进行combine操作。这个操作返回的类型不需要和RDD中元素类型一致，所以在使用 <strong>aggregate()</strong>时，需要提供我们期待的返回类型的初始值，然后通过一个函数把RDD中的元素累加起来􏵧􏲢放入累加器􏵌。考虑到每个节点是在本地进行累加的，最终还需要提供第二个函数来将累加器两两合并。</p>
<p>其中<strong>seqOp</strong>操作会聚合各分区中的元素，然后<strong>combOp</strong>操作会把所有分区的聚合结果再次聚合，两个操作的初始值都是<strong>zeroValue</strong>. <strong>seqOp</strong>的操作是遍历分区中的所有元素(T)，第一个T跟<strong>zeroValue</strong>做操作，结果再作为与第二个T做操作的<strong>zeroValue</strong>，直到遍历完整个分区。<strong>combOp</strong>操作是把各分区聚合的结果，再聚合。<strong>aggregate</strong>函数返回一个跟<strong>RDD</strong>不同类型的值。因此，需要一个操作<strong>seqOp</strong>来把分区中的元素T合并成一个U，另外一个操作<strong>combOp</strong>把所有U聚合。</p>
<p>下面举一个利用aggreated求平均数的例子:</p>
<pre><code>val rdd = List(1,2,3,4)
val input = sc.parallelize(rdd)
val result = input.aggregate((0,0))(
(acc,value) =&gt; (acc._1 + value, acc._2 + 1),
(acc1,acc2) =&gt; (acc1._1 + acc2._1, acc1._2 + acc2._2)
)
result: (Int, Int) = (10, 4)
val avg = result._1 / result._2
avg: Int = 2.5
</code></pre><p>程序的详细过程大概如下：</p>
<ol>
<li>首先定义一个初始值 (0, 0)，即我们期待的返回类型的初始值。</li>
<li><p><strong>(acc,value) =&gt; (acc._1 + value, acc._2 + 1)</strong>， <strong>value</strong>是函数定义里面的<strong>T</strong>，这里是List里面的元素。所以<strong>acc._1 + value, acc._2 + 1</strong>的过程如下：</p>
<pre><code>1.  0+1,  0+1
2.  1+2,  1+1
3.  3+3,  2+1
4.  6+4,  3+1
</code></pre></li>
<li><p>结果为 (10,4)。在实际Spark执行中是分布式计算，可能会把List分成多个分区，假如3个，p1(1,2), p2(3), p3(4)，经过计算各分区的的结果 (3,2), (3,1), (4,1)，这样，执行 <strong>(acc1,acc2) =&gt; (acc1._1 + acc2._1, acc1._2 + acc2._2)</strong> 就是 <strong>(3+3+4,2+1+1)</strong> 即 <strong>(10,4)</strong>，然后再计算平均值。 </p>
</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/08/GraphX学习/" itemprop="url">
                  GraphX学习:基础知识
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-08T14:25:44+08:00" content="2016-10-08">
              2016-10-08
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Spark/" itemprop="url" rel="index">
                    <span itemprop="name">Spark</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/10/08/GraphX学习/" class="leancloud_visitors" data-flag-title="GraphX学习:基础知识">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1-简介"><a href="#1-简介" class="headerlink" title="1. 简介"></a>1. 简介</h3><p>GraphX是Spark用于解决图和并行图计算问题的新组件。通过RDD（Resilient Distributed Datasets，弹性分布式数据集）的扩展，GraphX在其中引入了一个新的图抽象，即顶点和边带有特性的有向多重图。Graph提供了一些基本运算符和优化了的Pregel API，来支持图计算。另外，Graph包含了大量的图算法和构造器来简化图的分析任务，并且这个数量还在增加。</p>
<h3 id="2-GraphX使用"><a href="#2-GraphX使用" class="headerlink" title="2. GraphX使用"></a>2. GraphX使用</h3><p>第一步，引入Spark和GraphX相关的包：</p>
<pre><code>import org.apache.spark._
import org.apache.spark.graphx._

// 此处仍然需要用到RDD来让一些例子正常运行
import org.apache.spark.rdd.RDD
</code></pre><p>如果你没有使用Spark Shell（例如在外部的IDE中编辑项目），那么你还需要引入SparkContext。具体方法请参阅Spark官方文档，此处不再赘述。</p>
<h3 id="3-属性图"><a href="#3-属性图" class="headerlink" title="3. 属性图"></a>3. 属性图</h3><p>属性图是一个有向多重图，它的每个顶点和每条边都附有用户定义的对象。作为有向图，有向多重图可能有多个平行的边来共享相同的源顶点和目标顶点。作为多重图，它支持并行边，这个特性简化了许多涉及多重关系的建模场景。每个顶点的主键是一个长度为64 bit的唯一标识符<strong>（VertexID）</strong>。<strong>GraphX</strong>没有为顶点添加任何顺序的约束。类似地，每一条边有对应的源顶点和目标顶点的标识符。</p>
<p>因此，属性图的参数是通过顶点（VD）和边的类型（ED）来决定的。</p>
<p>在某些情况下，你可能希望在同一个图里面，顶点能够有不同的属性类型。这个想法可以通过继承实现。举个例子，我们可以对用户和产品进行建模，将其作为一个二分图，然后进行如下的定义（请在Spark Shell中输入语句）：</p>
<pre><code>class VertexProperty()
case class UserProperty(val name: String) extends VertexProperty
case class ProductProperty(val name: String, val price: Double) extends VertexProperty

// 图可能会有这个类型:
var graph: Graph[VertexProperty, String] = null
</code></pre><p>类似于RDD，属性图是不可变的、分布式的，并且具有容错性。对于图而言，它的值或者结构上的改变，是通过产生带有预期改变的新图来完成的。主要注意的是，原始图的主要部分（即不受影响的结构、属性和索引等）在新图中被重用，以减少固有功能的数据结构成本。通过使用大量的启发式顶点分区，图在不同的执行器里被划分。就像RDD一样，图的每个分区可以在发生故障时被不同的机器重建。</p>
<p>属性图在逻辑上对应于一对类型化集合（RDD），该集合编码了每个顶点和每条边属性。因而，图类包含了可以访问图的顶点和边的成员，它的定义如下（该定义仅作了解，无需自己手动定义该类）：</p>
<pre><code>class Graph[VD, ED] {
  val vertices: VertexRDD[VD]
  val edges: EdgeRDD[ED]
}
</code></pre><p><strong>VertexRDD[VD]</strong>类和<strong>EdgeRDD[ED]</strong>类分别继承和优化了<strong>RDD[(VertexID, VD)]</strong>类和<strong>RDD[Edge[ED]]</strong>类。两者都提供基于图计算和内部优化构建的额外功能。在此你可将其简单地理解为以<strong>RDD[(VertexID, VD)]</strong>和<strong>RDD[Edge[ED]]</strong>形式定义的<strong>RDD</strong>。</p>
<h3 id="4-一个属性图的例子"><a href="#4-一个属性图的例子" class="headerlink" title="4. 一个属性图的例子"></a>4. 一个属性图的例子</h3><p>现在假设我们要构建一个由许多来自GraphX项目组的协作者组成的属性图。顶点的属性可能包含用户名和职业。我们应该用一个可以描述协作者间的关系的字符串来注释图的边。</p>
<p>这段话可以用下图来表示（图片来自GraphX官方文档）：</p>
<p><img src="/img/graphx.png" alt=""></p>
<p>由这些因素构成的图将有下面的类型定义（该定义仅作了解即可，无需输入该语句）：</p>
<pre><code>val userGraph: Graph[(String, String), String]
</code></pre><p>有很多办法可以由原始文件、RDD或者综合生成器来构建一个属性图。可能最常用的方法还是使用一个<strong>Graph Object</strong>。下面的代码展示了如何通过一个RDD的集合来构建图，你可以尝试在<strong>Spark Shell</strong>中输入下面的代码来完成构建。</p>
<pre><code>// 在Spark Shell中，这里的SparkContext已经默认给出了。可略过此步。
val sc: SparkContext

// 创建一个RDD用于表示顶点
val users: RDD[(VertexId, (String, String))] =
  sc.parallelize(Array((3L, (&quot;rxin&quot;, &quot;student&quot;)), (7L, (&quot;jgonzal&quot;, &quot;postdoc&quot;)),
                       (5L, (&quot;franklin&quot;, &quot;prof&quot;)), (2L, (&quot;istoica&quot;, &quot;prof&quot;))))
// 创建一个RDD用于表示边
val relationships: RDD[Edge[String]] =
  sc.parallelize(Array(Edge(3L, 7L, &quot;collab&quot;),    Edge(5L, 3L, &quot;advisor&quot;),
                       Edge(2L, 5L, &quot;colleague&quot;), Edge(5L, 7L, &quot;pi&quot;)))

// 定义默认的用户，用于建立与缺失的用户之间的关系
val defaultUser = (&quot;John Doe&quot;, &quot;Missing&quot;)

// 构造图对象，即初始化过程
val graph = Graph(users, relationships, defaultUser)
</code></pre><p>在这个例子中，我们用到了名为<strong>Edge</strong>的<strong>case</strong>类。<strong>Edge</strong>类有<strong>srcId</strong>和<strong>dstId</strong>，它们对应于源顶点和目标庆典的标识符。另外，<strong>Edge</strong>类有一个名为<strong>attr</strong>的成员，用于存储边的属性。</p>
<p>我们也可以使用<strong>graph.vertices</strong>和<strong>graph.edges</strong>函数来解构一个图，将其转化为各个顶点和边的视图。用法如下，请尝试在Shell中输入这些语句：</p>
<pre><code>// 统计是博士后的用户数量
graph.vertices.filter { case (id, (name, pos)) =&gt; pos == &quot;postdoc&quot; }.count

// 统计符合 src &gt; dst 条件的边的数量 
graph.edges.filter(e =&gt; e.srcId &gt; e.dstId).count
</code></pre><p>注意，<strong>graph.vertices</strong>函数的返回值类型是 <strong>VertexRDD[(String, String)]</strong>，它继承了 <strong>RDD[(VertexID, (String, String))]</strong>，所以我们可以用<strong>Scala</strong>的<strong>case</strong>表达式来解构这个元组。另外，<strong>graph.edges</strong>函数的返回值类型是<strong>EdgeRDD</strong>，它包含了<strong>Edge[String]</strong>对象。我们同样可以使用<strong>case</strong>类的类型构造器，请尝试在<strong>Shell</strong>中输入下面的代码：</p>
<pre><code>graph.edges.filter { case Edge(src, dst, prop) =&gt; src &gt; dst }.count
</code></pre><p>对于属性类的顶点和边视图，GraphX还提供了三重视图<strong>（Triplet View）</strong>。这个三重视图从逻辑上联合了顶点和边的属性，产生了一个<strong>RDD[EdgeTriplet[VD, ED]]</strong>，它包含了<strong>DegeTriplet</strong>类的实例。这个<strong>join</strong>联合操作可以由下面的<strong>SQL</strong>表达式解释：</p>
<pre><code>SELECT src.id, dst.id, src.attr, e.attr, dst.attr
FROM edges AS e LEFT JOIN vertices AS src, vertices AS dst
ON e.srcId = src.Id AND e.dstId = dst.Id
</code></pre><p>如果看不懂这段SQL代码，没关系，下图也能帮助你理解该操作的含义：</p>
<p><img src="/img/graphx2.png" alt=""></p>
<p><strong>EdgeTriplet</strong>类继承了<strong>Edge</strong>类，并且添加了<strong>srcAttr</strong>和<strong>dstAttr</strong>两个成员。这两个成员分别包含了源属性和目标属性。我们可以用一个图的三重视图来渲染一个描述用户间关系的字符串集合，就像下面这样：</p>
<pre><code>// 使用 triplets view 来创建一个事实（facts）的RDD
val facts: RDD[String] =
  graph.triplets.map(triplet =&gt;
    triplet.srcAttr._1 + &quot; is the &quot; + triplet.attr + &quot; of &quot; + triplet.dstAttr._1)
facts.collect.foreach(println(_))
</code></pre>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/10/07/实现-memcpy-函数/" itemprop="url">
                  实现 memcpy 函数
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-07T11:10:09+08:00" content="2016-10-07">
              2016-10-07
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/面试总结/" itemprop="url" rel="index">
                    <span itemprop="name">面试总结</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/10/07/实现-memcpy-函数/" class="leancloud_visitors" data-flag-title="实现 memcpy 函数">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="1-接口设计"><a href="#1-接口设计" class="headerlink" title="1. 接口设计"></a>1. 接口设计</h4><pre><code>void mymemcpy(void* dst, const void* src, size_t num)
</code></pre><h4 id="2-边界条件"><a href="#2-边界条件" class="headerlink" title="2. 边界条件"></a>2. 边界条件</h4><p><strong>典型错误</strong></p>
<pre><code>void mymemcpy(void* dst, const void* src, size_t num){
    assert((dst != NULL)&amp;&amp;(src != NULL));

    const char * psrc = (const char *)src;
    char * pdst = (char *)dst;
    while(num-- &gt; 0)
    {
        *pdst++ = *psrc++;
    }
}
</code></pre><p><strong>情况1</strong>：不重合， 没问题</p>
<p><strong>情况2</strong>：重合，且dst &lt; src，也没问题</p>
<p><strong>情况3</strong>：重合，且dst &gt;= src，oops！</p>
<p>解决方法：从后向前拷贝</p>
<p><strong>正确解法</strong></p>
<pre><code>void mymemcpy(void *dst, const void *src, size_t num)
{
    assert((dst != NULL)&amp;&amp;(src != NULL));

    const char* psrc = (const char*)src;
    char* pdst = (char*)dst;

    if (pdst &gt; psrc &amp;&amp; pdst &lt; psrc + num)
    {
        for (size_t i = num - 1; i != -1; --i)
        {
            pdest[i] = psrc[i];
        }
    else
    {
        for (size_t i = 0; i &lt; num; ++i)
        {
            pdst[i] = psrc[i];
        }
    }
}
</code></pre><h4 id="3-如何对memcpy函数进行优化"><a href="#3-如何对memcpy函数进行优化" class="headerlink" title="3. 如何对memcpy函数进行优化"></a>3. 如何对memcpy函数进行优化</h4><p><strong>关键点</strong>：没有必要一个字节一个字节拷贝</p>
<p><strong>优化</strong>:</p>
<pre><code>void mymemcpy(void *dst, const void *src, size_t num)
{
    assert((dst != NULL)&amp;&amp;(src != NULL));

    int wordnum = num / 4;
    int slice = num % 4;
    const int* psrc = (const int*)src;
    int* pintdst = (int*)dst;

    // 一次拷贝 4 bytes
    while(wordnum--)
    {
        *pintdst++ = *pintsrc++;    
    }

    // 拷贝剩下的bytes
    const char* pcharsrc = (const char*)pintsrc;
    char* pchardst = (char*)pintdst;
    while (slice--)
    {
        *pchardst++ = *pcharsrc++;
    }
}
</code></pre>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/27/面试排序算法总结/" itemprop="url">
                  面试排序算法总结
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-09-27T09:15:16+08:00" content="2016-09-27">
              2016-09-27
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/面试总结/" itemprop="url" rel="index">
                    <span itemprop="name">面试总结</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/09/27/面试排序算法总结/" class="leancloud_visitors" data-flag-title="面试排序算法总结">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1-冒泡排序"><a href="#1-冒泡排序" class="headerlink" title="1. 冒泡排序"></a>1. 冒泡排序</h3><p>冒泡排序的原理就是重复的去遍历要排序的数列，一次比较2个元素，如果它们顺序错误就把它们交换过来。</p>
<p>代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bubble_sort</span><span class="params">(arry)</span>:</span></span><br><span class="line">    n = len(arry)   <span class="comment"># 获得数组的长度</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(i + <span class="number">1</span>, n):</span><br><span class="line">            <span class="keyword">if</span> arry[i] &gt; arry[j]:   <span class="comment"># 如果前者比后者大</span></span><br><span class="line">                arry[i], arry[j] = arry[j], arry[i] <span class="comment"># 则互相交换</span></span><br><span class="line">    <span class="keyword">return</span> arry</span><br></pre></td></tr></table></figure>
<h3 id="2-选择排序"><a href="#2-选择排序" class="headerlink" title="2. 选择排序"></a>2. 选择排序</h3><p>选择排序的思想比较简单，先在未排序的序列中找到最大（最小）的元素，存放到排序序列的起始位置；再从剩余未排序的序列中寻找最大（最小）的元素，然后放到已排序序列的末尾；以此类推。</p>
<p>代码实现：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">select_sort</span><span class="params">(arry)</span>:</span></span><br><span class="line">   n = len(arry)</span><br><span class="line">   <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>, n):</span><br><span class="line">       min = i     <span class="comment"># 先假定第一个为最小元素</span></span><br><span class="line">       <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, n):</span><br><span class="line">           <span class="keyword">if</span> arry[j] &lt; arry[min]:</span><br><span class="line">               min = j     <span class="comment"># 找到最小值的下标</span></span><br><span class="line">       arry[min], arry[i] = arry[i], arry[min]</span><br><span class="line">   <span class="keyword">return</span> arry</span><br></pre></td></tr></table></figure>
<h3 id="3-插入排序"><a href="#3-插入排序" class="headerlink" title="3. 插入排序"></a>3. 插入排序</h3><p>插入排序的工作原理是，对于每个未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。</p>
<p>步骤：</p>
<ol>
<li>从第一个元素开始，该元素可以认为已经被排序</li>
<li>取出下一个元素，在已经排序的元素序列中从后向前扫描</li>
<li>如果被扫描的元素（已排序）大于新元素，将该元素后移一位</li>
<li>重复步骤3，直到找到已排序的元素小于或者等于新元素的位置</li>
<li>将新元素插入到该位置后</li>
<li>重复步骤2~5</li>
</ol>
<p>代码实现：</p>
<pre><code class="python"><span class="function"><span class="keyword">def</span> <span class="title">insert_sort</span><span class="params">(arry)</span>:</span>
    n = len(arry)
    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, n):
        <span class="keyword">if</span> arry[i] &lt; arry[i<span class="number">-1</span>]:
            temp = arry[i]
            index = i   <span class="comment"># 待插入的下标</span>
            <span class="keyword">for</span> j <span class="keyword">in</span> range(i<span class="number">-1</span>, <span class="number">-1</span>, <span class="number">-1</span>): <span class="comment"># 从i-1 循环到 0 (包括0)</span>
                <span class="keyword">if</span> arry[j] &gt; temp:
                    arry[j+<span class="number">1</span>] = arry[j]
                    index = j
                <span class="keyword">else</span>:
                    <span class="keyword">break</span>
            arry[index] = temp
    <span class="keyword">return</span> arry
</code></pre>
<h3 id="4-希尔排序"><a href="#4-希尔排序" class="headerlink" title="4. 希尔排序"></a>4. 希尔排序</h3><p>希尔排序，也称递减增量排序算法，实质是分组插入排序。</p>
<p>希尔排序的基本思想是：将数组列在一个表中并对列分别进行插入排序，重复这过程，不过每次用更长的列（步长更长了，列数更少了）来进行。最后整个表就只有一列了。将数组转换至表是为了更好地理解这算法，算法本身还是使用数组进行排序。</p>
<p>例如，假设有这样一组数[ 13 14 94 33 82 25 59 94 65 23 45 27 73 25 39 10 ]，如果我们以步长为5开始进行排序，我们可以通过将这列表放在有5列的表中来更好地描述算法，这样他们就应该看起来是这样：</p>
<pre><code>13 14 94 33 82
25 59 94 65 23
45 27 73 25 39
10
</code></pre><p>然后我们对每列进行排序：</p>
<pre><code>10 14 73 25 23
13 27 94 33 39
25 59 94 65 82
45
</code></pre><p>将上述四行数字，依序接在一起时我们得到：[ 10 14 73 25 23 13 27 94 33 39 25 59 94 65 82 45 ]。这时10已经移至正确位置了，然后再以3为步长进行排序：</p>
<pre><code>10 14 73
25 23 13
27 94 33
39 25 59
94 65 82
45
</code></pre><p>排序之后变为：</p>
<pre><code>10 14 13
25 23 33
27 25 59
39 65 73
45 94 82
94
</code></pre><p>最后以1步长进行排序（此时就是简单的插入排序了）。</p>
<p>代码实现：</p>
<pre><code class="python"><span class="function"><span class="keyword">def</span> <span class="title">shell_sort</span><span class="params">(arry)</span>:</span>
    n = len(arry)
    gap = n/<span class="number">2</span>    <span class="comment"># 初始步长</span>
    <span class="keyword">while</span> gap &gt; <span class="number">0</span>:
        <span class="keyword">for</span> i <span class="keyword">in</span> range(gap, n):     <span class="comment"># 对每一列进行插入排序, 从gap 到 n-1</span>
            temp = arry[i]
            j = i
            <span class="keyword">while</span> j &gt;= gap <span class="keyword">and</span> arry[j-gap] &gt; temp: <span class="comment"># 插入排序</span>
                arry[j] = arry[j-gap]
                j -= gap
            arry[j] = temp
        gap /= <span class="number">2</span>
    <span class="keyword">return</span> arry
</code></pre>
<h3 id="5-归并排序"><a href="#5-归并排序" class="headerlink" title="5. 归并排序"></a>5. 归并排序</h3><p>归并排序是采用分治法的一个非常典型的应用。归并排序的思想就是先递归分解数组，再合并数组。</p>
<p>先考虑合并两个有序数组，基本思路是比较两个数组的最前面的数，谁小就先取谁，取了后相应的指针就往后移一位。然后再比较，直至一个数组为空，最后把另一个数组的剩余部分复制过来即可。</p>
<p>再考虑递归分解，基本思路是将数组分解成left和right，如果这两个数组内部数据是有序的，那么就可以用上面合并数组的方法将这两个数组合并排序。如何让这两个数组内部是有序的？可以再二分，直至分解出的小组只含有一个元素时为止，此时认为该小组内部已有序。然后合并排序相邻二个小组即可。</p>
<p>代码实现：</p>
<pre><code class="python"><span class="function"><span class="keyword">def</span> <span class="title">merge</span><span class="params">(left, right)</span>:</span>
    l, r = <span class="number">0</span>, <span class="number">0</span>
    result = []
    <span class="keyword">while</span> l &lt; len(left) <span class="keyword">and</span> r &lt; len(right):
      <span class="keyword">if</span> left[l] &lt; right[r]:
          result.append(left[l])
          l += <span class="number">1</span>
      <span class="keyword">else</span>:
          result.append(right[r])
          r += <span class="number">1</span>
    result += left[l:]
    result += right[r:]
    <span class="keyword">return</span> result

<span class="function"><span class="keyword">def</span> <span class="title">merge_sort</span><span class="params">(arry)</span>:</span>
    n = len(arry)
    <span class="keyword">if</span> n &lt;= <span class="number">1</span>:
        <span class="keyword">return</span> arry
    num = n/<span class="number">2</span>
    left = merge_sort(arry[:num])
    right = merge_sort(arry[num:])
    <span class="keyword">return</span> merge(left, right)
</code></pre>
<h3 id="6-快速排序"><a href="#6-快速排序" class="headerlink" title="6. 快速排序"></a>6. 快速排序</h3><p>快速排序是面试中被考的频率最高的排序算法了。快速排序通常明显比同为Ο(nlogn)的其他算法更快，因此常被采用，而且快排采用了分治法的思想，所以在很多笔试面试中能经常看到快排的影子。可见掌握快排的重要性。</p>
<p>步骤：</p>
<ol>
<li>从数列中挑出一个元素作为基准数。</li>
<li>分区过程，将比基准数大的放到右边，小于或等于它的数都放到左边。</li>
<li>再对左右区间递归执行第二步，直至各区间只有一个数</li>
</ol>
<p>代码实现：</p>
<pre><code class="python">
<span class="function"><span class="keyword">def</span> <span class="title">quick_sort</span><span class="params">(arry)</span>:</span>
    <span class="keyword">return</span> qsort(arry, <span class="number">0</span>, len(arry)<span class="number">-1</span>)

<span class="function"><span class="keyword">def</span> <span class="title">qsort</span><span class="params">(arry, left, right)</span>:</span>
    <span class="comment"># arry为待排序数组,left为该数组左边界,right为该数组右边界</span>
    <span class="keyword">if</span> left &gt;= right:
        <span class="keyword">return</span> arry
    <span class="comment"># 取最左边的数为基准数</span>
    key = arry[left]
    lp = left
    rp = right
    <span class="keyword">while</span> lp &lt; rp:
        <span class="keyword">while</span> arry[rp] &gt;= key <span class="keyword">and</span> lp &lt; rp:
            rp -= <span class="number">1</span>
        <span class="keyword">while</span> arry[lp] &lt;= key <span class="keyword">and</span> lp &lt; rp:
            lp += <span class="number">1</span>
        arry[lp], arry[rp] = arry[rp], arry[lp]
    arry[left], arry[rp] = arry[rp], arry[left]
    qsort(arry, left, lp - <span class="number">1</span>)
    qsort(arry, rp + <span class="number">1</span>, right)
    <span class="keyword">return</span> arry
</code></pre>
<h3 id="7-堆排序"><a href="#7-堆排序" class="headerlink" title="7. 堆排序"></a>7. 堆排序</h3><p>堆排序在 top K 问题中使用比较频繁。堆排序是采用二叉堆的数据结构来实现的，虽然实质上还是一维数组。二叉堆是一个近似完全二叉树。</p>
<p>二叉堆具有以下性质：</p>
<ol>
<li><p>父节点的键值总是大于或等于(小于或等于)任何一个子节点的键值。</p>
</li>
<li><p>每个节点的左右子树都是一个二叉堆(都是最大堆或最小堆)。</p>
</li>
</ol>
<p>步骤：</p>
<ol>
<li><p>构造最大堆（Build_Max_Heap）：若数组下标范围为0~n，考虑到单独一个元素是大根堆，则从下标n/2开始的元素均为大根堆。于是只要从n/2-1开始，向前依次构造大根堆，这样就能保证，构造到某个节点时，它的左右子树都已经是大根堆。</p>
</li>
<li><p>堆排序（HeapSort）：由于堆是用数组模拟的。得到一个大根堆后，数组内部并不是有序的。因此需要将堆化数组有序化。思想是移除根节点，并做最大堆调整的递归运算。第一次将heap[0]与heap[n-1]交换，再对heap[0…n-2]做最大堆调整。第二次将heap[0]与heap[n-2]交换，再对heap[0…n-3]做最大堆调整。重复该操作直至heap[0]和heap[1]交换。由于每次都是将最大的数并入到后面的有序区间，故操作完后整个数组就是有序的了。</p>
</li>
<li><p>最大堆调整（Max_Heapify）：该方法是提供给上述两个过程调用的。目的是将堆的末端子节点作调整，使得子节点永远小于父节点。</p>
</li>
</ol>
<p>代码实现：</p>
<pre><code class="python">
<span class="function"><span class="keyword">def</span> <span class="title">heap_sort</span><span class="params">(ary)</span> :</span>
    n = len(ary)
    <span class="comment"># 最后一个非叶子节点</span>
    first = int(n/<span class="number">2</span><span class="number">-1</span>)
    <span class="comment"># 构造大根堆</span>
    <span class="keyword">for</span> start <span class="keyword">in</span> range(first, <span class="number">-1</span>, <span class="number">-1</span>):     
        max_heapify(ary, start, n<span class="number">-1</span>)
    <span class="keyword">for</span> end <span class="keyword">in</span> range(n<span class="number">-1</span>, <span class="number">0</span>, <span class="number">-1</span>):
        <span class="comment"># 堆排，将大根堆转换成有序数组</span>
        ary[end], ary[<span class="number">0</span>] = ary[<span class="number">0</span>], ary[end]
        max_heapify(ary, <span class="number">0</span>, end<span class="number">-1</span>)
    <span class="keyword">return</span> ary

<span class="string">'''
最大堆调整：将堆的末端子节点作调整，使得子节点永远小于父节点
start为当前需要调整最大堆的位置，end为调整边界
'''</span>
<span class="function"><span class="keyword">def</span> <span class="title">max_heapify</span><span class="params">(ary, start, end)</span>:</span>
    root = start
    <span class="keyword">while</span> <span class="keyword">True</span>:
        <span class="comment"># 调整节点的子节点</span>
        child = root*<span class="number">2</span> + <span class="number">1</span>
        <span class="keyword">if</span> child &gt; end:
            <span class="keyword">break</span>
        <span class="keyword">if</span> child+<span class="number">1</span> &lt;= end <span class="keyword">and</span> ary[child] &lt; ary[child+<span class="number">1</span>]:
            <span class="comment"># 取较大的子节点</span>
            child += <span class="number">1</span>
        <span class="comment"># 较大的子节点成为父节点</span>
        <span class="keyword">if</span> ary[root] &lt; ary[child]:
            <span class="comment"># 交换</span>
            ary[root], ary[child] = ary[child], ary[root]
            root = child
        <span class="keyword">else</span>:
            <span class="keyword">break</span>
</code></pre>
<h3 id="8-总结"><a href="#8-总结" class="headerlink" title="8. 总结"></a>8. 总结</h3><p>下面为七种经典排序算法指标对比情况：</p>
<p><img src="/img/classicalsort.png" alt=""></p>
<h3 id="9-参考资料"><a href="#9-参考资料" class="headerlink" title="9. 参考资料"></a>9. 参考资料</h3><ul>
<li><p><a href="http://wuchong.me/blog/2014/02/09/algorithm-sort-summary/" target="_blank" rel="external">经典排序算法总结与实现</a></p>
</li>
<li><p><a href="http://blog.csdn.net/morewindows/article/details/7961256" target="_blank" rel="external">白话经典算法系列</a></p>
</li>
</ul>
<p>注：本文所有源代码已共享到<a href="https://github.com/pengshuang/Leetcode/tree/master/classical%20alogrithm" target="_blank" rel="external">GitHub</a>。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/26/TCP学习-三/" itemprop="url">
                  IP协议学习(三):路由控制和IPv4数据包
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-09-26T18:47:11+08:00" content="2016-09-26">
              2016-09-26
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/读书笔记/" itemprop="url" rel="index">
                    <span itemprop="name">读书笔记</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/09/26/TCP学习-三/" class="leancloud_visitors" data-flag-title="IP协议学习(三):路由控制和IPv4数据包">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1-路由控制表"><a href="#1-路由控制表" class="headerlink" title="1. 路由控制表"></a>1. 路由控制表</h3><p>路由控制表中记录着网络地址与下一步应该发送至路由器的地址。在发送IP包时，首先要确定IP包首部中的目标地址，再从路由控制表中找到与该地址具有相同网络地址的记录，根据该记录将IP包转发给相应的下一个路由器。如果路由控制表中存在多条相同网络地址的记录，就选择一个最为吻合的网络地址，即最长匹配。</p>
<h3 id="2-默认路由"><a href="#2-默认路由" class="headerlink" title="2. 默认路由"></a>2. 默认路由</h3><p>如果一张路由表中包含所有的网络及其子网的信息，将会造成无端的浪费。这时，默认路由是不错的选择。默认路由是指路由表中任何一个地址都能与之匹配的记录。</p>
<h3 id="3-主机路由"><a href="#3-主机路由" class="headerlink" title="3. 主机路由"></a>3. 主机路由</h3><p>“IP地址/32” 也被称为主机路由。例如，192.168.153.15/32 就是一种主机路由。它的意思是整个IP地址的所有位都将参与路由。进行主机路由，意味着要基于主机上网卡上配置的IP地址本身，而不是基于该地址的网络地址部分进行路由。</p>
<h3 id="4-环回地址"><a href="#4-环回地址" class="headerlink" title="4. 环回地址"></a>4. 环回地址</h3><p>环回地址是同一台计算机上的程序之间进行网络通信时所使用的一个默认地址。计算机使用一个特殊的IP地址127.0.0.1作为环回地址。与该地址具有相同意义的一个叫做localhost的主机名。使用这个IP或主机名时，数据包不会流向网络。</p>
<h3 id="5-路由控制表的聚合"><a href="#5-路由控制表的聚合" class="headerlink" title="5. 路由控制表的聚合"></a>5. 路由控制表的聚合</h3><p>利用网络地址的比特分布可以有效地进行分层配置。对内即使有多个子网掩码，对外呈现出的也是同一个网络地址。这样可以更好的构建网络，通过路由信息的聚合可以有效地减少路由表的条目。下图展示一个简单的路由聚合的例子。</p>
<p><img src="/img/juhe.png" alt=""></p>
<h3 id="6-IPv4首部"><a href="#6-IPv4首部" class="headerlink" title="6. IPv4首部"></a>6. IPv4首部</h3><p>IP首部包含着用于IP协议进行发包控制时所有的必要信息。下图展示了一个IP数据包格式(IPv4)。</p>
<p><img src="/img/ipv4.png" alt=""></p>
<p>下面对IP首部各部分一一进行介绍。</p>
<h4 id="（1）版本"><a href="#（1）版本" class="headerlink" title="（1）版本"></a>（1）版本</h4><p>没什么实际意义。。。忽略</p>
<h4 id="（2）首部长度"><a href="#（2）首部长度" class="headerlink" title="（2）首部长度"></a>（2）首部长度</h4><p>由4比特构成，表明IP首部的大小，单位为4字节(32比特)，对应没有可选项的IP包，首部长度则设置为5，即没有可选项时，IP首部的长度为20字节(4*5=20)。</p>
<h4 id="（3）区分服务（TOS）"><a href="#（3）区分服务（TOS）" class="headerlink" title="（3）区分服务（TOS）"></a>（3）区分服务（TOS）</h4><p>由8比特构成，用来表明服务质量。用0、1、2这三位来表示0~7的优先度。从0到7表示优先度从低到高。每一位具体含义如下所示。</p>
<p><img src="/img/tos.png" alt=""></p>
<h4 id="（4）总长度（Total-Length）"><a href="#（4）总长度（Total-Length）" class="headerlink" title="（4）总长度（Total Length）"></a>（4）总长度（Total Length）</h4><p>表示IP首部与数据部分合起来的总字节数。该字段长16比特。因此IP包的最大长度为65535。</p>
<h4 id="（5）标识-（ID：Identification）"><a href="#（5）标识-（ID：Identification）" class="headerlink" title="（5）标识 （ID：Identification）"></a>（5）标识 （ID：Identification）</h4><p>由16比特构成，用于分片重组。同一个分片的标识值相同，不同分片的标识值不同。通常，没发送一个IP包，它的值也逐渐递增。此外，即使ID相同，如果目标地址、源地址或协议不同的话，也会被认为是不同的分片。</p>
<h4 id="（6）标志（Flags）"><a href="#（6）标志（Flags）" class="headerlink" title="（6）标志（Flags）"></a>（6）标志（Flags）</h4><p>由3比特构成，表示包被分片的相关信息。每一位的具体含义如下：</p>
<table>
<thead>
<tr>
<th>比特</th>
<th>含义</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>未使用</td>
</tr>
<tr>
<td>1</td>
<td>指示是否进行分片。0-可以分片；1-不能分片</td>
</tr>
<tr>
<td>2</td>
<td>包被分片的情况下，表示是否为最后一个包。0-最后一个分片的包；1-分片中段的包</td>
</tr>
</tbody>
</table>
<h4 id="（7）片偏移（FO-Fragment-Offset"><a href="#（7）片偏移（FO-Fragment-Offset" class="headerlink" title="（7）片偏移（FO: Fragment Offset)"></a>（7）片偏移（FO: Fragment Offset)</h4><p>由13比特构成，用来标识被分片的每一个分段相对于原始数据的位置。第一个分片对应的值为0.由于FO域占13位，因此最多可以表示8192个相对位置。单位为8字节，因此最大可以表示原始数据为65536字节。</p>
<h4 id="（8）生存时间-TTL"><a href="#（8）生存时间-TTL" class="headerlink" title="（8）生存时间 (TTL)"></a>（8）生存时间 (TTL)</h4><p>由8比特构成，在实际中表示可以中转多少个路由器。每经过一个路由器，TTL会减少1，直到变成0则丢弃该包。</p>
<h4 id="（9）协议（Protocol）"><a href="#（9）协议（Protocol）" class="headerlink" title="（9）协议（Protocol）"></a>（9）协议（Protocol）</h4><p>由8比特构成，表示IP首部的下一个首部隶属于哪个协议。</p>
<h4 id="（10）首部校验和"><a href="#（10）首部校验和" class="headerlink" title="（10）首部校验和"></a>（10）首部校验和</h4><p>由16比特（2个字节构成），也叫IP首部校验和。该字段只校验数据报的首部，不校验数据部分。它主要用来确保IP数据报不被破坏。校验和的计算过程，首先要将校验和的所有位置设置为0，然后以16比特为单位划分IP首部，并用1补数计算所有16位字的和。最后将所得到这个和1的补数赋给首部校验和字段。</p>
<h4 id="（11）源地址"><a href="#（11）源地址" class="headerlink" title="（11）源地址"></a>（11）源地址</h4><p>由32位比特（4个字节）构成，表示发送端IP地址。</p>
<h4 id="（12）目标地址"><a href="#（12）目标地址" class="headerlink" title="（12）目标地址"></a>（12）目标地址</h4><p>由32位比特（4个字节）构成，表示接收端IP地址。 </p>
<h4 id="（13）数据"><a href="#（13）数据" class="headerlink" title="（13）数据"></a>（13）数据</h4><p>存入数据。将IP上层协议的首部也作为数据进行处理。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/25/IP地址基础知识/" itemprop="url">
                  IP协议学习(二):IP地址基础知识
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-09-25T21:15:14+08:00" content="2016-09-25">
              2016-09-25
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/读书笔记/" itemprop="url" rel="index">
                    <span itemprop="name">读书笔记</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/09/25/IP地址基础知识/" class="leancloud_visitors" data-flag-title="IP协议学习(二):IP地址基础知识">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>在TCP/IP通信时，用IP地址识别主机和路由器。为了保证正常通信，有必要为每个设备识别主机和路由器。在互联网通信中，全世界都必须设定正确的IP地址。否则，根本无法实现正常的通信。</p>
<h3 id="1-IP地址的定义"><a href="#1-IP地址的定义" class="headerlink" title="1. IP地址的定义"></a>1. IP地址的定义</h3><p>IP地址（IPv4）由32位正整数来表示。TCP/IP通信要求将这样的IP地址分配给每一个参与通信的主机。</p>
<p>IP地址由 ”网络标识（网络地址）” 和 “主机标识（主机地址）”两部分组成。如下图所示，网络标识在数据链路的每个段配置不同的值。网络标识必须保证相互连接的每个段的地址不相重复。而相同段内相连的主机必须有相同的网络地址。IP地址的 “主机标识” 则不允许在同一个网段内重复出现。</p>
<p>通过下图也可以看出，IP包被转发到途中某个路由器时，正是利用目标IP地址的网络标识进行路由。因为即使不看主机标识，只要一见到网络标识就能判断出是否为该网段内的主机。网络标识和主机标识通常通过子网掩码（网络前缀）区分。</p>
<p><img src="/img/IPnet.png" alt=""></p>
<h3 id="2-IP地址的分类"><a href="#2-IP地址的分类" class="headerlink" title="2. IP地址的分类"></a>2. IP地址的分类</h3><p><img src="/img/IPaddress.png" alt=""></p>
<p>IP地址分为四个级别，分为A类，B类，C类，D类。它根据IP地址中从第1位到第4位的比特列对网络标识和主机标识进行区分。</p>
<h4 id="A类地址"><a href="#A类地址" class="headerlink" title="A类地址"></a>A类地址</h4><p>A类IP地址是首位以 “0” 开头的地址。从第1位到第8位是它的网络标识。用十进制表示的话，0.0.0.0 ~ 127.0.0.0 是A类的网络地址。A类地址的后24位相当于主机标识。因此，一个网段内可容纳的主机地址上限为16，777，214个。</p>
<h4 id="B类地址"><a href="#B类地址" class="headerlink" title="B类地址"></a>B类地址</h4><p>B类IP地址是前两位为 “10” 的地址。从第1位到第16位是它的网络标识。用十进制表示的话，128.0.0.1 ~ 191.255.0.0是B类的网络地址。B类网络地址的后16位相当于主机标识。因此，一个网段内可容纳的主机上限为65，534个。</p>
<h4 id="C类地址"><a href="#C类地址" class="headerlink" title="C类地址"></a>C类地址</h4><p>C类IP地址是前三位为 “110” 的地址。从第1位到第24位是它的网络标识。用十进制表示的话，192.168.0.0 ~ 239.255.255.0 是C类的网络地址。C类地址的后8位相当于主机标识。因此，一个网段内可容纳的主机地址上限为254个。</p>
<h4 id="D类地址"><a href="#D类地址" class="headerlink" title="D类地址"></a>D类地址</h4><p>D类IP地址是前四位为 “1110” 地址。从第1位到第32位是它的网络标识。用十进制表示的话，224.0.0.0 ~ 239.255.255.255 是D类的网络地址。D类地址没有主机标识，常被用于多播。</p>
<p><strong>注意</strong></p>
<p>主机地址全部为0只有在表示对应的网络地址或IP地址不可获知的情况下才使用。而全部为1的主机地址通常作为广播地址。</p>
<h3 id="3-广播地址"><a href="#3-广播地址" class="headerlink" title="3. 广播地址"></a>3. 广播地址</h3><p>广播地址用于在同一个链路中相互连接的主机之间发生数据。IP地址中的主机地址部分全部设置为1，就成了广播地址。</p>
<p>广播地址分为本地广播和直接广播两种。在本网络内的广播为本地广播，这个广播地址的IP包会被路由器屏蔽；在不同网络之间的广播叫做之间广播。</p>
<h3 id="4-IP多播"><a href="#4-IP多播" class="headerlink" title="4. IP多播"></a>4. IP多播</h3><h4 id="同时发送提供效率"><a href="#同时发送提供效率" class="headerlink" title="同时发送提供效率"></a>同时发送提供效率</h4><p>多播用于将包发送给特点组内的所有主机。由于其之间使用IP协议，因此也不存在可靠传输。</p>
<h4 id="IP多播与地址"><a href="#IP多播与地址" class="headerlink" title="IP多播与地址"></a>IP多播与地址</h4><p>多播使用D类地址。因此，如果从首位开始到第4位是“1110”，就可以认为是多播地址。而剩下的28位可以成为多播的组编号。</p>
<h3 id="5-子网掩码"><a href="#5-子网掩码" class="headerlink" title="5. 子网掩码"></a>5. 子网掩码</h3><p><img src="/img/mask.png" alt=""></p>
<p>引入了子网以后，一个IP地址就有了两种识别码。一是IP地址本身，另一个是表示网络内部的子网掩码。子网掩码用二进制的方式表示的话，也是一个32位的数字。它对应IP地址网络标识部分的位全部为“1”，对应IP地址主机标识的部分则全部为“0”。由此，一个IP地址可以不再受限于自己的类别，而是可以用这样的子网掩码自由的定位自己的网络标识长度。当然，子网掩码必须是IP地址的首位开始连续的“1”。表示方法如下：</p>
<p>IP地址：    172.20.100.52/26</p>
<p>子网掩码：    255.255.255.192</p>
<p>网络地址：  172.20.100.0</p>
<p>广播地址：    172.20.100.63</p>
<p><strong>子网掩码可以灵活的指定网络标识的长度</strong></p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/21/谷歌三篇论文学习-MapReduce/" itemprop="url">
                  谷歌三篇论文学习(一): MapReduce
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-09-21T15:05:34+08:00" content="2016-09-21">
              2016-09-21
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/论文/" itemprop="url" rel="index">
                    <span itemprop="name">论文</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/09/21/谷歌三篇论文学习-MapReduce/" class="leancloud_visitors" data-flag-title="谷歌三篇论文学习(一): MapReduce">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h3><p><strong>MapReduce</strong>  是一个编程模型，也是一个处理和生产超大数据集的算法模型的相关实现。用户首先创建一个 <strong>Map</strong> 函数处理一个基于 <strong>key/value pair</strong> 的数据集合，输出中间的基于 <strong>key/value pair</strong> 的数据集合；然后再创建一个 <strong>Reduce</strong> 函数来用来合并所有的具有相同中间<strong>key</strong>值的中间<strong>values</strong>值。现实世界中有很多满足上述处理模型的例子。</p>
<p><strong>MapReduce</strong> 编程模型的原理是:利用一个输入 <strong>key/value pair</strong> 集合来产生一个输出的 <strong>key/value pair</strong> 集合。 <strong>MapReduce</strong>  库的用户用两个函数表达这个计算: <strong>Map</strong> 和 <strong>Reduce</strong>。</p>
<p>用户自定义的 <strong>Map</strong> 函数接受一个输入的 <strong>key/value pair</strong> 值,然后产生一个中间 <strong>key/value pair</strong> 值的集合。 <strong>MapReduce</strong> 库把所有具有相同中间 key 值的中间 <strong>value</strong> 值集合在一起后传递给 <strong>Reduce</strong> 函数。</p>
<p>用户自定义的 <strong>Reduce</strong> 函数接受一个中间 <strong>key</strong> 的值和相关的一个 <strong>value</strong> 值的集合。 <strong>Reduce</strong> 函数合并这些 <strong>value</strong> 值，形成一个较小的 <strong>value</strong> 值的集合。一般的，每次 <strong>Reduce</strong> 函数调用只产生 0 或 1 个输出 <strong>value</strong> 值。通 常我们通过一个迭代器把中间 <strong>value</strong> 值提供给 <strong>Reduce</strong> 函数，这样我们就可以处理无法全部放入内存中的大量的 <strong>value</strong> 值的集合。</p>
<pre><code>map(String key, String value):
    // key: document name
    // value: document contents 
    for each word w in value:
        EmitIntermediate(w, 1);

reduce(String key, Iterator values): 
    // key: a word
    // values: a list of counts 
    int result = 0;
    for each v in values:
        result += ParseInt(v); 
    Emit(AsString(result));
</code></pre><p><strong>Map</strong> 函数输出文档中的每个词、以及这个词的出现次数（在这个简单的例子里就是1）。<strong>Reduce</strong> 函数把Map函数产生的每一个特定的词的计数累加起来。</p>
<h3 id="MapReduce编程模型应用"><a href="#MapReduce编程模型应用" class="headerlink" title="MapReduce编程模型应用"></a>MapReduce编程模型应用</h3><p>分布式的Grep：Map函数输出匹配模式的一行，Reduce函数是一个恒等函数，即把中间数据复制到输出。</p>
<p>计算URL访问频率：Map函数处理日志中web页面请求的记录，然后输出(URL,1)。Reduce 函数把相同的value值都累加起来，产生(URL，记录总数)结果。</p>
<p>倒转网络链接图：Map函数在源页面(source)中搜索所有的链接目标(target)并输出为(target, source)。Reduce 函数把给定链接目标(target)的链接组合成一个列表，输出(target, list(source))。</p>
<p>其他的一些应用场景有，每个主机的检索词向量，倒排索引以及分布式排序。</p>
<h3 id="MapReduce实现"><a href="#MapReduce实现" class="headerlink" title="MapReduce实现"></a>MapReduce实现</h3><p>上图展示了<strong>MapReduce</strong> 实现中操作的全部流程。当用户调用 <strong>MapReduce</strong> 函数时，将发生下面的一 系列动作(下面的序号和图中的序号一一对应):</p>
<ol>
<li><p>用户程序首先调用的 <strong>MapReduce</strong> 库将输入文件分成 M 个数据片度,每个数据片段的大小一般从 16MB 到 64MB(可以通过可选的参数来控制每个数据片段的大小)。然后用户程序在集群中创建大量的程序副本。</p>
</li>
<li><p>这些程序副本中的有一个特殊的程序——<strong>master</strong>。副本中其它的程序都是 <strong>worker</strong> 程序，由 <strong>master</strong> 分配 任务。有 M 个 <strong>Map</strong> 任务和 R 个 <strong>Reduce</strong> 任务将被分配，<strong>master</strong> 将一个 <strong>Map</strong> 任务或 <strong>Reduce</strong> 任务分配给一个空闲的 <strong>worker</strong>。</p>
</li>
<li><p>被分配了 <strong>Map</strong> 任务的 <strong>worker</strong> 程序读取相关的输入数据片段，从输入的数据片段中解析出 <strong>key/value pair</strong>，然后把 <strong>key/value pair</strong> 传递给用户自定义的 <strong>Map</strong> 函数，由 <strong>Map</strong> 函数生成并输出的中间 <strong>key/value pair</strong>，并缓存在内存中。</p>
</li>
<li><p>缓存中的 <strong>key/value pair</strong> 通过分区函数分成 R 个区域,之后周期性的写入到本地磁盘上。缓存的 <strong>key/value pair</strong> 在本地磁盘上的存储位置将被回传给 <strong>master</strong>，由 <strong>master</strong> 负责把这些存储位置再传送给 <strong>Reduce worker</strong>。</p>
</li>
<li><p>当 <strong>Reduce worker</strong> 程序接收到 <strong>master</strong> 程序发来的数据存储位置信息后，使用 RPC 从 <strong>Map worker</strong> 所在主机的磁盘上读取这些缓存数据。当 <strong>Reduce worker</strong> 读取了所有的中间数据后，通过对 <strong>key</strong> 进行排序后使得具有相同 <strong>key</strong> 值的数据聚合在一起。由于许多不同的 <strong>key</strong> 值会映射到相同的 <strong>Reduce</strong> 任务上，因此必须进行排序。如果中间数据太大无法在内存中完成排序,那么就要在外部进行排序。</p>
</li>
<li><p><strong>Reduce worker</strong> 程序遍历排序后的中间数据,对于每一个唯一的中间 <strong>key</strong> 值，<strong>Reduce worker</strong> 程序将这 个 <strong>key</strong> 值和它相关的中间 <strong>value</strong> 值的集合传递给用户自定义的 <strong>Reduce</strong> 函数。<strong>Reduce</strong> 函数的输出被追加到所属分区的输出文件。</p>
</li>
<li><p>当所有的 <strong>Map</strong> 和 <strong>Reduce</strong> 任务都完成之后，<strong>master</strong> 唤醒用户程序。在这个时候,在用户程序里的对 <strong>MapReduce</strong> 调用才返回。</p>
</li>
</ol>
<p>在成功完成任务之后，<strong>Mapreduce</strong> 的输出存放在R个输出文件中（对应每个 <strong>Reduce</strong> 任务产生一个输出文件，文件名由用户指定）。一般情况下，用户不需要将这R个输出文件合并成一个文件——他们经常把这些文件作为另外一个 <strong>Mapreduce</strong> 的输入， 或者在另外一个可以处理多个分割文件的分布式应用中使用。</p>
<h3 id="Master的数据结构"><a href="#Master的数据结构" class="headerlink" title="Master的数据结构"></a>Master的数据结构</h3><p><strong>Master</strong> 持有一些数据结构，它存储每一个Map和Reduce任务（空闲、工作中或完成），以及Worker机器（非空闲任务的机器）的标识。</p>
<p><strong>Master</strong> 就像一个数据管道，中间文件存储区域的位置信息通过这个管道从Map传递到Reduce。因此，对于每个已经完成的Map任务，<strong>Master</strong> 存储了Map任务产生的R个中间文件存储区域的大小和位置。当Map任务完成时，<strong>Master</strong>接收到位置和大小的更新信息，这些信息被逐步递增的推送给那些正在工作的Reduce任务。</p>
<h3 id="容错机制"><a href="#容错机制" class="headerlink" title="容错机制"></a>容错机制</h3><p><strong>Master</strong> 周期性的 ping 每个 <strong>worker</strong>。如果在一个约定的时间范围内没有收到 <strong>worker</strong> 返回的消息，<strong>Master</strong> 将把这个任务标记为失效。所有由这个失效的 <strong>worker</strong> 完成的 <strong>Map</strong> 任务被重设为初始的空闲状态，之后这些任务就可以被安排给其他的 <strong>worker</strong>。 同样的，<strong>worker</strong> 失效时正在运行的 <strong>Map</strong> 或 <strong>Reduce</strong> 任务也将被重新置为空闲状态，等待重新调度。</p>
<p>当 <strong>worker</strong> 故障时，由于已经完成的 <strong>Map</strong> 任务的输出存储在这台机器上，<strong>Map</strong> 任务的输出已不接访问了，因此需要重新执行。而已经完成的 Reduce 任务的输出存储在全局文件系统上， 因此不需要再次执行。</p>
<p>当一个 <strong>Map</strong> 任务首先被 <strong>worker A</strong> 执行，之后由于 <strong>worker A</strong> 失效了又被调度到 <strong>worker B</strong> 执行，这个“重新执行”的动作会被通知给所有执行 <strong>Reduce</strong> 任务的 <strong>worker</strong>。任何还没有从 <strong>worker A</strong> 读取数据的 <strong>Reduce</strong> 任务 将从 <strong>worker B</strong> 读取数据。</p>
<p><strong>MapReduce</strong> 可以处理大规模 <strong>worker</strong> 失效的情况。比如，在一个 <strong>MapReduce</strong> 操作执行期间，在正在运行的集群上进行网络维护引起80台机器在几分钟内不可访问了，<strong>MapReduce master</strong> 只需要简单的再次执行那些不可访问的 <strong>worker</strong> 完成的工作，之后继续执行未完成的任务，直到最终完成这个 <strong>MapReduce</strong>  操作。</p>
<h3 id="失效方面的处理机制"><a href="#失效方面的处理机制" class="headerlink" title="失效方面的处理机制"></a>失效方面的处理机制</h3><p>当用户提供的 <strong>Map</strong> 和 <strong>Reduce</strong> 操作是输入确定性函数(即相同的输入产生相同的输出)时，我们的分布式实现在任何情况下的输出都和所有程序没有出现任何错误、顺序的执行产生的输出是一样的。</p>
<p>我们依赖对 <strong>Map</strong> 和 <strong>Reduce</strong> 任务的输出是原子提交的来完成这个特性。每个工作中的任务把它的输出写到私有的临时文件中。每个 <strong>Reduce</strong> 任务生成一个这样的文件，而每个 <strong>Map</strong> 任务则生成 R 个这样的文件(一个 <strong>Reduce</strong> 任务对应一个文件)。当一个 <strong>Map</strong> 任务完成的时，<strong>worker</strong> 发送一个包含 R 个临时文件名的完成消息给 <strong>master</strong>。如果 <strong>master</strong> 从一个已经完成的 <strong>Map</strong> 任务再次接收到到一个完成消息，<strong>master</strong> 将忽略这个消息；否则，<strong>Master</strong> 将这 R 个文件的名字记录在数据结构里。</p>
<p>当 <strong>Reduce</strong> 任务完成时，<strong>Reduce worker</strong> 进程以原子的方式把临时文件重命名为最终的输出文件。如果同 一个 <strong>Reduce</strong> 任务在多台机器上执行,针对同一个最终的输出文件将有多个重命名操作执行。我们依赖底层文 件系统提供的重命名操作的原子性来保证最终的文件系统状态仅仅包含一个 <strong>Reduce</strong> 任务产生的数据。</p>
<h3 id="分区函数"><a href="#分区函数" class="headerlink" title="分区函数"></a>分区函数</h3><p><strong>MapReduce</strong> 的使用者通常会指定 <strong>Reduce</strong> 任务和 <strong>Reduce</strong> 任务输出文件的数量(R)。我们在中间 key 上使用分区函数来对数据进行分区，之后再输入到后续任务执行进程。一个缺省的分区函数是使用 <strong>hash</strong> 方法(比如，hash(key) mod R)进行分区。hash方法能产生非常平衡的分区。然而，有的时候，其它的一些分区函数对 <strong>key</strong> 值进行的分区将非常有用。比如，输出的 <strong>key</strong> 值是 <strong>URLs</strong>，我们希望每个主机的所有条目保持在同一个输出文件中。为了支持类似的情况，<strong>MapReduce</strong> 库的用户需要􏰁供专门的分区函数。例如，使用“hash(Hostname(urlkey)) mod R”作为分区函数就可以把所有来自同一个主机的 <strong>URLs</strong> 保存在同一个输出文件中。</p>
<h3 id="顺序保证"><a href="#顺序保证" class="headerlink" title="顺序保证"></a>顺序保证</h3><p>我们确保在给定的分区中，中间 <strong>key/value pair</strong> 数据的处理顺序是按照 <strong>key</strong> 值增量顺序处理的。这样的顺序保证对每个分区生成一个有序的输出文件，这对于需要对输出文件按 <strong>key</strong> 值随机存取的应用非常有意义，对在排序输出的数据集也很有帮助。</p>
<h3 id="Combiner-函数"><a href="#Combiner-函数" class="headerlink" title="Combiner 函数"></a>Combiner 函数</h3><p>在某些情况下，<strong>Map</strong> 函数产生的中间 <strong>key</strong> 值的重复数据会占很大的比重，并且，用户自定义的 <strong>Reduce</strong> 函数满足结合律和交换律。之前举例过的词频统计中，每个 <strong> Map </strong> 任务将产生成千上万个这样的任务<the, 1="">。所有的这些记录将通过网络被发送到一个单独的 <strong>Reduce</strong> 任务，然后这个 <strong>Reduce</strong> 任务把所有这些记录累加起来产生一个数字。我们允许用户指定一个可选的 <strong>combiner</strong> 函数，<strong>combiner</strong> 函数首先在本地将这些记录进行一次合并，然后将合并的结果再通过网络发送出去。</the,></p>
<p><strong>Combiner</strong> 函数在每台执行 <strong>Map</strong> 任务的机器上都会被执行一次。 一般情况下，<strong>Combiner</strong> 和 <strong>Reduce</strong> 函数是一样的。<strong>Combiner</strong> 函数和 <strong>Reduce</strong>函数之间唯一的区别是 <strong>MapReduce</strong> 库怎样控制函数的输出。<strong>Reduce</strong> 函数的输出被保存在最终的输出文件里，而 <strong>Combiner</strong> 函数的输出被写到中间文件里，然后被发送给 <strong>Reduce</strong> 任务。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/20/IP协议/" itemprop="url">
                  IP协议学习(一):IP基础知识
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-09-20T16:32:15+08:00" content="2016-09-20">
              2016-09-20
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/读书笔记/" itemprop="url" rel="index">
                    <span itemprop="name">读书笔记</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/09/20/IP协议/" class="leancloud_visitors" data-flag-title="IP协议学习(一):IP基础知识">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1-网络层与数据链路层的关系"><a href="#1-网络层与数据链路层的关系" class="headerlink" title="1. 网络层与数据链路层的关系"></a>1. 网络层与数据链路层的关系</h3><p>数据链路层提供直连两个设备之间的通信功能。与之相比，作为网络层的IP则负责在没有直连的两个网络之间进行通信传输。</p>
<p>数据链路只负责某一个区间之间的通信传输。IP负责将数据包发送给最终的目标地址。即点对点通信。</p>
<p>IP大致分为三大作用模块，它们是IP寻址、路由（最终节点为止的转发）以及IP分包与组包。</p>
<h3 id="2-IP地址属于网络层地址"><a href="#2-IP地址属于网络层地址" class="headerlink" title="2. IP地址属于网络层地址"></a>2. IP地址属于网络层地址</h3><p>在计算机通信中，为了识别通信对端，必须要有一个类似于地址的识别码进行标识。数据链路的MAC地址是用来标识同一个链路中不同计算机的一种标识码。</p>
<p>而作为网络层的IP，我们常称为IP地址，也包含着这样一种地址信息。IP地址用于在“连接到网络中的所有主机中识别出进行通信的目标地址”。因此，在TCP/IP通信中所有的主机或路由器必须设定自己的IP地址。（严格来说，要针对每块网卡至少配置一个或一个以上的IP地址）</p>
<p>不论一台主机与哪种数据链路连接，其IP地址的形式都保持不变。以太网、无线局域网、PPP等，都不会改变IP地址的形式。</p>
<h3 id="3-路由控制"><a href="#3-路由控制" class="headerlink" title="3. 路由控制"></a>3. 路由控制</h3><p>路由控制（Routiong）是指将分组数据发送到最终目标地址的功能。即使网络非常复杂，也可以通过路由控制确定到达目标地址的通路。一旦这个路由控制的运行出现异常，分组数据极有可能“迷失”，无法到达目标地址。因此，一个数据包之所以能够成功第达到最终的目标地址，全靠路由控制。</p>
<p><strong>发送数据至最终目标地址</strong></p>
<p><strong>Hop</strong> 译为“跳”。它是指网络中的一个区间。IP包正是在网络中一个个跳间被转发。因此IP路由也叫做多跳路由。在每一个区间内决定着包在下一跳被转发的路径。下面这张图形象的表示了包转发的整个过程。</p>
<p><img src="/img/hop.png" alt=""></p>
<p><strong>一跳的范围</strong></p>
<p>一跳（1 Hop）是指利用数据链路层以下分层的功能传输数据帧的一个区间。</p>
<p>以太网等数据链路中使用MAC地址传输数据帧。此时的一跳是指从源MAC地址到目标MAC地址之间传输帧的区间。也就是说它是主机或路由器网卡不经其他路由器而能直接到达的相邻主机或路由器网卡之间的一个区间。在一跳的这个区间内，电缆可以通过网桥或交换集线器相连，不会通过路由器或网关相连。</p>
<p>多跳路由是指路由器或主机在转发IP数据包时只指定下一个路由器或主机，而不是将到最终目标地址为止的所有通路全都指定出来。因为每一个区间（跳）在转发IP数据包时会分别指定下一跳的操作，直至包到达最终的目标地址。如果用购买火车票为例来说的话，IP就相当于在每次换乘时购买了标有下一个MAC地址的车票。</p>
<p><strong>路由控制表</strong></p>
<p>为了将数据包发送给目标主机，所有路由器都维护着一张路由控制表（Routing Table）。该表记录IP数据在下一步应该发给哪个路由器。IP包将根据这个路由表在各个数据链路上传输。下图是一个路由控制表的示意图。</p>
<p><img src="/img/routing.png" alt=""></p>
<h3 id="4-数据链路的抽象化"><a href="#4-数据链路的抽象化" class="headerlink" title="4. 数据链路的抽象化"></a>4. 数据链路的抽象化</h3><p>IP是实现多个数据链路之间通信的协议。数据链路根据种类的不同各有特点。对这些不同数据链路的相异特性进行抽象化是IP的重要作用之一。不论底层数据链路使用以太网LAN亦或是PPP，都将被一视同仁。</p>
<p>不同数据链路有个很大的区别，就是它们各自的最大传输单播（MTU）不同。IP的上一层可能会要求传送比这些MTU更多字节的数据，因此必须在线路上传送比包长还要小的MTU。</p>
<p>为了解决这个问题，IP进行分片处理(IP Fragmentation)。所谓分片处理，就是将较大的IP包分成多个较小的IP包。分片的包到了对端目标地址以后会再被组合起来传给上一层。即从IP的上次层看，它完全可以忽略数据包在途中的各个数据链路上的MTU，而只需要按照源地址发送的长度接收数据包。IP就是以这种方式抽象化了数据链路层，使得从上层更不容易看到底层网络构造的细节。</p>
<h3 id="5-IP属于面向无连接型"><a href="#5-IP属于面向无连接型" class="headerlink" title="5. IP属于面向无连接型"></a>5. IP属于面向无连接型</h3><p>IP面向无连接。即在发包之前，不需要建立与对端目标地址之间的连接。上层如果遇到需要发送给IP的数据，该数据会立即被压缩成IP包发送出去。之所以IP要面向无连接，一是为了简化，二是为了提速。面向连接比起面向无连接处理相对复杂。甚至管理每个连接本身就是一个相当繁琐的事情。IP在需要有连接时，可以委托上一层提供此服务，因此，IP为了实现简单化与高速化采用面向无连接的方式。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/09/20/hive模式设计/" itemprop="url">
                  《Hive编程指南》学习笔记：Hive模式设计
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-09-20T10:58:22+08:00" content="2016-09-20">
              2016-09-20
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/读书笔记/" itemprop="url" rel="index">
                    <span itemprop="name">读书笔记</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2016/09/20/hive模式设计/" class="leancloud_visitors" data-flag-title="《Hive编程指南》学习笔记：Hive模式设计">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="1-按天划分的表"><a href="#1-按天划分的表" class="headerlink" title="1. 按天划分的表"></a>1. 按天划分的表</h3><pre><code>hive&gt; CREATE TABLE supply (id int, part string, quantity int)
    &gt; PARTITIONED BY (int day);

hive&gt; ALTER TABLE supply add PARTITION (day=20110102)
hive&gt; ALTER TABLE supply add PARTITION (day=20110103)
...

hive&gt; .... load data ....

hive&gt; SELECT part, quantity FROM supply
    &gt; WHERE day &gt;= 20110102 AND day &lt; 20110103 AND quantity &lt; 4;
</code></pre><h3 id="2-关于分区"><a href="#2-关于分区" class="headerlink" title="2. 关于分区"></a>2. 关于分区</h3><p>在Hive中，通过创建分区可以优化一些查询，但如果创建的分区很多很多的话，反而会对其他一些重要的查询不利，因为HDFS用于设计存储数百万的大文件，而非数十亿的小文件。使用过多的分区可能导致的一个问题就是会创建大量的非必须的Hadoop文件和文件夹。</p>
<p>MapReduce 会将一个任务（job）转换为多个任务（task）。默认情况下，每个task都是一个新的JVM实例，都需要开启和销毁的开销。对于小文件来说，每个文件都会对应一个task。在一些情况下，JVM开启和销毁的时间中销毁可能会比实际处理数据的时间消耗更长！</p>
<p>因此，一个理想的分区方案不应该导致产生太多的分区和文件夹目录，并且每个目录下的文件应该足够得大，应该是文件系统中块大小的若干倍。</p>
<p>按时间范围进行分区的一个好的策略就是按照不同的时间粒度来确定合适大小的数据积累量，而且安装这个时间粒度。随着时间的推移，分区数量的增长是“均匀的”，而且每个分区下包含的文件大小至少是文件系统中块的大小的若干倍。这个平衡可以保持使分区足够大，从而优化一般情况下查询的数据吞吐量。同时有必要考虑这中粒度级别在未来是否是适用的，特别是查询中WHERE子句选择较小粒度的范围的情况：</p>
<pre><code>hive&gt; CREATE TABLE weblogs (url string, time long, state string, 
city string )
    &gt; PARTITIONED BY (day int);
hive&gt; SELECT * FROM weblogs WHERE day=20110102;
</code></pre><p>也可以使用2个级别的分区，并且适用不同的维度:</p>
<pre><code>hive&gt; CREATE TABLE weblogs (url string, time long, city string )
    &gt; PARTITIONED BY (day int, state string);
hive&gt; SELECT * FROM weblogs WHERE day=20110102;
</code></pre><h3 id="3-唯一键和标准化"><a href="#3-唯一键和标准化" class="headerlink" title="3. 唯一键和标准化"></a>3. 唯一键和标准化</h3><p>关系型数据库通常使用唯一键、索引和标准化来存储数据集，通常是全部或者大部分存储到内存的。然而，Hive没有主键或基于序列密钥生成的自增键的概念。</p>
<p>避免标准化的主要原因是为了最小化磁盘寻道，比如那些通常需要外键关系的情况。非标准化数据允许被扫描或写入到大的，连续的磁盘存储区域，从而优化磁盘驱动器的I/O性能。然而，非标准化数据可能导致数据重复，有导致数据不一致的风险。</p>
<h3 id="4-同一份数据多种处理"><a href="#4-同一份数据多种处理" class="headerlink" title="4. 同一份数据多种处理"></a>4. 同一份数据多种处理</h3><p>Hive 本身提供一个独特的语法，它可以从一个数据源产生多个数据聚合，而无需每次聚合都要重新扫描一次。对于大的数据输入集来说，这个优化可以节约非常可观的时间。</p>
<p>常用的方法：</p>
<pre><code>hive&gt; FROM history
    &gt; INSERT OVERWRITE sales SELECT * WHERE action=&quot;purchased&apos;
    &gt; INSERT OVERWRITE credits SELECT * WHERE actions=&quot;returned&apos;;
</code></pre><h3 id="5-对于每个表的分区"><a href="#5-对于每个表的分区" class="headerlink" title="5. 对于每个表的分区"></a>5. 对于每个表的分区</h3><p>很多的ETL处理过程会涉及到多个处理步骤，而每个处理步骤可能会产生一个或多个临时表，这些表仅供下一个job使用。下面的这个例子即在中间表内部使用分区，这样的话就不会再计算某一天的数据时会发生前一天的数据被 <strong>INSERT OVERWRITE</strong> 语句覆盖掉的情况。</p>
<pre><code>$ hive -hiveconf dt=2011-01-01
hive&gt; INSERT OVERWRITE table distinct_ip_logs
    &gt; PARTITION (hit_date=${dt})
    &gt; SELECT distinct(ip) as ip from weblogs
    &gt; WHERE hit_date = &apos;${hiveconf:dt}&apos;;

hive&gt; CREATE TABLE state_city_for_day (state string, city string)
    &gt; PARTITIONED BY (hit_date string)

hive&gt; INSERT OVERWRITE table state_city_for_day PARTITION(${hivecong:df})
    &gt; SELECT distinct(state, city) FROM distinct_ip_in_logs
    &gt; JOIN geodata ON (distinct_ip_in_logs.ip = geodata.ip)
    &gt; WHERE (hit_date = &apos;${hiveconf:dt}&apos;);
</code></pre><p>这种方法有个缺点，就是用户将需要管理中间表并删除旧分区。</p>
<h3 id="6-分桶表数据存储"><a href="#6-分桶表数据存储" class="headerlink" title="6. 分桶表数据存储"></a>6. 分桶表数据存储</h3><p>分区提供一个隔离数据和优化查询的便利的方式。但是并非所有的数据集都可以形成合理的分区，特别是之前所提过的要确定合适的划分大小。</p>
<p>分桶是将数据集分解成更容易管理的若干部分。我们假设有个表的一级分区是dt，代表日期，二级分区是<strong>user_id</strong>，那么这种划分方式可能导致太多的小分区。但是，如果我们对表进行分桶，并使用<strong>user_id</strong>字段作为分桶字段，则字段值会根据用户指定的值进行哈希分发到桶中。同一个<strong>user_id</strong>下的记录通常会存储到同一个桶内。同一个<strong>user_id</strong>下的记录通常会存储到同一个桶内，假设用户数要比桶数多得多，那么每个桶内就将会包含多个用户的记录：</p>
<pre><code>hive&gt; CREATE TABLE weblog (user_id INT, url STRING, source_ip STRING)
    &gt; PARTITIONED BY (dt STRING)
    &gt; CLUSTERED BY (user_id) INTO 96 BUCKETS;
</code></pre><p>在使用 <strong>INSERT … TABLE</strong> 语句时，我们需要设置一个属性来强制Hive为目标表的分桶初始化过程设置一个正确的reducer个数。然后我们再执行一个查询来填充分区。例如：</p>
<pre><code>hive&gt; SET hive.enforce.bucketing = true

hive&gt; FROM raw_logs
    &gt; INSERT OVERWRITE TABLE weblog
    &gt; PARTITION (dt=&quot;2015-01-01&quot;)
    &gt; SELECT user_id, url, source_ip WHERE dt=&quot;2015-01-01&quot;;
</code></pre><p>如果我们没有使用 <strong>hive.enforce.bucketing</strong> 属性，那么我们就需要自己设置和分桶个数想匹配的 <strong>reducer</strong> 个数。例如，使用 <strong>set.mapred.reduce.tasks=96</strong>，然后在 <strong>INSERT</strong> 语句中，需要在 <strong>SELECT</strong> 语句后增加 <strong>CLUSTER BY</strong> 语句。</p>
<p>分桶有几个优点，因为桶的数量是固定的，所以它没有数据波动，故对于抽样再合适不过。</p>
<h3 id="7-为表增加列"><a href="#7-为表增加列" class="headerlink" title="7. 为表增加列"></a>7. 为表增加列</h3><p>Hive允许在原始数据文件之上定义一个模式，而不像很多的数据库那样，要求必须以特定的格式转换和插入数据。这样的分离方式的好处是，当为数据文件增加新的字段时，可以容易地适应表定义的模式。</p>
<p>下面来举个例子：</p>
<pre><code>hive&gt; CREATE TABLE weblogs (version LONG, url STRING)
    &gt; PARTITIONED BY (hit_date int)
    &gt; ROW FORMAT DELIMITED FIELDS TERMINATED BY &apos;\t&apos;;

hive&gt; ! cat log1.txt
1    /login
1    /logout

hive&gt; LOAD DATA LOCAL INPATH &apos;log1.txt&apos; int weblogs partition(20150101);

hive&gt; SELECT * FROM weblogs;
1    /mystuff    20150101
1    /toys        20150101
</code></pre><p>随着时间的推移，可能会为底层数据增加一个新字段。下面是为数据新增 <strong>user_id</strong>字段的过程。</p>
<pre><code>hive&gt; ! cat log2.txt
2    /cars    bob
2    /stuff    terry

hive&gt; ALTER TABLE weblogs ADD COLUMNS (user_id string);

hive&gt; LOAD DATA LOCAL INPATH &apos;log2.txt&apos; int weblogs partition(20150102);

hive&gt; SELECT * from weblogs
1    /mystuff    20150101     NULL
1    /toys        20150101    NULL
2    /cars        20150102     bob
2    /stuff        20150102    terry
</code></pre><p>但是这种方式，无法在已有字段的开始或中间增加新字段。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/5/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><span class="page-number current">6</span><a class="page-number" href="/page/7/">7</a><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/7/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="PengShuang" />
          <p class="site-author-name" itemprop="name">PengShuang</p>
          <p class="site-description motion-element" itemprop="description">在路上，慢慢走！</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">78</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">20</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">28</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/pengshuang" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/2176899852/profile?rightmod=1&wvr=6&mod=personnumber&is_all=1" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://bbs.byr.cn/" title="北邮人" target="_blank">北邮人</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://coolshell.cn/" title="酷壳" target="_blank">酷壳</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.dongwm.com" title="小明明的博客" target="_blank">小明明的博客</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PengShuang</span>
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
  <p>Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a></p>
</div>

<script>
(function(){
    var bp = document.createElement('script');
    bp.src = '//push.zhanzhang.baidu.com/push.js';
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>



        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("DKbLgBme7UkAx9JX6sM3D4Hj-gzGzoHsz", "GXjJ9Ox3pUGI9PJhm6CNfJGN");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

</body>
</html>
