<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="在路上，慢慢走！">
<meta property="og:type" content="website">
<meta property="og:title" content="小沙文的博客">
<meta property="og:url" content="http://pengshuang.space/index.html">
<meta property="og:site_name" content="小沙文的博客">
<meta property="og:description" content="在路上，慢慢走！">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="小沙文的博客">
<meta name="twitter:description" content="在路上，慢慢走！">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://pengshuang.space/"/>

  <title> 小沙文的博客 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">小沙文的博客</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle"></p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/08/20/AUC、ROC-以及-KS-介绍/" itemprop="url">
                  AUC、ROC 以及 KS 介绍
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-08-20T09:37:36+08:00" content="2017-08-20">
              2017-08-20
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2017/08/20/AUC、ROC-以及-KS-介绍/" class="leancloud_visitors" data-flag-title="AUC、ROC 以及 KS 介绍">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>ROC（Receiver Operating Characteristic）曲线和 AUC 常被用来评价一个二值分类器（binary classifier）的优劣。</p>
<p>KS（Kolmogorov-Smirnov）检验：K-S 检验主要是验证模型的区分能力，通常是在模型预测全体样本的 label 后，将全体样本按 label 为正与 label 为负分为两部分，然后用 K-S 统计量来检验这两组样本 label 预测概率的分布是否有显著差异。</p>
<h3 id="ROC-曲线"><a href="#ROC-曲线" class="headerlink" title="ROC 曲线"></a>ROC 曲线</h3><p>对于分类器，或者说分类算法，评价指标主要有 precision，recall，F-score1，以及这篇文章里面介绍的 ROC 和 AUC。下图是一个 ROC 曲线的示例：</p>
<p><img src="/img/roc.png" alt=""></p>
<p>ROC 曲线的横坐标为 false positive rate（FPR），纵坐标为true positive rate（TPR），关于 FPR 和 TPR 的定义如下：</p>
<p><img src="/img/fpr-and-tpr.png" alt=""></p>
<p>ROC 曲线图中有四个特殊的点和一条特殊的线。第一个点，(0,1)，即 FPR = 0, TPR = 1，这意味着 FN = 0，并且 FP = 0。这是一个完美的分类器，它将所有的样本都正确分类。第二个点，(1,0)，即 FPR = 1，TPR = 0，类似地分析可以发现这是一个最糟糕的分类器，因为它成功避开了所有的正确答案。第三个点，(0,0)，即 FPR = TPR = 0，即 FP = TP = 0，可以发现该分类器预测所有的样本都为负样本（negative）。类似的，第四个点（1,1），分类器实际上预测所有的样本都为正样本。经过以上的分析，我们可以断言，ROC曲线越接近左上角，该分类器的性能越好。</p>
<p>ROC 曲线图中的特殊的线是 y = x。这条对角线上的点其实表示的是一个采用随机猜测策略的分类器的结果，例如 (0.5，0.5)，表示该分类器随机对于一半的样本猜测其为正样本，另外一半的样本为负样本。</p>
<h3 id="绘制-ROC-曲线"><a href="#绘制-ROC-曲线" class="headerlink" title="绘制 ROC 曲线"></a>绘制 ROC 曲线</h3><p>对于一个特定的分类器和测试数据集，显然只能得到一个分类结果，即一组 FPR 和 TPR 结果，而要得到一个曲线，则需要一系列 FPR 和 TPR 的值。如何得到这么一系列的值，我们需要去调整分类器的阈值，这里的阈值指的是大于这个阈值则判为正，小于则判为负，然后计算得到的 FPR 和 TPR。</p>
<p>当我们将阈值设置为 1 和 0 时，分别可以得到 ROC 曲线上的 (0,0) 和 (1,1) 两个点。将这些 (FPR, TPR) 对连接起来，就得到了 ROC 曲线。当阈值取值越多，ROC 曲线越平滑。</p>
<h3 id="AUC-值"><a href="#AUC-值" class="headerlink" title="AUC 值"></a>AUC 值</h3><p>AUC（Area Under Curve）被定义为 ROC 曲线下的面积，显然这个面积的数值不会大于 1。又由于 ROC 曲线一般都处于 y = x 这条直线的上方，所以 AUC 的取值范围在 0.5 和 1 之间。使用 AUC 值作为评价标准是因为很多时候 ROC 曲线并不能清晰的说明哪个分类器的效果更好，而作为一个数值，对应 AUC 更大的分类器效果更好。</p>
<h3 id="为什么使用-ROC-曲线"><a href="#为什么使用-ROC-曲线" class="headerlink" title="为什么使用 ROC 曲线"></a>为什么使用 ROC 曲线</h3><p>相比其他评价指标，ROC 曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC 曲线能够保持不变。在实际的数据集中经常会出现类不平衡现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。下图对比了 ROC 图和其他评价指标图：</p>
<p><img src="/img/roc-and-precall.png" alt=""></p>
<p>在上图中，(a) 和 (c) 为ROC曲线，(b) 和 (d) 为Precision-Recall曲线。(a) 和 (b) 展示的是分类其在原始测试集（正负样本分布平衡）的结果，(c) 和 (d) 是将测试集中负样本的数量增加到原来的 10 倍后，分类器的结果。可以明显的看出，ROC 曲线基本保持原貌，而 Precision-Recall 曲线则变化较大。</p>
<h3 id="K-S-曲线绘制方法"><a href="#K-S-曲线绘制方法" class="headerlink" title="K-S 曲线绘制方法"></a>K-S 曲线绘制方法</h3><p>K-S 也可以作为常用的模型评价指标。它和 ROC 曲线的画法有很大不同。以 LR 模型为例，首先把 LR 模型输出的概率从大到小排序，然后取前 10% 的值（也就是概率值）作为阀值，同理把 10% * k（k=1,2,3, … ,9）处的值作为阀值，计算出不同的 FPR 和 TPR 值，以10% * k（k=1,2,3, … ,9）为横坐标，分别以 TPR 和 FPR 的值为纵坐标，就可以画出两个曲线，这就是K-S曲线。</p>
<p>从 K-S 曲线就能衍生出 KS 值，KS = max(TPR - FPR)，即是两条曲线之间的最大间隔距离。当 (TPR - FPR) 最大时，即 ΔTPR - ΔFPR = 0，这和 ROC 曲线上找最优阀值的条件 ΔTPR = ΔFPR 是一样的。从这点也可以看出，ROC 曲线、K-S 曲线、KS 值的本质是相同的。</p>
<h3 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h3><ul>
<li><p><a href="http://alexkong.net/2013/06/introduction-to-auc-and-roc/" target="_blank" rel="external">ROC和AUC介绍以及如何计算AUC</a></p>
</li>
<li><p><a href="https://zhuanlan.zhihu.com/p/24327437" target="_blank" rel="external">关于模型检验的ROC值和KS值的异同_ROC曲线和KS值</a></p>
</li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/08/06/CTR-中-LR、GBDT-LR、FM-DNN-比较/" itemprop="url">
                  CTR 中 LR、GBDT + LR、FM 和 DNN 比较
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-08-06T19:03:59+08:00" content="2017-08-06">
              2017-08-06
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/工程经验/" itemprop="url" rel="index">
                    <span itemprop="name">工程经验</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2017/08/06/CTR-中-LR、GBDT-LR、FM-DNN-比较/" class="leancloud_visitors" data-flag-title="CTR 中 LR、GBDT + LR、FM 和 DNN 比较">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近在知乎上看到这个问题，觉得很有意思，顺便整理总结了一下各位大佬的回答。</p>
<h3 id="LR"><a href="#LR" class="headerlink" title="LR"></a>LR</h3><p><strong>优点</strong>：LR，算法简单，容易并行和工程化实现。FTRL 是 LR 在线学习版本，目前广泛应用在工业界。优点就是简单，能够处理超高纬度稀疏问题，能够做到实时。</p>
<p><strong>缺点</strong>：因为 LR 是线性模型，基本靠人工特征工程，来选择交叉特征。一般都是 wrapper 方法选择，每轮可能都要进行很长时间的运算，理论上要进行 2 的 n 次方轮(n 是特征数)，但因为离线分析的指标和线上效果不一定是强相关的，所以分析起来有些痛苦。更头疼的是点击率预估的数据变化是比较大的，线上线下结果不一定对应，离线选出来的特征，参数都不一定适用于未来。而且在线预测时，因为大量的特征都要与广告ID交叉，所以在线拼装特征的成本很高，可能会存在性能问题。</p>
<h3 id="GBDT-LR"><a href="#GBDT-LR" class="headerlink" title="GBDT + LR"></a>GBDT + LR</h3><p><strong>优点</strong>：GBDT 加 LR。GBDT 对连续特征划分能力超强，主要来提取特征，再加上一些稀疏特征，补足了 LR 的不足。优点是把 LR 中人工构造特征的大部分工作给做了。</p>
<p><strong>缺点</strong>：离线处理和在线处理都复杂。不同于比赛，在实践中 ID 类特征还是非常重要的，广告 ID 可能就有几十万个，树的深度很难控制，模型实现也很难。另外，在点击率预估中如果特征本身没问题，加上去一般都不会降效果，所以这种做法有待验证。</p>
<h3 id="DNN"><a href="#DNN" class="headerlink" title="DNN"></a>DNN</h3><p><strong>优点</strong>：优点是拟合能力强，样本足够的情况下一般效果都不会差。本质上讲，该方法是通过前面多层的隐藏网络学习抽象特征（特征之间的组合），由数据驱动的模式学习到了人工特征工程难以学到的隐含特征，并在最后输出层使用上述抽象得到的特征完成最终的学习任务（全连接层）。</p>
<p><strong>缺点</strong>：计算复杂，工程化和实时化难度大。而且模型如果哪天出问题了（线上 AUC 突降），难以排查。</p>
<h3 id="FM"><a href="#FM" class="headerlink" title="FM"></a>FM</h3><p><strong>优点</strong>：相较与 LR，能够捕捉特征之间的交叉关系。原理是在一阶拟合的基础上加入二阶拟合，可以自动的学习任意两维特征的交叉。而且，交叉是以 embedding 向量的形式表达。跟 LR 一样，他可以吞吐超大规模的稀疏特征空间的样本集合。这种形式可以比较好的提高模型的表达能力，把性能和学习非线性结构的能力结合在一起，在工业界应用的也很广泛。</p>
<h3 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h3><ul>
<li><a href="https://www.zhihu.com/question/62109451" target="_blank" rel="external">广告点击率模型中，LR, GBDT+LR, FM, DNN等模型的优点和缺点？实际效果如何?</a></li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/08/05/Resnet-学习笔记/" itemprop="url">
                  Resnet 学习笔记
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-08-05T15:50:59+08:00" content="2017-08-05">
              2017-08-05
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2017/08/05/Resnet-学习笔记/" class="leancloud_visitors" data-flag-title="Resnet 学习笔记">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>深度学习网络的深度对最后的分类和识别的效果有着很大的影响，所以一般把网络设计的越深效果越好，但是事实上却不是这样，常规的网络的堆叠（plain network）在网络很深的时候，效果却越来越差了。<strong>这里的效果差不是单指在测试集上的效果差，而是在训练集和测试集上的效果都变差。</strong></p>
<p>产生这种问题的原因之一即是网络越深，梯度消失的现象就越来越明显，网络的训练效果也不会很好。但是现在浅层的网络（shallower network）又无法明显提升网络的识别效果了，所以 Resnet（残差网络）的目标是在网络深度加深的情况下解决梯度消失的问题。</p>
<h3 id="方法"><a href="#方法" class="headerlink" title="方法"></a>方法</h3><p><img src="/img/resnet1.jpeg" alt=""></p>
<p>常规的神经网络结构如上图所示。</p>
<p><img src="/img/resnet2.jpeg" alt=""></p>
<p>ResNet 引入了残差网络结构（residual network），通过残差网络，可以把网络层弄的很深，据说可以达到了1000多层，最终的网络分类的效果也是非常好，残差网络的基本结构如上图所示。</p>
<p>通过增加一个恒等映射（identity mapping），同时在输出个输入之间引入一个 shortcut connection，而不是简单的堆叠网络。将原始所需要学习的函数 <strong>H(x)</strong> 转换成 <strong>F(x) + x</strong>。这样可以解决网络由于很深出现梯度消失的问题，从而可以把网络做的很深，ResNet 其中一个网络结构如下图所示：</p>
<p><img src="/img/resnet3.jpeg" alt=""></p>
<p>Resnet 网络结构的基本设计方案 — VGG-style：</p>
<ol>
<li>所有的3x3卷积层（几乎所有）</li>
<li>空间规模/2 =&gt; #过滤器x2 (~每一层的复杂度相同)</li>
<li>简约的设计风格</li>
</ol>
<p>训练方法：</p>
<ol>
<li><p>所有的平原/残差网络都是从头开始训练的。</p>
</li>
<li><p>所有的平原/残差网络都运用组归一化（Batch Normalization）。</p>
</li>
<li><p>标准化的超参数&amp;增强。</p>
</li>
</ol>
<p>论文中介绍了一个深层次的残差学习框架来解决精准度下降问题。并且明确地让这些层适合残差映射，而不是寄希望于每一个堆叠层直接适合一个所需的底层映射。形式上，把 H(x) 作为所需的基本映射，让堆叠的非线性层适合另一个映射 F(x) := H(x) - x。</p>
<p>公式 F(x) + x 可以通过 shortcut 前馈神经网络实现。shortcut 是那些跳过中的一层或更多层。在我们的情景中，shortcut 简单的执行身份映射，并将它们的输出添加到叠加层的输出。身份快捷连接添加既不产生额外的参数，也会增加不计算的复杂度。通过反向传播的SGD，整个网络仍然可以被训练成终端到端的形式。</p>
<h3 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h3><p>残差网络的精美之处在于那个 shortcut 的设计。</p>
<p>增加一个恒等映射这一步，将原始所需要学的函数 H(x) 转换成 F(x) + x。论文认为这两种表达的效果是相同的，但是优化的难度却并不相同。</p>
<p>首先作者假设 F(x) 的优化会比H(x)简单的多。这一想法也是源于图像处理中的残差向量编码，通过一个 reformulation，将一个问题分解成多个尺度直接的残差问题，能够很好的起到优化训练的效果。</p>
<p>这个 Residual block 通过 shortcut connection 实现，通过 shortcut 将这个 block 的输入和输出进行一个 element-wise 的加叠，这个简单的加法并不会给网络增加额外的参数和计算量，同时却可以大大增加模型的训练速度、提高训练效果，并且当模型的层数加深时，这个简单的结构能够很好的解决退化问题。</p>
<p><img src="/img/resnet4.png" alt=""></p>
<p>残差网络也可以从另一个角度来理解，如上图所示。</p>
<p>残差网络单元其中可以分解成右边的形式，从图中可以看出，残差网络其实是由多种路径组合的一个网络，即，残差网络其实是很多并行子网络的组合，整个残差网络其实相当于一个多人投票系统（Ensembling）。</p>
<h3 id="为了证明，如果删除残差网络的一部分"><a href="#为了证明，如果删除残差网络的一部分" class="headerlink" title="为了证明，如果删除残差网络的一部分"></a>为了证明，如果删除残差网络的一部分</h3><p>如果把残差网络理解成一个Ensambling系统，那么网络的一部分就相当于少一些投票的人，如果只是删除一个基本的残差单元，对最后的分类结果应该影响很小；而最后的分类错误率应该是和删除的残差单元的个数成正比的，这个结论也被学者实验证明。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/08/01/数据库中视图的作用/" itemprop="url">
                  数据库中视图的作用
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-08-01T15:42:55+08:00" content="2017-08-01">
              2017-08-01
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/数据库/" itemprop="url" rel="index">
                    <span itemprop="name">数据库</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2017/08/01/数据库中视图的作用/" class="leancloud_visitors" data-flag-title="数据库中视图的作用">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>视图是从一个或几个基本表（或视图）导出的表。它与基本表不同，是一个虚表。数据库只存放视图的定义，而不存放视图对应的数据，这些数据仍存放在原来的基本表中。所以基本表中的数据发生变化，从视图中查询出的数据也就随之改变了。从这个意义上讲，视图就像一个窗口，透过它可以看到数据库中自己感兴趣的数据及其变化。</p>
<p>这是因为合理地使用视图能够带来许多好处：</p>
<h3 id="1-视图能简化用户操作"><a href="#1-视图能简化用户操作" class="headerlink" title="1. 视图能简化用户操作"></a>1. 视图能简化用户操作</h3><p>视图机制使用户可以将注意力集中在所关心地数据上。如果这些数据不是直接来自基本表，则可以通过定义视图，使数据库看起来结构简单、清晰，并且可以简化用户的的数据查询操作。例如，那些定义了若干张表连接的视图，就将表与表之间的连接操作对用户隐藏起来了。换句话说，用户所作的只是对一个虚表的简单查询，而这个虚表是怎样得来的，用户无需了解。</p>
<h3 id="2-视图使用户能以多种角度看待同一数据"><a href="#2-视图使用户能以多种角度看待同一数据" class="headerlink" title="2. 视图使用户能以多种角度看待同一数据"></a>2. 视图使用户能以多种角度看待同一数据</h3><p>视图机制能使不同的用户以不同的方式看待同一数据，当许多不同种类的用户共享同一个数据库时，这种灵活性是非常必要的。</p>
<h3 id="3-视图对重构数据库提供了一定程度的逻辑独立性"><a href="#3-视图对重构数据库提供了一定程度的逻辑独立性" class="headerlink" title="3. 视图对重构数据库提供了一定程度的逻辑独立性"></a>3. 视图对重构数据库提供了一定程度的逻辑独立性</h3><p>数据的物理独立性是指用户的应用程序不依赖于数据库的物理结构。数据的逻辑独立性是指当数据库重构造时，如增加新的关系或对原有的关系增加新的字段，用户的应用程序不会受影响。层次数据库和网状数据库一般能较好地支持数据的物理独立性，而对于逻辑独立性则不能完全的支持。</p>
<p>在关许数据库中，数据库的重构造往往是不可避免的。重构数据库最常见的是将一个基本表“垂直”地分成多个基本表。例如：将学生关系Student（Sno，Sname，Ssex，Sage，Sdept），</p>
<p>分为SX（Sno，Sname，Sage）和SY（Sno，Ssex，Sdept）两个关系。这时原表Student为SX表和SY表自然连接的结果。如果建立一个视图Student：</p>
<pre><code>CREATE VIEW Student（Sno，Sname，Ssex，Sage，Sdept）
AS
SELECT SX.Sno，SX.Sname，SY.Ssex，SX.Sage，SY.Sdept
FROM SX，SY
WHERE SX.Sno=SY.Sno;
</code></pre><p>这样尽管数据库的逻辑结构改变了（变为SX和SY两个表了），但应用程序不必修改，因为新建立的视图定义为用户原来的关系，使用户的外模式保持不变，用户的应用程序通过视图仍然能够查找数据。</p>
<p>当然，视图只能在一定程度上提供数据的逻辑独立，比如由于视图的更新是有条件的，因此应用程序中修改数据的语句可能仍会因为基本表构造的改变而改变。</p>
<h3 id="4-视图能够对机密数据提供安全保护"><a href="#4-视图能够对机密数据提供安全保护" class="headerlink" title="4. 视图能够对机密数据提供安全保护"></a>4. 视图能够对机密数据提供安全保护</h3><p>有了视图机制，就可以在设计数据库应用系统时，对不同的用户定义不同的视图，使机密数据不出现在不应该看到这些数据的用户视图上。这样视图机制就自动提供了对机密数据的安全保护功能。例如，Student 表涉及全校 15 个院系学生数据，可以在其上定义15个视图，每个视图只包含一个院系的学生数据，并只允许每个院系的主任查询和修改本原系学生视图。</p>
<h3 id="5-适当的利用视图可以更清晰地表达查询"><a href="#5-适当的利用视图可以更清晰地表达查询" class="headerlink" title="5. 适当的利用视图可以更清晰地表达查询"></a>5. 适当的利用视图可以更清晰地表达查询</h3><p>例如经常需要执行这样的查询“对每个学生找出他获得最高成绩的课程号”。可以先定义一个视图，求出每个同学获得的最高成绩：</p>
<pre><code>CREATE VIEW VMGRADE
AS
SELECT Sno，MAX(Grade) Mgrade
FROM SC
GROUP BY Sno;
</code></pre><p>然后用如下的查询语句完成查询：</p>
<pre><code>SELECT SC.Sno，Cno FROM SC，VMGRADE WHERE SC.Sno = VMGRADE.Sno AND 
SC.Grade = VMGRADE.Mgrade;
</code></pre>
          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/07/23/Parameter-Server-学习/" itemprop="url">
                  Parameter Server 学习
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-07-23T16:36:58+08:00" content="2017-07-23">
              2017-07-23
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/系统架构/" itemprop="url" rel="index">
                    <span itemprop="name">系统架构</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2017/07/23/Parameter-Server-学习/" class="leancloud_visitors" data-flag-title="Parameter Server 学习">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>大数据机器学习系统，通常数据在 1 TB 到 1 PB 之间，参数在 10 的 9 次方和 10 的 12 次方左右，很多算法的参数只能采用分布式存储。这样的话会带来下面几个问题：</p>
<ul>
<li>访问这些参数需要很大的网络带宽。</li>
<li>很多算法是序列性的，同步会影响性能。</li>
<li>在大规模分布式的情况下，如何设计容错机制至关重要。</li>
</ul>
<p>为了解决这些问题，大神们提出了一种新的架构 - Parameter Server (简称 PS)</p>
<p>PS 整体架构图如下</p>
<p><img src="/img/parameter-server.png" alt=""></p>
<h3 id="PS-架构分为两个部分："><a href="#PS-架构分为两个部分：" class="headerlink" title="PS 架构分为两个部分："></a>PS 架构分为两个部分：</h3><p><strong>外功</strong>：把计算资源分为两个部分，参数服务器节点和工作节点。</p>
<ol>
<li>参数服务器来存储参数</li>
<li>工作节点来做算法的训练</li>
</ol>
<p><strong>内功</strong>：内功是对应的，把机器学习分为两个部分，参数部分和训练部分。</p>
<ol>
<li>参数部分即模型部分，有一致性的要求，参数服务器也可以是一个集群。</li>
<li>训练部分需要并行化。因为参数服务器的存在，每个计算节点在拿到新的一批batch数据之后，都要从参数服务器上取下最新的参数，然后计算梯度，再将梯度更新会参数服务器。</li>
</ol>
<p>在 PS 中，每个 server 实际上都只负责分到的部分参数（servers共同维持一个全局的共享参数），而每个 work 也只分到部分数据和处理任务；每个子节点都只维护自己分配到的参数，自己部分更新之后，将计算结果（例如：梯度）传回到主节点，进行全局的更新（比如平均操作之类的），主节点再向子节点传送新的参数；</p>
<p>server 节点可以跟其他 server 节点通信，每个 server 负责自己分到的参数，server group 共同维持所有参数的更新。</p>
<p>server manager node 负责维护一些元数据的一致性，比如各个节点的状态，参数的分配情况等；</p>
<p>worker 节点之间没有通信，只跟自己对应的 server 进行通信。每个 worker group 有一个 task scheduler，负责向 worker 分配任务，并且监控 worker 的运行情况。当有新的 worker 加入或者退出，task scheduler 负责重新分配任务。</p>
<h3 id="PS-架构有-5-个特点"><a href="#PS-架构有-5-个特点" class="headerlink" title="PS 架构有 5 个特点"></a>PS 架构有 5 个特点</h3><ol>
<li><p>高效的通信</p>
<p> 异步通信，使得计算不会被拖累</p>
</li>
<li><p>弹性一致性</p>
<p> 允许用户自定义一致性: 比如 Sequential（序列式的，即完全同步）、Eventual（完全不同步的）和 Bounded Delay（有条件的限制，可以允许用户在限制的次数内异步，比如限制为 3 次，如果某个节点已经超前了其他节点四次迭代了，那么要停下等待同步。在整个训练的过程中，Delay 可能是动态的，即 delay 的参数在训练过程中可以变大或变小）</p>
</li>
<li><p>扩展性强</p>
<p> 使用了一个分布式 hash 表使得新的 server 节点可以随时动态的插入到集合中；因此，新增一个节点不需要重新运行系统。</p>
</li>
<li><p>错误容忍</p>
<p> 在大规模商用服务器集群中。从非灾难性机器故障中恢复，只需要 1 秒，而且不需要中断计算。Vector Clocks 保证了经历故障之后还是能运行良好；</p>
</li>
<li><p>易用性</p>
<p> 全局共享的参数可以被表示成各种形式：vector，matrices 或者相应的 sparse 类型，这大大方便了机器学习算法的开发。并且提供的线性代数的数据类型都具有高性能的多线程库。</p>
</li>
</ol>
<h3 id="PS-的一些关键概念"><a href="#PS-的一些关键概念" class="headerlink" title="PS 的一些关键概念"></a>PS 的一些关键概念</h3><h4 id="1-key-value-，Range-Push-and-Pull"><a href="#1-key-value-，Range-Push-and-Pull" class="headerlink" title="1. (key, value)，Range Push and Pull"></a>1. (key, value)，Range Push and Pull</h4><p><img src="/img/parameter-server4.png" alt=""></p>
<p>parameter server 中，参数都是可以被表示成(key, value)的集合，比如一个最小化损失函数的问题，key 就是 feature ID，而 value 就是它的权值。对于稀疏参数，不存在的key，就可以认为是0。</p>
<p>把参数表示成 k-v， 形式更自然，易于理解，更易于编程解；</p>
<p>workers 跟 servers 之间通过 push 跟 pull 来通信。worker 通过 push 将计算好的梯度发送到 server，然后通过 pull 从 server 更新参数。为了提高计算性能和带宽效率，parameter server 允许用户使用 Range Push 跟 Range Pull 操作（使用区间更新的方式）。</p>
<h4 id="2-Key-value-vectors"><a href="#2-Key-value-vectors" class="headerlink" title="2. Key-value vectors"></a>2. Key-value vectors</h4><p>赋予每个 key 所对应的 value 一个向量概念或矩阵概念。</p>
<h4 id="3-User-Defined-Functions-on-the-Server"><a href="#3-User-Defined-Functions-on-the-Server" class="headerlink" title="3. User-Defined Functions on the Server"></a>3. User-Defined Functions on the Server</h4><p>服务器端更新参数的时候还有计算正则项，这样的操作可以由用户自定义。</p>
<h4 id="4-Asychronous-Tasks-and-Dependency"><a href="#4-Asychronous-Tasks-and-Dependency" class="headerlink" title="4. Asychronous Tasks and Dependency"></a>4. Asychronous Tasks and Dependency</h4><p><img src="/img/parameter-server3.png" alt=""></p>
<p>如图，如果 iter1 需要在 iter0 computation，push 跟 pull 都完成后才能开始，那么就是 Synchronous，反之就是Asynchronous.</p>
<p>参数服务器和工作节点之间的通信都属于远程调用。远程调用相对而言要比较耗时，因而 PS 框架让远程调用成为异步调用，比如参数的 push 和 pull 发出之后，立即使用当前值开始进行下一步的梯度计算。（失去了模型的一致性，但提升了速度）。</p>
<p>Asychronous 的优点是能够提高系统的效率（因为节省了很多等待的过程），但是，它的缺点就是容易降低算法的收敛速率；</p>
<p>所以，系统性能跟算法收敛速率之间是存在一个 trade-off 的，你需要同时考虑：</p>
<ol>
<li><p>算法对于参数非一致性的敏感度；</p>
</li>
<li><p>训练数据特征之间的关联度；</p>
</li>
<li><p>硬盘的存储容量</p>
</li>
</ol>
<h4 id="6-User-Defined-Filters（用户自定义过滤）"><a href="#6-User-Defined-Filters（用户自定义过滤）" class="headerlink" title="6. User-Defined Filters（用户自定义过滤）"></a>6. User-Defined Filters（用户自定义过滤）</h4><p>在工作节点这一端对梯度进行过滤，如果梯度并不是影响那么大，就不占用网络去更新，等积累一段时间之后再去做更新。</p>
<p>对于机器学习优化问题比如梯度下降来说，并不是每次计算的梯度对于最终优化都是有价值的，用户可以通过自定义的规则过滤一些不必要的传送，再进一步压缩带宽 cost：</p>
<ol>
<li>发送很小的梯度值是低效的：</li>
</ol>
<p>因此可以自定义设置，只在梯度值较大的时候发送；</p>
<ol>
<li>更新接近最优情况的值是低效的：</li>
</ol>
<p>因此，只在非最优的情况下发送，可通过KKT来判断；</p>
<h3 id="PS-的实现"><a href="#PS-的实现" class="headerlink" title="PS 的实现"></a>PS 的实现</h3><p><strong>Vector Clock</strong></p>
<p>为参数服务器中的每个参数加一个时间戳来跟踪参数的更新，防止重复发送数据。如果每个参数都有一个时间戳，那么参数众多，时间戳也众多。但借助于Vector概念，很多的参数可以作为向量存在k-v中，因而，时间戳的数量大大减少。</p>
<p>在刚开始的时候，所有的参数都是一个大向量，时间戳为0，每次来一个范围的更新，如果能找到对应的key，那么直接更新那个key的时间戳就可以了。否则，就可能会对某些向量进行切分，一次更新请求，最多能把一个区间切分为三个区间。</p>
<p><strong>一致性哈希</strong></p>
<p>参数服务器集群中每个节点都负责不同区域的参数，那么，类似于hash table，使用hash ring进行实现，key和server id都插入到hash ring上去。</p>
<p><strong>备份和一致性</strong></p>
<p>使用类似 hadoop 的 chain 备份方式，对于一个 master 节点，如果有更新，先更新它，然后再去更新备份的服务器。</p>
<p><img src="/img/parameter-server2.png" alt=""></p>
<p>在更新的时候，由于机器学习算法的特点，可以将多次梯度聚合之后再去更新备份服务器，从而减少带宽。</p>
<p><strong>Messages</strong></p>
<p>一条 message 包括：时间戳，len(range) 对 k-v。</p>
<p>这是 parameter server 中最基本的通信格式，不仅仅是共享的参数才有，task 的message 也是这样的格式，只要把这里的 (key, value) 改成 (task ID, 参数/返回值)。</p>
<p>由于机器学习问题通常都需要很高的网络带宽，因此信息的压缩是必须的。</p>
<p>key 的压缩：因为训练数据通常在分配之后都不会发生改变，因此worker没有必要每次都发送相同的key，只需要接收方在第一次接收的时候缓存起来就行了。第二次，worker不再需要同时发送key和value，只需要发送value 和 key list的hash就行。这样瞬间减少了一般的通信量。</p>
<p>value的压缩： 假设参数时稀疏的，那么就会有大量的0存在。因此，为了进一步压缩，我们只需要发送非0值。parameter server使用 Snappy 快速压缩库来压缩数据、高效去除 0 值。</p>
<pre><code>key 的压缩和 value 的压缩可以同时进行。
</code></pre><p><strong>Server Management</strong></p>
<p>由于 key 的 range 特性，当参数服务器集群中增加一个节点时，步骤如下：</p>
<ul>
<li>server manager 节点给新节点分配一个 key range，这可能会导致其他节点上的 key range 切分。</li>
<li>新节点从其他节点上将属于它的 key range 数据取过来，然后也将 slave 信息取过来。</li>
<li>server manager广播节点变动，其他节点得知消息后将不属于自己 key range 的数据删掉</li>
</ul>
<p>在第二步，从其他节点上取数据的时候，其他节点上的操作也分为两步，第一是拷贝数据，这可能也会导致 key range 的切分。第二是不再接受和这些数据有关的消息，而是进行转发，转发到新节点。</p>
<p>在第三步，收到广播信息后，节点会删除对应区间的数据，然后，扫描所有的和R有关发送出去的还没收到回复的消息，当这些消息回复时，转发到新节点。</p>
<p>节点的离开与节点的加入类似。</p>
<p><strong>Worker Management</strong></p>
<p>添加工作节点比添加服务器节点要简单一些，步骤如下：</p>
<ul>
<li>task scheduler 给新节点分配一些数据</li>
<li>节点从网络文件系统中载入数据，然后从服务器端拉取参数</li>
<li>task scheduler 广播变化，其他节点 free 掉一些训练数据</li>
</ul>
<p>当一个节点离开的时候，task scheduler 可能会寻找一个替代，但恢复节点是十分耗时的工作，同时，损失一些数据对最后的结果可能影响并不是很大。所以，系统会让用户进行选择，是恢复节点还是不做处理。这种机制甚至可以允许用户删掉跑的最慢的节点来提升速度。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/15/XGBoost-介绍/" itemprop="url">
                  XGBoost 介绍
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-03-15T19:28:38+08:00" content="2017-03-15">
              2017-03-15
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2017/03/15/XGBoost-介绍/" class="leancloud_visitors" data-flag-title="XGBoost 介绍">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<h3 id="目标函数"><a href="#目标函数" class="headerlink" title="目标函数"></a>目标函数</h3><p>我之前的博客提到过，Boosting 是一种将弱分类器转化为强分类器的方法，它的函数模型具有叠加性。</p>
<p>XGBoost 的目标函数由损失函数和复杂度组成。复杂度又由叶子数量和 L2 正则组成。</p>
<p>$$L(\phi) = \sum_i l(y^{*}_i, y_i) + \sum_k \Omega(f_k) $$</p>
<p>$$where \,\, \Omega(f) = \gamma T + \frac{1}{2}\lambda||w||^2$$</p>
<p>其中 i 是样本 id，k 是树 id（轮数），由于 loss 函数和复杂度项都是凸函数，所以有最小值。w 是与真实值的残差，将 w 的 L2 正则项加在目标函数中，可以有效的防止过拟合。叶子节点的数目也作为正则项加在了目标函数中，一定程度上限制了叶子数量，防止过拟合。而传统 GBDT 防止过拟合的手段是预剪枝或者后剪枝。</p>
<h3 id="推导过程"><a href="#推导过程" class="headerlink" title="推导过程"></a>推导过程</h3><p>对于每次迭代过程，可以将一颗树的训练目标函数写成形式如下：</p>
<p>$$L^{(t)} = \sum_{i=1}^n l(y_i, y_i^{*(t-1)} + f_t(x_i)) + \Omega(f_t)$$</p>
<p>输入是 \(t-1\) 轮后预测的值和真实值，用来拟合残差 \(f(x)\)。对于这个式子，因为无法对 \(f(x)\) 进行有效的最优估计，所以要进行如下推导：</p>
<p>首先将目标函数泰勒二阶展开：</p>
<p>$$L^{(t)} = \sum_{i=1}^n [ l(y_i, y_i^{*(t-1)}) + g_i f_i(x_i) + \frac{1}{2} h_if^2_t(x_i)] + \Omega(f_t)$$</p>
<p>去掉常数项，</p>
<p>$$L^{(t)} = \sum_{i=1}^n [g_i f_i(x_i) + \frac{1}{2} h_if^2_t(x_i)] + \Omega(f_t)$$</p>
<p>正则项展开，</p>
<p>$$L^{(t)} = \sum_{i=1}^n [g_i f_i(x_i) + \frac{1}{2} h_if^2_t(x_i)] + \gamma T + \frac{1}{2} \lambda \sum_{j=1}^T w_j^2$$</p>
<p>首先做一下转换，</p>
<p>$$w_j = f(x_i) \, \, i \in _jI$$</p>
<p>所以，公式可以转化为：</p>
<p>$$L^{(t)} = \sum_{j=1}^T [(\sum_{i \in I_j}g_i)w_j + \frac{1}{2}(\sum_{i \in I_j}h_i + \lambda) w_j^2] + \gamma T$$</p>
<p>这是一个二次项形式，所以最后使得目标函数最小的 w 为，</p>
<p>$$w^*_j = - \frac{\sum_{i \in I_j} g_i}{\sum_{i \in I_j} h_i + \lambda}$$</p>
<p>带入原方程最小值为：</p>
<p>$$L^{t}(q) = - \frac{1}{2} \sum_{j=1}^T \frac{(\sum_{i \in I_j} g_i)^2}{\sum_{i \in I_j} h_i + \lambda} + \gamma T$$</p>
<p>最后求得的w就是目标函数在一个样本集合条件下的最优解。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><strong>为什么要用泰勒二阶近似展开。</strong></p>
<p>由于 gbdt 只用到了一阶信息，相当于 loss 函数只进行了一阶泰勒展开。在没有复杂度项的情况下，无法确定步长，所以只能用常数步长根据一阶梯度方向去逼近。这就是牛顿下降法和梯度下降法的区别。由于二阶展开用二次函数去逼近函数，所以可以利用二阶信息确定更新步长，比只利用一阶信息的 gdbt 用更少的迭代获得更好的效果。</p>
<p><strong>为何要对目标函数进行推导。</strong></p>
<ol>
<li>为了适应各种损失函数。</li>
<li>正则项的加入对参数估计产生了影响。</li>
<li>如果只考虑平方损失的条件下，在没有正则项的情况下参数的最优估计为样本均值。在没有指定损失函数情况下，我们也很容易想到均值是给定样本条件下的误差最小的最优估计。但是损失函数换成绝对值损失，那么最优估计就为中位数。可见不同损失函数下，结果并不想我们想的那么简单。</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/13/线性回归家族一览/" itemprop="url">
                  线性回归家族一览
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-03-13T20:59:23+08:00" content="2017-03-13">
              2017-03-13
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2017/03/13/线性回归家族一览/" class="leancloud_visitors" data-flag-title="线性回归家族一览">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<p>线性回归的目的是要得到输出向量 Y 和输入特征 X 之间的线性关系，求出线性回归系数 \(\theta\)，也就是 \(Y = X\theta\)。其中 Y 的维度是 m <em> 1，X 的维度是 m </em> n，而 \(\theta\) 的维度为 n * 1。m 代表样本个数，n 代表样本特征的维度。</p>
<p>为了得到线性回归系数 \(\theta\)，我们需要定义一个损失函数，一个极小化损失函数的优化方法，以及一个验证算法的方法。损失函数的不同，损失函数的优化方法的不同，验证方法的不同，就形成了不同的线性回归算法。</p>
<h3 id="LinearRegression"><a href="#LinearRegression" class="headerlink" title="LinearRegression"></a>LinearRegression</h3><p>损失函数：</p>
<p>LinearRegression类就是我们平时说的最常见普通的线性回归，它的损失函数也是最简单的，如下：</p>
<p>$$J(\theta) =  \frac{1}{2}(X\theta - Y)^{T}(X\theta - Y)$$</p>
<p>损失函数的优化方法：</p>
<p>对于这个函数，一般有梯度下降法和最小二乘法两种极小化损失函数的优化方法。通过最小二乘法，可以解出线性回归系数 \(\theta\) 为：</p>
<p>$$\theta = (X^TX)^{-1}X^{T}Y$$</p>
<h4 id="使用场景"><a href="#使用场景" class="headerlink" title="使用场景"></a>使用场景</h4><p>一般来说，只要我们觉得数据有线性关系，LinearRegression 是我们的首先应该采用的。如果发现拟合或者预测的不好，再考虑用其他的线性回归库。如果是学习线性回归，推荐先从这个类开始第一步的研究。</p>
<h3 id="Ridge-Regression"><a href="#Ridge-Regression" class="headerlink" title="Ridge Regression"></a>Ridge Regression</h3><p>由于单纯的线性回归没有考虑过拟合的问题，有可能泛化能力较差，这时损失函数可以加入正则化项，如果加入的是 L2 范数的正则化项，就是 Ridge 回归。此时，损失函数如下：</p>
<p>$$J(\theta) =  \frac{1}{2}(X\theta - Y)^{T}(X\theta - Y) + \frac{1}{2}\alpha ||\theta||^2_2$$</p>
<p>其中 \(\alpha\) 为常数系数，需要进行调优。</p>
<p>Ridge 回归在不抛弃任何一个特征的情况下，缩小了回归系数，使得模型相对而言比较的稳定，不至于过拟合。</p>
<h4 id="损失函数的优化方法"><a href="#损失函数的优化方法" class="headerlink" title="损失函数的优化方法"></a>损失函数的优化方法</h4><p>一般也用最小二乘法或者梯度下降法来优化。通过最小二乘法，可以解得系数：</p>
<p>$$\theta = (X^TX + \alpha E)^{-1}X^TY$$</p>
<h4 id="使用场景："><a href="#使用场景：" class="headerlink" title="使用场景："></a>使用场景：</h4><p>一般来说，只要我们觉得数据有线性关系，用 LinearRegression 拟合的不是特别好，需要正则化，可以考虑用 Ridge Regression。但是这个类最大的缺点是每次我们要自己指定一个超参数 \(\alpha\)，然后自己评估 \(\alpha\) 的好坏，比较麻烦。</p>
<h3 id="RidgeCV"><a href="#RidgeCV" class="headerlink" title="RidgeCV"></a>RidgeCV</h3><p>RidgeCV 的损失函数和损失函数的优化方法完全与 Ridge 类相同，区别在于验证方法。</p>
<p>RidgeCV 对超参数 \(\alpha\) 使用了交叉验证，来帮忙我们选择一个合适的 \(\alpha\)。在初始化 RidgeCV 时候，我们可以传一组备选的 \(\alpha\) 值，10个，100个都可以。RidgeCV类会帮我们选择一个合适的αα。免去了我们自己去一轮轮筛选αα的苦恼。　　</p>
<h4 id="使用场景-1"><a href="#使用场景-1" class="headerlink" title="使用场景"></a>使用场景</h4><p>一般来说，只要我们觉得数据有线性关系，用 LinearRegression 拟合的不是特别好，需要正则化，可以考虑用 RidgeCV。如果输入特征的维度很高，而且是稀疏线性关系的话，RidgeCV类就不合适了。这时应该主要考虑下面要讲到的 Lasso 回归类家族。</p>
<h3 id="Lasso-Regression"><a href="#Lasso-Regression" class="headerlink" title="Lasso Regression"></a>Lasso Regression</h3><p>线性回归的 L1 正则化通常称为 Lasso 回归，它和 Ridge 回归的区别是在损失函数上增加了的是 L1 正则化的项，而不是 L2 正则化项。L1 正则化的项也有一个常数系数 \(\alpha\) 来调节损失函数的均方差项和正则化项的权重，具体 Lasso 回归的损失函数表达式如下：</p>
<p>$$J(\theta) = \frac{1}{2m}(X\theta - Y)^{T}(X\theta - Y) + \alpha||\theta||_1$$</p>
<p>Lasso 回归可以使得一些特征的系数变小，甚至还是一些绝对值比较小的系数直接变为 0。增强模型的泛化能力。</p>
<h3 id="ElasticNet"><a href="#ElasticNet" class="headerlink" title="ElasticNet"></a>ElasticNet</h3><p>ElasticNet 可以看做 Lasso 和 Ridge 的结合。它也是对普通的线性回归做了正则化，但是它的损失函数记不全是 L1 的正则化，也不全是 L2 的正则化，而是一个权重 \(\rho\) 来平衡 L1 和 L2 正则化的比重，形成了一个全新的损失函数如下：</p>
<p>$$J(\theta) = \frac{1}{2m}(X\theta - Y)^{T}(X\theta - Y) + \alpha \rho||\theta||_1 + \frac{\alpha(1 - \rho)}{2}||\theta||^2_2$$</p>
<h4 id="使用场景-2"><a href="#使用场景-2" class="headerlink" title="使用场景"></a>使用场景</h4><p>ElasticNet 用在我们发现用 Lasso 回归太过（太多特征被稀疏为0），而用Ridge回归又正则化的不够（回归系数衰减的太慢）的时候。一般不推荐拿到数据就直接就 ElasticNet。</p>
<h3 id="BayesianRidge"><a href="#BayesianRidge" class="headerlink" title="BayesianRidge"></a>BayesianRidge</h3><p>贝叶斯回归模型假设先验概率，似然函数和后验概率都是正态分布。先验概率是假设模型输出 Y 是符合均值为 \(X\theta\) 的正态分布，正则化参数 \(X\alpha\) 被看作是一个需要从数据中估计得到的随机变量。回归系数 \(\theta\) 的先验分布规律为球形正态分布，超参数为 λ。我们需要通过最大化边际似然函数来估计超参数 α 和 λ，以及回归系数 \(\theta\)。</p>
<h4 id="使用场景：-1"><a href="#使用场景：-1" class="headerlink" title="使用场景："></a>使用场景：</h4><p>如果我们的数据有很多缺失或者矛盾的病态数据，可以考虑 BayesianRidge，它对病态数据鲁棒性很高，也不用交叉验证选择超参数。但是极大化似然函数的推断过程比较耗时，一般情况不推荐使用。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/13/什么是单例模式/" itemprop="url">
                  (转载) 什么是单例模式?
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-03-13T09:16:00+08:00" content="2017-03-13">
              2017-03-13
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/设计模式/" itemprop="url" rel="index">
                    <span itemprop="name">设计模式</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2017/03/13/什么是单例模式/" class="leancloud_visitors" data-flag-title="(转载) 什么是单例模式?">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>最近找实习的时候，经常被问到什么是单例模式，能不能手写一个单例模式。。。虽然我面试的都是机器学习岗。所以，痛定思痛，今天来整理总结一下什么是单例模式，这里主要是整理一下耗子叔曾经写过的一篇文章 —- <a href="http://coolshell.cn/articles/265.html" target="_blank" rel="external">深入浅出单实例SINGLETON设计模式
</a>。</p>
<p>单例模式的目的是想在整个系统中只能出现一个类的实例。</p>
<h3 id="普通的-Singleton-版本"><a href="#普通的-Singleton-版本" class="headerlink" title="普通的 Singleton 版本"></a>普通的 Singleton 版本</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> Singleton singleton = <span class="keyword">null</span>;</span><br><span class="line">	<span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123; &#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Single <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (singleton == <span class="keyword">null</span>) &#123;</span><br><span class="line">			singleton = <span class="keyword">new</span> Singleton();</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> singleton;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Singleton 的几个特点：</p>
<ol>
<li>私有（private）的构造函数，表明这个类是不可能形成实例了。这主要是怕这个类会有多个实例。</li>
<li>即然这个类是不可能形成实例，那么，我们需要一个静态的方式让其形成实例：getInstance()。注意这个方法是在new自己，因为其可以访问私有的构造函数，所以他是可以保证实例被创建出来的。</li>
<li>在 getInstance()中，先做判断是否已形成实例，如果已形成则直接返回，否则创建实例。</li>
<li>所形成的实例保存在自己类中的私有成员中。</li>
<li>我们取实例时，只需要使用 Singleton.getInstance() 就行了。</li>
</ol>
<h3 id="改进下的-Singleton"><a href="#改进下的-Singleton" class="headerlink" title="改进下的 Singleton"></a>改进下的 Singleton</h3><p>上面这个例子因为是全局性的实例，所以，在多线程情况下，所有的全局共享的东西都会变得非常危险，如果在多线程情况下同时调用 gerInstance() 的话，那么，可能会有多个进程同时通过 singleton == null 的条件检查，于是多个实例就创建出来，并且可能造成内存泄露问题。所以改进版本如下：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">static</span> Singleton singleton = <span class="keyword">null</span>;</span><br><span class="line">	<span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123; &#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Single <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (singleton == <span class="keyword">null</span>) &#123;</span><br><span class="line">			<span class="keyword">synchronized</span> (Singleton.class) &#123;</span><br><span class="line">				<span class="keyword">if</span> (singleton == <span class="keyword">null</span>) &#123;</span><br><span class="line">					singleton = <span class="keyword">new</span> Singleton();</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> singleton;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol>
<li>第一个条件是说，如果实例创建了，那就不需要同步了，直接返回就好了。</li>
<li>不然，我们就开始同步线程。</li>
<li>第二个条件是说，如果被同步的线程中，有一个线程创建了对象，那么别的线程就不用再创建了。</li>
</ol>
<p>但是， single = new Singleton() 这句，并非是一个原子操作。事实上，在 JVM 中，这句话大概做了下面 3 件事情。</p>
<ol>
<li>给 singleton 分配内存</li>
<li>调用 Singleton 的构造函数来初始化成员变量，形成实例</li>
<li>将 singleton 对象指向分配的内存空间</li>
</ol>
<p>但是在 JVM 的即时编译器中存在指令重排序的优化。也就是说上面的第二步和第三步的顺序是不能保证的，最终的执行顺序可能是 1-2-3 也可能是 1-3-2。如果是后者，则在 3 执行完毕、2 未执行之前，被线程二抢占了，这时 instance 已经是非 null 了（但却没有初始化），所以线程二会直接返回 instance，然后使用，然后便会报错。</p>
<p>因此，修改的方法是把 singleton 声明成 volatile 就可以了。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton singleton = <span class="keyword">null</span>;</span><br><span class="line">	<span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123; &#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Single <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">if</span> (singleton == <span class="keyword">null</span>) &#123;</span><br><span class="line">			<span class="keyword">synchronized</span> (Singleton.class) &#123;</span><br><span class="line">				<span class="keyword">if</span> (singleton == <span class="keyword">null</span>) &#123;</span><br><span class="line">					singleton = <span class="keyword">new</span> Singleton();</span><br><span class="line">				&#125;</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">		<span class="keyword">return</span> singleton;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用 volatile 有两个功用：</p>
<ol>
<li>这个变量不会在多个线程中存在复本，直接从内存读取。</li>
<li>这个关键字会禁止指令重排序优化。也就是说，在 volatile 变量的赋值操作后面会有一个内存屏障（生成的汇编代码上），读操作不会被重排序到内存屏障之前。</li>
</ol>
<h3 id="Singleton-的简化版本"><a href="#Singleton-的简化版本" class="headerlink" title="Singleton 的简化版本"></a>Singleton 的简化版本</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</span><br><span class="line">	<span class="keyword">private</span> <span class="keyword">volatile</span> <span class="keyword">static</span> Singleton singleton = <span class="keyword">new</span> Singleton();</span><br><span class="line">	<span class="function"><span class="keyword">private</span> <span class="title">Singleton</span><span class="params">()</span> </span>&#123; &#125;</span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">		<span class="keyword">return</span> singleton;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>
<p>这种方法非常简单，因为单例的实例被声明成 static 和 final 变量了，在第一次加载类到内存中时就会初始化，所以创建实例本身是线程安全的。</p>
<p>但是，这种方法的最大问题是，当这个类被加载的时候，new Singleton() 这句话就会被执行，就算是 getInstance() 没有被调用，类也被初始化了。</p>
<p>于是，这个可能会与我们想要的行为不一样，比如，我的类的构造函数中，有一些事可能需要依赖于别的类干的一些事（比如某个配置文件，或是某个被其它类创建的资源），我们希望他能在我第一次getInstance()时才被真正的创建。这样，我们可以控制真正的类创建的时刻，而不是把类的创建委托给了类装载器。</p>
<p>于是，</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Singleton</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">SingletonHolder</span> </span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton INSTANCE = <span class="keyword">new</span> Singleton();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="title">Singleton</span> <span class="params">()</span></span>&#123;&#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> Singleton <span class="title">getInstance</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> SingletonHolder.INSTANCE;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>上面这种方式，仍然使用 JVM 本身机制保证了线程安全问题；由于 SingletonHolder 是私有的，除了 getInstance() 之外没有办法访问它，因此它只有在 getInstance() 被调用时才会真正创建；同时读取实例的时候不会进行同步，没有性能缺陷；也不依赖 JDK 版本。</p>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/07/Adaboost-算法总结/" itemprop="url">
                  Adaboost 算法总结
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-03-07T20:01:42+08:00" content="2017-03-07">
              2017-03-07
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2017/03/07/Adaboost-算法总结/" class="leancloud_visitors" data-flag-title="Adaboost 算法总结">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<p>Adaboost 是 boosting 算法的其中之一。它既可以作为分类，也可以作为回归。一般我们都是提它怎么用于分类，对它应用在回归比较少提到，其实它也是可以用于回归的。今天我不想写太多 Adaboost 的原理，主要是写一下 Adaboost 如何用于分类和回归问题。</p>
<h3 id="Adaboost-二元分类问题的算法流程"><a href="#Adaboost-二元分类问题的算法流程" class="headerlink" title="Adaboost 二元分类问题的算法流程"></a>Adaboost 二元分类问题的算法流程</h3><p>输入为样本集 \( (x_1, y_1) ,…, (x_n, y_n) \)，输出为 {+1，-1}。</p>
<p>弱分类器迭代次数为 K。输出为最终的强分类器 \(f(x)\)</p>
<p>1) 初始化样本集权重为：</p>
<p>$$D(1) = (w_{11}, w_{12},…, w_{1m});$$</p>
<p>$$w_{1i} = \frac{1}{m}; i = 1,2,…,m$$</p>
<p>2）对于 \(k = 1, 2, 3 … K\):</p>
<p>a) 使用具有权重 \(D_k\) 的样本集来训练数据，得到弱分类器 \(G_{k}(x)\)</p>
<p>b) 计算 \(G_{k}(x)\) 的分类误差率</p>
<p>$$e_{k} = P(G_k(x_i) \neq y_i); i = 1,2,…,m$$</p>
<p>c) 计算弱分类器的系数</p>
<p>$$\alpha_k = \frac{1}{2} log \frac{1 - e_k}{e_k}$$</p>
<p>d) 更新样本集的权重分布</p>
<p>$$w_{k+1,i} = \frac{w_{ki}}{Z_k} exp(- \alpha_k y_i G(x_i))$$</p>
<p>这里 \(Z_k\) 是规范因子：</p>
<p>$$Z_k = \sum_{i=1}^m w_{ki} exp(-\alpha_k y_i G_k(x_i)) \,\,  i = 1,2,…,m$$</p>
<p>3) 构建最终的分类器为：</p>
<p>$$f(x) = sign \sum_{k=1}^K \alpha_k G_k(K)$$</p>
<p>对于 Adaboost 多元分类算法，其实原理和二分类很类似，最主要的区别是在弱分类器的系数上，比如 Adaboost SAMME 算法，它的弱分类器的系数：</p>
<p>$$ \alpha_k = \frac{1}{2} log \frac{1 - e_k}{e_k} + log(R - 1)$$</p>
<p>其中 R 为类别数，从上式可以看出，如果是二元分类，R = 2，则上式和我们的二元分类算法中的弱分类器的系数一致。</p>
<h3 id="Adaboost-回归问题的算法流程"><a href="#Adaboost-回归问题的算法流程" class="headerlink" title="Adaboost 回归问题的算法流程"></a>Adaboost 回归问题的算法流程</h3><p>AdaBoost回归算法变种很多，下面的算法为Adaboost R2 回归算法过程。</p>
<p>输入为样本集 \( (x_1, y_1) ,…, (x_n, y_n) \)，</p>
<p>最终输出为强学习器 \(f(x)\)</p>
<p>1) 初始化样本集权重为：</p>
<p>$$D(1) = (w_{11}, w_{12},…, w_{1m});$$</p>
<p>$$w_{1i} = \frac{1}{m}; i = 1,2,…,m$$</p>
<p>2）对于 \(k = 1, 2, 3 … K\):</p>
<p>a) 使用具有权重 \(D_k\) 的样本集来训练数据，得到弱分类器 \(G_{k}(x)\)</p>
<p>b) 计算训练集上的最大误差</p>
<p>$$E_k = max|y_i - G_k(x_i)|; i = 1, 2, 3 … m$$</p>
<p>c) 计算每个样本的相对误差：</p>
<p>如果是线性误差，则 \(e_{ki} = \frac{|y_i - G_k(x_i)|}{E_k}\)</p>
<p>如果是平方误差，则 \(e_{ki} = \frac{(y_i - G_k(x_i))^2}{E_k}\)</p>
<p>如果是指数误差，则 \(e_{ki} = 1 -  exp(\frac{-y_i + G_k(x_i)}{E_k})\)</p>
<p>d) 计算回归误差率</p>
<p>$$e_k = \sum_{i=1}^m w_{ki}e_{ki}$$</p>
<p>e) 计算弱学习器的系数</p>
<p>$$\alpha_k = \frac{e_k}{1 - e_k}$$</p>
<p>f) 更新样本集的权重分布为</p>
<p>$$w_{k+1, j} = \frac{w_{ki}}{Z_k} \alpha_k^{1 - e_{ki}}$$</p>
<p>这里 \(Z_k\) 是规范化因子：</p>
<p>$$ Z_k = \sum_{i=1}^m w_{ki} \alpha_k ^{1 - e_{ki}}$$</p>
<p>3) 构建最终的强学习器：</p>
<p>$$f(x) = \sum_{k=1}^K = (ln \frac{1}{\alpha_k}) G_k(x)$$</p>
<h3 id="Adaboost算法的正则化"><a href="#Adaboost算法的正则化" class="headerlink" title="Adaboost算法的正则化"></a>Adaboost算法的正则化</h3><p>为了防止 Adaboost 过拟合，我们通常也会加入正则化项，这个正则化项我们通常称为步长(learning rate)。定义为 ν，对于前面的弱学习器的迭代：</p>
<p>$$f_k(x) = f_{k-1}(x) + \alpha_k G_k (x)$$</p>
<p>如果我们加上了正则项，则有：</p>
<p>$$f_k(x) = f_{k-1}(x) + \nu \alpha_k G_k(x)$$</p>
<p>ν 的取值范围为 \(0&lt;ν≤10&lt;ν≤1\)。对于同样的训练集学习效果，较小的 ν 意味着我们需要更多的弱学习器的迭代次数。通常我们用步长和迭代最大次数一起来决定算法的拟合效果。</p>
<h3 id="Adaboost-小结"><a href="#Adaboost-小结" class="headerlink" title="Adaboost 小结"></a>Adaboost 小结</h3><p>理论上任何学习器都可以用于 Adaboost。但一般来说，使用最广泛的 Adaboost 弱学习器是决策树和神经网络。对于决策树，Adaboost分类用了 CART 分类树，而 Adaboost 回归用了 CART 回归树。</p>
<p>这里对Adaboost算法的优缺点做一个总结。</p>
<p>Adaboost的主要优点有：</p>
<ol>
<li>Adaboost作为分类器时，分类精度很高</li>
<li>在Adaboost的框架下，可以使用各种回归分类模型来构建弱学习器，非常灵活。</li>
<li>作为简单的二元分类器时，构造简单，结果可理解。</li>
<li>不容易发生过拟合</li>
</ol>
<p>Adaboost的主要缺点有：</p>
<ol>
<li>对异常样本敏感，异常样本在迭代中可能会获得较高的权重，影响最终的强学习器的预测准确性。</li>
</ol>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2017/03/05/随机森林和GBDT/" itemprop="url">
                  集成学习：从随机森林到 GBDT
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2017-03-05T15:23:15+08:00" content="2017-03-05">
              2017-03-05
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
          

          

          
          
             <span id="/2017/03/05/随机森林和GBDT/" class="leancloud_visitors" data-flag-title="集成学习：从随机森林到 GBDT">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

<p>研究生期间参加了很多数据挖掘比赛，比赛的题目各不相同，但其实每次用的模型都差不多，其中用的最多的就是随机森林和 GBDT。所以今天打算总结一下这两个模型。</p>
<p>随机森林是一种 bagging 的方法，而 GBDT 则是一种 boosting 的方法。这两类方法统称为集成学习。</p>
<h3 id="什么是集成学习"><a href="#什么是集成学习" class="headerlink" title="什么是集成学习"></a>什么是集成学习</h3><p>集成学习是一种技术框架，其按照不同的思路来组合基础模型，从而达到比单一模型更好的效果。常见的集成学习框架有：bagging，boosting和stacking。南京大学的周志华老师曾经对这三种方法有很明确的定义：</p>
<ul>
<li><strong>bagging</strong>：从训练集从进行子抽样组成每个基模型所需要的子训练集，对所有基模型预测的结果进行综合产生最终的预测结果。</li>
</ul>
<p><img src="/img/bagging.jpg" width="500" height="200" alt="图片名称" align="center"></p>
<ul>
<li><strong>boosting</strong>：训练过程为阶梯状，基模型按次序一一进行训练（实现上可以做到并行），基模型的训练集按照某种策略每次都进行一定的转化。对所有基模型预测的结果进行线性综合产生最终的预测结果。</li>
</ul>
<p><img src="/img/boosting.jpg" width="500" height="300" alt="图片名称" align="center"></p>
<ul>
<li><strong>stack</strong>：将训练好的所有基模型对训练基进行预测，第j个基模型对第i个训练样本的预测值将作为新的训练集中第i个样本的第j个特征值，最后基于新的训练集进行训练。同理，预测的过程也要先经过所有基模型的预测形成新的测试集，最后再对测试集进行预测。</li>
</ul>
<p><img src="/img/stack.jpg" width="500" height="400" alt="图片名称" align="center"></p>
<p>有了集成学习的思想，模型便有了 “集思广益” 的能力，也就不容易产生过拟合现象。但是，为什么这样就可以防止过拟合呢，这就不得不先从模型的偏差和方差入手。</p>
<h3 id="偏差和方差"><a href="#偏差和方差" class="headerlink" title="偏差和方差"></a>偏差和方差</h3><p>广义的偏差（bias）描述的是预测值和真实值之间的差异，方差（variance）描述距的是预测值作为随机变量的离散程度。《Understanding the Bias-Variance Tradeoff》当中有一副图形象地向我们展示了偏差和方差的关系：</p>
<p><img src="/img/varience.png" width="500" height="400" alt="图片名称" align="center"></p>
<h4 id="模型的偏差和方差"><a href="#模型的偏差和方差" class="headerlink" title="模型的偏差和方差"></a>模型的偏差和方差</h4><p>模型的偏差：训练出来的模型在训练集上的误差。</p>
<p>模型的方差：假设模型是随机变量。设样本容量为 n 的训练集为随机变量的集合 \(X_1, X_2,…,X_n\)。那么模型是以这些随机变量为输入的随机变量函数。抽样的随机性会带来模型的随机性。</p>
<p>定义随机变量的值的差异是计算方差的前提条件，通常来说，我们遇到的都是数值型的随机变量，数值之间的差异很好量化，那么对于模型，它们的差异性是指模型的结构差异，例如：线性模型中权值向量的差异，树模型中树的结构差异等。</p>
<p>我们认为方差越大的模型越容易过拟合：假设有两个训练集 A 和 B，经过 A 训练的模型 Fa 与经过 B 训练的模型Fb差异很大，这意味着 Fa 在类 A 的样本集合上有更好的性能，而 Fb 反之，则出现了过拟合。</p>
<p>集成模型中的基模型一般都是弱模型，通常而言，弱模型的偏差很大，方差小，虽然在训练集上效果不好，但是不容易过拟合。有些集成模型中的基模型不是弱模型，bagging 和 stacking 中的基模型为强模型（偏差低，方差高），boosting 中的基模型为弱模型。</p>
<p>在 bagging 和 boosting 框架中，通过计算基模型的期望和方差，我们可以得到模型整体的期望和方差。为了简化模型，我们假设基模型的权重、方差及两两间的相关系数相等。由于bagging 和 boosting 的基模型都是线性组成的，那么有：</p>
<p><img src="/img/m1.png" width="400" height="400" alt="图片名称" align="center"></p>
<h4 id="bagging-的偏差和方差"><a href="#bagging-的偏差和方差" class="headerlink" title="bagging 的偏差和方差"></a>bagging 的偏差和方差</h4><p>对于 bagging 来说，每个基模型的权重等于 1/m 且期望近似相等（子训练集都是从原训练集中进行子抽样），故我们可以进一步化简得到：</p>
<p><img src="/img/m2.png" width="400" height="300" alt="图片名称" align="center"></p>
<p>根据上式我们可以看到，<strong>整体模型的期望近似于基模型的期望，这也就意味着整体模型的偏差和基模型的偏差近似</strong>。同时，整体模型的方差小于等于基模型的方差（当相关性为 1 时取等号），随着基模型数（m）的增多，整体模型的方差减少，从而防止过拟合的能力增强，模型的准确度得到提高。但是，模型的准确度一定会无限逼近于 1 吗？并不一定，当基模型数增加到一定程度时，方差公式第二项的改变对整体方差的作用很小，防止过拟合的能力达到极限，这便是准确度的极限了。<strong>另外，在此我们还知道了为什么 bagging 中的基模型一定要为强模型，否则就会导致整体模型的偏差度低，即准确度低。</strong></p>
<p>随机森林是典型的 bagging 模型，在 bagging 的基础上，进一步降低了模型的方差。随机森林中的基模型是树模型，在树的内部节点分裂过程中，不再是将所有特征，而是随机抽样一部分特征纳入分裂的候选项。这样一来，基模型之间的相关性降低，从而在方差公式中，第一项显著减小，第二项稍微增加，整体方差仍然是减少。</p>
<p>随机森林的子模型都拥有较低的偏差，在 sklearn 中，整体模型的训练过程旨在降低方差，故其需要较少的子模型（n_estimators默认值为10）且子模型不为弱模型（max_depth的默认值为None），同时，降低子模型间的相关度可以起到减少整体模型的方差的效果（max_features的默认值为auto。</p>
<h4 id="boosting-的偏差和方差"><a href="#boosting-的偏差和方差" class="headerlink" title="boosting 的偏差和方差"></a>boosting 的偏差和方差</h4><p>对于 boosting 来说，基模型的训练集抽样是强相关的，那么模型的相关系数近似等于 1，故我们也可以针对 boosting 化简公式为：</p>
<p><img src="/img/m3.png" width="400" height="140" alt="图片名称" align="center"></p>
<p>通过观察整体方差的表达式，我们容易发现，<strong>若基模型不是弱模型，其方差相对较大，这将导致整体模型的方差很大，即无法达到防止过拟合的效果。</strong> 因此，boosting框架中的基模型必须为弱模型。</p>
<p>因为基模型为弱模型，导致了每个基模型的准确度都不是很高（因为其在训练集上的准确度不高）。随着基模型数的增多，整体模型的期望值增加，更接近真实值，因此，整体模型的准确度提高。但是准确度一定会无限逼近于 1 吗？仍然并不一定，因为训练过程中准确度的提高的主要功臣是整体模型在训练集上的准确度提高，而随着训练的进行，整体模型的方差变大，导致防止过拟合的能力变弱，最终导致了准确度反而有所下降。</p>
<p>基于 boosting 框架的 GBDT 模型中基模型也为树模型，和随机森林一样，我们也可以对特征进行随机抽样来使基模型间的相关性降低，从而达到减少方差的效果。</p>
<p>在 sklearn 中，GBDT 的子模型都拥有较低的方差，整体模型的训练过程旨在降低偏差，故其需要较多的子模型（n_estimators默认值为100）且子模型为弱模型（max_depth的默认值为3），但是降低子模型间的相关度不能显著减少整体模型的方差（max_features的默认值为None）。</p>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ol>
<li><p>使用模型的偏差和方差来描述其在训练集上的准确度和防止过拟合的能力。</p>
</li>
<li><p>对于 bagging 来说，整体模型的偏差和基模型近似，随着训练的进行，整体模型的方差降低</p>
</li>
<li><p>对于 boosting 来说，整体模型的初始偏差较高，方差较低，随着训练的进行，整体模型的偏差降低（虽然也不幸地伴随着方差增高），当训练过度时，因方差增高，整体模型的准确度反而降低</p>
</li>
<li><p>整体模型的偏差和方差与基模型的偏差和方差息息相关</p>
</li>
</ol>
<h3 id="GBDT"><a href="#GBDT" class="headerlink" title="GBDT"></a>GBDT</h3><p>我们先讲 GBDT 模型的损失函数。</p>
<p>基于 boosting 框架的整体模型可以用线性组成式来描述，其中 \(h_{i}(x)\) 为基模型与其权值的乘积：</p>
<p>$$F(x) = \sum_i^m h_{i}(x)$$</p>
<p>根据上式，整体模型的训练目标是使预测值 \(F(x)\) 逼近真实值 y，也就是说要让每一个基模型的预测值逼近各自要预测的部分真实值。由于要同时考虑所有基模型，导致了整体模型的训练变成了一个非常复杂的问题。所以，研究者们想到了一个贪心的解决手段：每次只训练一个基模型。那么，现在改写整体模型为迭代式：</p>
<p>$$F^i(x) = f^{i-1}(x) + h_i(x)$$</p>
<p>这样一来，每一轮迭代中，只要集中解决一个基模型的训练问题：使 \(F^i(x)\) 逼近真实值y。</p>
<h4 id="拟合残差"><a href="#拟合残差" class="headerlink" title="拟合残差"></a>拟合残差</h4><p>使 \(F^i(x)\) 逼近真实值，其实就是使 \(h_i(x)\) 逼近真实值和上一轮迭代的预测值 \(F^{i-1}(x)\) 之差，即残差 (\( y - F^{i-1}(x))\) 。最直接的做法是构建基模型来拟合残差。</p>
<p>研究者发现，残差其实是最小均方损失函数的关于预测值的反向梯度：</p>
<p>$$- \frac{\partial (\frac{1}{2} \ast (y - F_{i-1}(x))^2)}{\partial F(x)} = y - F_{i-1}(x)$$</p>
<p>即，\(F^{i-1}(x)\) 加上反向梯度的 \(h_i(x)\) 得到 \(F^i(x)\)，该值可能导致平方差损失函数降低，预测的准确度降低。</p>
<h4 id="拟合反向梯度"><a href="#拟合反向梯度" class="headerlink" title="拟合反向梯度"></a>拟合反向梯度</h4><p>引入任意损失函数后，我们可以定义整体模型的迭代式如下：</p>
<p>$$F^i(x) = F^{i-1}(x) + argmin \sum_j^n L(y_j, F^{i-1}(x_j) + h_i(x_j))$$</p>
<h4 id="常见的损失函数"><a href="#常见的损失函数" class="headerlink" title="常见的损失函数"></a>常见的损失函数</h4><ul>
<li>最小均方误差函数：sklearn 中 GBDT 回归中的默认损失函数，刚才介绍的拟合残差其实就是改损失函数的反向梯度值。</li>
<li>logit 函数：LR 中常用的损失函数。逻辑回归的本质是求极大似然解，其认为样本服从几何分布，样本属于某类别的概率可以用 logistics 函数表达。sklean 中 GBDT 分类模型默认采用这个损失函数。</li>
<li>指数损失函数：<br>$$L(y_j, F^{i-1}(x_j) = e^{-y_j \ast F^{i-1}(x_j)}$$<br>对该损失函数求反向梯度得：<br>$$- \frac{\partial ( y_j, F^{i-1}(x_j))}{\partial ^{i-1} F^{i-1}(x)} = y_j \ast e^{-y_j \ast F^{i-1}(x_j)}$$<br>这时，第 i 轮迭代中，新训练集如下：<br>$${(x_j, y_j \ast e^{-y_j \ast F^{i-1}(x_j)})}$$<br>这表明当损失函数是指数损失时，GBDT 相当于二分类的 Adaboost 算法。是的，指数损失仅能用于二分类的情况。</li>
</ul>
<h4 id="shrinkage"><a href="#shrinkage" class="headerlink" title="shrinkage"></a>shrinkage</h4><p>使用 GBDT 时，每次学习的步长缩减一点。这有什么好处呢？缩减思想认为每次走一小步，多走几次，更容易逼近真实值。如果步子迈大了，使用最速下降法时，容易迈过最优点。</p>
<h4 id="初始模型"><a href="#初始模型" class="headerlink" title="初始模型"></a>初始模型</h4><p>我们定义损失模型为：</p>
<p>$$ F^0 (x) = argmin \sum_j^n L(y_j, \gamma)$$</p>
<p>根据上式可知，对于不同的损失函数来说，初始模型也是不一样的。</p>
<h4 id="小结-1"><a href="#小结-1" class="headerlink" title="小结"></a>小结</h4><p><strong>偏差描述了模型在训练集准确度，而损失函数则是描述该准确度的间接量纲。</strong> 也就是说，模型采用不同的损失函数，其训练过程会朝着不同的方向进行！</p>
<h3 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h3><ul>
<li><a href="http://www.jianshu.com/p/28604e0870d7" target="_blank" rel="external">Random Forest和Gradient Tree Boosting参数详解</a></li>
</ul>

          
        
      
    </div>

    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.jpg"
               alt="PengShuang" />
          <p class="site-author-name" itemprop="name">PengShuang</p>
          <p class="site-description motion-element" itemprop="description">在路上，慢慢走！</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">75</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">20</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">28</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/pengshuang" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://weibo.com/2176899852/profile?rightmod=1&wvr=6&mod=personnumber&is_all=1" target="_blank" title="Weibo">
                  
                    <i class="fa fa-fw fa-weibo"></i>
                  
                  Weibo
                </a>
              </span>
            
          
        </div>

        
        

        
        
          <div class="links-of-blogroll motion-element links-of-blogroll-inline">
            <div class="links-of-blogroll-title">
              <i class="fa  fa-fw fa-globe"></i>
              Links
            </div>
            <ul class="links-of-blogroll-list">
              
                <li class="links-of-blogroll-item">
                  <a href="http://bbs.byr.cn/" title="北邮人" target="_blank">北邮人</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://coolshell.cn/" title="酷壳" target="_blank">酷壳</a>
                </li>
              
                <li class="links-of-blogroll-item">
                  <a href="http://www.dongwm.com" title="小明明的博客" target="_blank">小明明的博客</a>
                </li>
              
            </ul>
          </div>
        

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">PengShuang</span>
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
  <p>Hosted by <a href="https://pages.coding.me" style="font-weight: bold">Coding Pages</a></p>
</div>

<script>
(function(){
    var bp = document.createElement('script');
    bp.src = '//push.zhanzhang.baidu.com/push.js';
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>



        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  



  




  
  

  
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
  </script>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for (i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
      }
    });
  </script>
  <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("DKbLgBme7UkAx9JX6sM3D4Hj-gzGzoHsz", "GXjJ9Ox3pUGI9PJhm6CNfJGN");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

</body>
</html>
